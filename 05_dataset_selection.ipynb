{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Selection\n",
    "\n",
    "**Objective:** Select and prepare a balanced dataset from classified rooftops for analysis.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load classified rooftop data and GeoTIFF metadata\n",
    "2. Enrich data by joining rooftop classifications with tile information\n",
    "3. Create balanced dataset sampling across SIA categories and area bins\n",
    "4. Generate visualizations and export dataset for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from collections import Counter\n",
    "import folium\n",
    "import pyproj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamp for output files\n",
    "todays_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Input data paths\n",
    "GEOPARQUET_CLASSIFICATION_PATH = (\n",
    "    \"data/notebook_02/parquet/02_gdf_toiture_7_classification.parquet\"\n",
    ")\n",
    "SPLIT_GEOTIFF_1024_PARQUET = \"data/notebook_04/geotiff/tile_1024_split/combined_metadata.parquet\"\n",
    "\n",
    "# Sampling parameters\n",
    "SAMPLES_PER_CAT = 8  # Number of samples per category/bin combination\n",
    "\n",
    "# Output paths\n",
    "NOTEBOOK_PATH = Path(\"data/notebook_05\")\n",
    "GRAPHICS_PATH = NOTEBOOK_PATH / \"graphics\"\n",
    "GPKG_SELECTION_DATASET = NOTEBOOK_PATH / \"parquet/05_02_dataset.gpkg\"\n",
    "\n",
    "# Visualization data\n",
    "GPKG_CAD_COMMUNE = \"data/SITG/CAD_COMMUNE_2024-11-03.gpkg\"\n",
    "\n",
    "# PNG conversion settings\n",
    "CONVERT_GEOTIFF_TO_PNG = True\n",
    "PNG_OUTPUT_PATH = NOTEBOOK_PATH / f\"dataset_{todays_date}\"\n",
    "os.makedirs(PNG_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories if they do not exist\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "os.makedirs(GPKG_SELECTION_DATASET.parent, exist_ok=True)\n",
    "os.makedirs(PNG_OUTPUT_PATH, exist_ok=True) \n",
    "\n",
    "\n",
    "# Verify all required paths exist\n",
    "assert(os.path.exists(GEOPARQUET_CLASSIFICATION_PATH))\n",
    "assert(os.path.exists(GRAPHICS_PATH))\n",
    "assert(os.path.exists(PNG_OUTPUT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classified rooftop data\n",
    "gdf_toiture_7_classification = gpd.read_parquet(GEOPARQUET_CLASSIFICATION_PATH)\n",
    "\n",
    "# Validate data integrity\n",
    "assert(gdf_toiture_7_classification[\"egid\"].isna().sum() == 0)\n",
    "gdf_toiture_7_classification[\"egid\"].duplicated().sum() == 0\n",
    "\n",
    "# Check unique building identifiers\n",
    "len(gdf_toiture_7_classification[\"egid\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Enrichment\n",
    "### Load GeoTIFF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tile metadata\n",
    "df_split_geotiff = pd.read_parquet(SPLIT_GEOTIFF_1024_PARQUET)\n",
    "\n",
    "# Display data types for validation\n",
    "df_split_geotiff.dtypes\n",
    "gdf_toiture_7_classification.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Classification sia_cat with Tile Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "df_split_geotiff_sia_cat = df_split_geotiff.copy()\n",
    "\n",
    "# Identify common columns between datasets (excluding geometry)\n",
    "common_columns = set(df_split_geotiff_sia_cat.columns) & set(gdf_toiture_7_classification.columns)\n",
    "common_columns = list(common_columns - {\"geometry\"})\n",
    "\n",
    "# Merge rooftop classifications with tile information\n",
    "df_split_geotiff_sia_cat = pd.merge(\n",
    "    gdf_toiture_7_classification, \n",
    "    df_split_geotiff_sia_cat, \n",
    "    on=list(common_columns), \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview merged data\n",
    "df_split_geotiff_sia_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all rooftops have associated tiles\n",
    "missing_tiles = df_split_geotiff_sia_cat[df_split_geotiff_sia_cat[\"tile_path\"].isnull()]\n",
    "assert(len(missing_tiles) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enriched dataset for future reference\n",
    "df_split_geotiff_sia_cat.to_parquet(NOTEBOOK_PATH / \"05_02_split_geotiff_sia_cat.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create randomized selection dataset\n",
    "df_selection = df_split_geotiff_sia_cat.copy()\n",
    "df_selection = df_selection.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "display(df_selection.head(5))\n",
    "display(df_selection.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique buildings per tile\n",
    "df_selection.groupby(\"tile_id\")[\"egid\"].nunique().reset_index().sort_values(by=[\"egid\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total rooftop area per tile\n",
    "df_selection.groupby(\"tile_id\")[\"SHAPE__Area\"].sum().reset_index().sort_values(by=[\"SHAPE__Area\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique SIA categories per tile\n",
    "df_selection.groupby(\"tile_id\")[\"sia_cat\"].nunique().reset_index().sort_values(by=[\"sia_cat\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add aggregate metrics per tile\n",
    "df_selection[\"egid_per_tile\"] = df_selection.groupby(\"tile_id\")[\"egid\"].transform(\"nunique\")\n",
    "df_selection[\"sia_cat_per_tile\"] = df_selection.groupby(\"tile_id\")[\"sia_cat\"].transform(\"nunique\")\n",
    "df_selection[\"SHAPE__Area_sum_per_tile\"] = df_selection.groupby(\"tile_id\")[\"SHAPE__Area\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling by SIA Category and Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data by tile\n",
    "tile_groups = df_selection.groupby('tile_id').agg({\n",
    "    'globalid': list,\n",
    "    'geometry_x': list,\n",
    "    'sia_cat': list,\n",
    "    'altitude_min': 'mean',\n",
    "    'altitude_max': 'mean',\n",
    "    'date_leve': 'first',\n",
    "    'tile_path': 'first',\n",
    "    'tile_bounds': 'first',\n",
    "    \"SHAPE__Area\": 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Determine dominant SIA class per tile\n",
    "tile_groups['dominant_class'] = tile_groups['sia_cat'].apply(\n",
    "    lambda x: Counter(x).most_common(1)[0][0]\n",
    ")\n",
    "\n",
    "# Create area bins for stratification\n",
    "area_bins = [0, 200, 500, 1000, 2000, 5000, np.inf]\n",
    "tile_groups['area_bin'] = pd.cut(\n",
    "    tile_groups['SHAPE__Area'],\n",
    "    bins=area_bins,\n",
    "    labels=[\n",
    "        '0-200', '200-500', '500-1000',\n",
    "        '1000-2000', '2000-5000', '5000+'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Area distribution across bins:\")\n",
    "print(tile_groups['area_bin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tiles(group, n_samples):\n",
    "    \"\"\"\n",
    "    Sample tiles from a group with fallback for small groups.\n",
    "    \n",
    "    Parameters:\n",
    "        group: DataFrame group to sample from\n",
    "        n_samples: Target number of samples\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Sampled subset of the group\n",
    "    \"\"\"\n",
    "    if len(group) > n_samples:\n",
    "        return group.sample(n=n_samples, random_state=42)\n",
    "    else:\n",
    "        return group\n",
    "\n",
    "# Perform stratified sampling\n",
    "sampled_df = tile_groups.groupby(['dominant_class', 'area_bin']).apply(\n",
    "    sample_tiles, n_samples=SAMPLES_PER_CAT\n",
    ").reset_index(drop=True)\n",
    "\n",
    "def convert_bounds_to_polygon(bounds):\n",
    "    \"\"\"\n",
    "    Convert tile bounds to Polygon geometry.\n",
    "    \n",
    "    Parameters:\n",
    "        bounds: Tuple or string representation of bounds (minx, miny, maxx, maxy)\n",
    "        \n",
    "    Returns:\n",
    "        Polygon: Shapely polygon representing the tile bounds\n",
    "    \"\"\"\n",
    "    if isinstance(bounds, str):\n",
    "        bounds = tuple(map(float, bounds.strip(\"()\").split(\",\")))\n",
    "    if len(bounds) == 4:\n",
    "        minx, miny, maxx, maxy = bounds\n",
    "        return Polygon([(minx, miny), (maxx, miny), (maxx, maxy), (minx, maxy)])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid bounds format: {bounds}\")\n",
    "\n",
    "# Convert bounds to geometry\n",
    "sampled_df['geometry'] = sampled_df['tile_bounds'].apply(convert_bounds_to_polygon)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "sampled_gdf = gpd.GeoDataFrame(\n",
    "    sampled_df,\n",
    "    geometry='geometry',\n",
    "    crs='EPSG:2056'\n",
    ")\n",
    "\n",
    "# Save sampled dataset\n",
    "sampled_gdf.to_file(GPKG_SELECTION_DATASET, driver=\"GPKG\", layer=\"sampled_tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "### Statistical Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plot for dominant SIA classes\n",
    "class_counts = tile_groups['dominant_class'].value_counts().reset_index()\n",
    "class_counts.columns = ['Classe SIA', 'Nombre de tiles']\n",
    "\n",
    "# Configure plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(6.5, 5.5))\n",
    "plot = sns.barplot(\n",
    "    x='Classe SIA', \n",
    "    y='Nombre de tiles', \n",
    "    data=class_counts.sort_values(by='Classe SIA'),\n",
    "    palette='pastel',\n",
    ")\n",
    "\n",
    "# Format labels\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Distribution des classes SIA dominantes par tuile\", fontsize=12, pad=10, fontweight='bold')\n",
    "plt.xlabel(\"Classe SIA\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Add value labels on bars\n",
    "for p in plot.patches:\n",
    "    plot.annotate(\n",
    "        f'{int(p.get_height())}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black',\n",
    "        xytext=(0, 5), \n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "# Clean up plot\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"05_01_dominant_class_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plot for area bins\n",
    "plt.close()\n",
    "area_counts = tile_groups['area_bin'].value_counts().reset_index()\n",
    "area_counts.columns = ['Area Bin', 'Nombre de tiles']\n",
    "area_counts = area_counts.sort_values(by='Area Bin')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(6.5, 4.5))\n",
    "plot = sns.barplot(\n",
    "    x='Area Bin', \n",
    "    y='Nombre de tiles', \n",
    "    data=area_counts,\n",
    "    palette='pastel',\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Distribution des tuiles par intervalle de surface\", fontsize=12, fontweight='bold', pad=10)\n",
    "plt.xlabel(\"Somme des surfaces par tuile en m²\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "# Add value labels\n",
    "for p in plot.patches:\n",
    "    plot.annotate(\n",
    "        f'{int(p.get_height())}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black',\n",
    "        xytext=(0, 5), \n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "# Clean up plot\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"05_02_area_bin_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stacked bar chart showing sampling distribution\n",
    "plt.close()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Prepare data for stacking\n",
    "stacked_data = sampled_df.groupby(['dominant_class', 'area_bin']).size().unstack().fillna(0)\n",
    "\n",
    "# Ensure consistent ordering\n",
    "area_order = ['0-200', '200-500', '500-1000', '1000-2000', '2000-5000', '5000+']\n",
    "stacked_data = stacked_data.reindex(columns=area_order)\n",
    "\n",
    "# Create color palette\n",
    "colors = sns.color_palette(\"pastel\", len(stacked_data.columns))\n",
    "\n",
    "plt.figure(figsize=(6.5, 5.5))\n",
    "\n",
    "# Create stacked bar plot\n",
    "stacked_data.plot(\n",
    "    kind='bar', \n",
    "    stacked=True, \n",
    "    color=colors,\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "total_samples = stacked_data.sum().sum()\n",
    "plt.title(f\"Distribution du dataset des classes SIA dominantes\\npar intervalle de surface (n={int(total_samples)})\", \n",
    "          fontsize=12, pad=20, fontweight='bold')\n",
    "plt.xlabel(\"Classe SIA dominante\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "# Configure legend\n",
    "plt.legend(\n",
    "    title=\"Surface totale\\n par tuile (m²)\", \n",
    "    bbox_to_anchor=(1.05, 1), \n",
    "    loc='upper left',\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    fontsize=10,\n",
    "    title_fontsize=10,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "plt.ylim(0, 55)\n",
    "sns.despine()\n",
    "plt.grid(False)\n",
    "\n",
    "# Add total counts on top of bars\n",
    "for i, total in enumerate(stacked_data.sum(axis=1)):\n",
    "    plt.text(i, total + 0.5, f'{int(total)}', \n",
    "             ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# Add counts for small segments\n",
    "for i, (index, row) in enumerate(stacked_data.iterrows()):\n",
    "    bottom = 0\n",
    "    annotation_count = 0\n",
    "    \n",
    "    for j, (area_bin, count) in enumerate(row.items()):\n",
    "        if count > 0 and count < 8:\n",
    "            segment_middle = bottom + count/2\n",
    "            \n",
    "            # Alternate label positions\n",
    "            offset = 0.4\n",
    "            if annotation_count % 2 == 0:\n",
    "                x_offset = i + offset\n",
    "            else:\n",
    "                x_offset = i - offset\n",
    "            \n",
    "            plt.text(x_offset, segment_middle, f'{int(count)}', \n",
    "                     ha='center', va='center', fontsize=9, \n",
    "                     color='black', fontweight='demibold',)\n",
    "            \n",
    "            annotation_count += 1\n",
    "        bottom += count\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"05_03_stacked.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_polygon(bounds_str):\n",
    "    \"\"\"\n",
    "    Convert bounds string to Polygon geometry.\n",
    "    \n",
    "    Parameters:\n",
    "        bounds_str: String representation of bounds '(minx, miny, maxx, maxy)'\n",
    "        \n",
    "    Returns:\n",
    "        Polygon: Shapely polygon or None if conversion fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coords = [float(x) for x in bounds_str.strip(\"()\").split(\", \")]\n",
    "        return Polygon([\n",
    "            (coords[0], coords[1]),  # Bottom-left\n",
    "            (coords[2], coords[1]),  # Bottom-right\n",
    "            (coords[2], coords[3]),  # Top-right\n",
    "            (coords[0], coords[3])   # Top-left\n",
    "        ])\n",
    "    except ValueError:\n",
    "        logging.error(f\"Error converting bounds to polygon: {bounds_str}\")\n",
    "        return None\n",
    "\n",
    "# Configure plot style\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Create geometry column\n",
    "tile_groups['geometry'] = tile_groups['tile_bounds'].apply(bounds_to_polygon)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    tile_groups,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:2056\"\n",
    ")\n",
    "\n",
    "# Create color mapping for SIA classes\n",
    "unique_classes = sorted(gdf['dominant_class'].unique())\n",
    "palette = sns.color_palette('tab20', n_colors=len(unique_classes))\n",
    "color_dict = dict(zip(unique_classes, palette))\n",
    "\n",
    "# Create spatial plot\n",
    "ax = gdf.plot(\n",
    "    figsize=(15, 15),\n",
    "    column='dominant_class',\n",
    "    legend=True,\n",
    "    legend_kwds={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    color=gdf['dominant_class'].map(color_dict)\n",
    ")\n",
    "\n",
    "# Add commune boundaries\n",
    "cad_commune = gpd.read_file(GPKG_CAD_COMMUNE, layer=\"CAD_COMMUNE\")\n",
    "cad_commune = cad_commune.to_crs(\"EPSG:2056\")\n",
    "cad_commune.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=0.2)\n",
    "\n",
    "# Create custom legend\n",
    "ax.legend(\n",
    "    handles=[plt.Line2D([0], [0], marker='o', color='w', label=cls, \n",
    "                         markerfacecolor=color_dict[cls], markersize=10) for cls in unique_classes],\n",
    "    title=\"Classe SIA dominante\",\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(1, 1)\n",
    ")\n",
    "\n",
    "ax.set_title(f\"Tile par catégorie SIA dominante (total {len(tile_groups)} tiles)\", fontsize=16, pad=20)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"05_04_map_tiles_group.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed map of sampled tiles\n",
    "plt.close()\n",
    "\n",
    "# Create geometry for sampled data\n",
    "sampled_df['geometry'] = sampled_df['tile_bounds'].apply(bounds_to_polygon)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    sampled_df,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:2056\"\n",
    ")\n",
    "\n",
    "unique_classes = sorted(gdf['dominant_class'].unique())\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define vibrant colors for better visibility\n",
    "vibrant_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', \n",
    "                  '#FF9FF3', '#54A0FF', '#5F27CD', '#00D2D3', '#FF9F43',\n",
    "                  '#A3CB38', '#C44569']\n",
    "\n",
    "color_dict = dict(zip(unique_classes, vibrant_colors[:len(unique_classes)]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5, 6.5), dpi=300)\n",
    "\n",
    "# Plot sampled tiles\n",
    "gdf.plot(\n",
    "    column='dominant_class',\n",
    "    ax=ax,\n",
    "    edgecolor=gdf['dominant_class'].map(color_dict),\n",
    "    linewidth=2,\n",
    "    alpha=1,\n",
    "    color=gdf['dominant_class'].map(color_dict)\n",
    ")\n",
    "\n",
    "# Add commune boundaries for context\n",
    "cad_commune = gpd.read_file(GPKG_CAD_COMMUNE, layer=\"CAD_COMMUNE\")\n",
    "cad_commune = cad_commune.to_crs(\"EPSG:2056\")\n",
    "cad_commune.plot(ax=ax, color=\"none\", edgecolor=\"grey\", linewidth=0.8, alpha=0.6, ls='--')\n",
    "\n",
    "# Create shortened labels for better readability\n",
    "class_labels = {\n",
    "    'I habitat collectif': 'I Habitat collectif',\n",
    "    'II habitat individuel': 'II Habitat individuel', \n",
    "    'III administration': 'III Administration',\n",
    "    'IV écoles': 'IV Écoles',\n",
    "    'IX industrie': 'IX Industrie',\n",
    "    'V commerce': 'V Commerce',\n",
    "    'VI restauration': 'VI Restauration',\n",
    "    'VII lieux de rassemblement': 'VII Lieux rassemblement',\n",
    "    'VIII hôpitaux': 'VIII Hôpitaux',\n",
    "    'X dépôts': 'X Dépôts',\n",
    "    'XI installations sportives': 'XI Installations sportives',\n",
    "    'XII piscines couvertes': 'XII Piscines couvertes'\n",
    "}\n",
    "\n",
    "# Create legend elements\n",
    "legend_elements = []\n",
    "for cls in unique_classes:\n",
    "    label = class_labels.get(cls, cls)\n",
    "    if len(label) > 25:\n",
    "        label = label[:22] + \"...\"\n",
    "    legend_elements.append(\n",
    "        plt.Line2D([0], [0], marker='s', color='w', label=label,\n",
    "                   markerfacecolor=color_dict[cls], markersize=8, \n",
    "                   markeredgecolor='black', markeredgewidth=0.5)\n",
    "    )\n",
    "\n",
    "# Add legend\n",
    "legend = ax.legend(\n",
    "    handles=legend_elements,\n",
    "    title=\"Classe SIA dominante\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(0.35, 0.95),\n",
    "    fontsize=9,\n",
    "    title_fontsize=10,\n",
    ")\n",
    "\n",
    "ax.set_title(f\"Tuiles par catégorie SIA dominante\\n(total {len(sampled_df)} tuiles)\", \n",
    "             fontsize=12, pad=-10, fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.02, right=0.98, top=0.95, bottom=0.02)\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"05_05_map_sampled_df.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinate system transformers\n",
    "swiss_cs = pyproj.CRS(\"EPSG:2056\")  # Swiss LV95\n",
    "wgs84_cs = pyproj.CRS(\"EPSG:4326\")  # WGS84\n",
    "\n",
    "transformer = pyproj.Transformer.from_crs(swiss_cs, wgs84_cs, always_xy=True)\n",
    "\n",
    "def swiss_to_wgs84(east, north):\n",
    "    \"\"\"\n",
    "    Convert Swiss coordinates to WGS84.\n",
    "    \n",
    "    Parameters:\n",
    "        east: Easting in Swiss coordinates\n",
    "        north: Northing in Swiss coordinates\n",
    "        \n",
    "    Returns:\n",
    "        list: [latitude, longitude] in WGS84\n",
    "    \"\"\"\n",
    "    lon, lat = transformer.transform(east, north)\n",
    "    return [lat, lon]\n",
    "   \n",
    "# Calculate map bounds from all tiles\n",
    "all_sw_points = []\n",
    "all_ne_points = []\n",
    "\n",
    "for tile_id in sampled_df['tile_id'].tolist():\n",
    "    tile_row = sampled_df[sampled_df['tile_id'] == tile_id]\n",
    "    if len(tile_row) == 0:\n",
    "        continue\n",
    "        \n",
    "    bounds = tile_row['tile_bounds'].values[0]\n",
    "    \n",
    "    if isinstance(bounds, str):\n",
    "        bounds_clean = bounds.strip('()').replace(' ', '')\n",
    "        bounds_list = bounds_clean.split(',')\n",
    "        bounds = tuple(float(x) for x in bounds_list if x)\n",
    "    \n",
    "    if len(bounds) >= 4:\n",
    "        minx, miny, maxx, maxy = bounds[:4]\n",
    "        \n",
    "        sw = swiss_to_wgs84(minx, miny)\n",
    "        ne = swiss_to_wgs84(maxx, maxy)\n",
    "        \n",
    "        all_sw_points.append(sw)\n",
    "        all_ne_points.append(ne)\n",
    "\n",
    "# Calculate center point\n",
    "if all_sw_points and all_ne_points:\n",
    "    avg_lat = np.mean([pt[0] for pt in all_sw_points + all_ne_points])\n",
    "    avg_lon = np.mean([pt[1] for pt in all_sw_points + all_ne_points])\n",
    "    print(f\"Center of all tiles (lat, lon): {avg_lat}, {avg_lon}\")\n",
    "    \n",
    "    m = folium.Map(location=[avg_lat, avg_lon], zoom_start=14)\n",
    "else:\n",
    "    print(\"No valid coordinates found\")\n",
    "    m = folium.Map(location=[46.2044, 6.1432], zoom_start=12)\n",
    "\n",
    "# Add tiles to map\n",
    "tiles_added = 0\n",
    "for tile_id in sampled_df['tile_id'].tolist():\n",
    "    tile_row = sampled_df[sampled_df['tile_id'] == tile_id]\n",
    "    if len(tile_row) == 0:\n",
    "        continue\n",
    "        \n",
    "    bounds = tile_row['tile_bounds'].values[0]\n",
    "    \n",
    "    if isinstance(bounds, str):\n",
    "        bounds_clean = bounds.strip('()').replace(' ', '')\n",
    "        bounds_list = bounds_clean.split(',')\n",
    "        bounds = tuple(float(x) for x in bounds_list if x)\n",
    "    \n",
    "    if len(bounds) >= 4:\n",
    "        minx, miny, maxx, maxy = bounds[:4]\n",
    "        \n",
    "        # Convert corners to WGS84\n",
    "        sw = swiss_to_wgs84(minx, miny)\n",
    "        ne = swiss_to_wgs84(maxx, maxy)\n",
    "        nw = swiss_to_wgs84(minx, maxy)\n",
    "        se = swiss_to_wgs84(maxx, miny)\n",
    "        \n",
    "        # Create polygon\n",
    "        folium.Polygon(\n",
    "            locations=[sw, nw, ne, se],\n",
    "            color='blue',\n",
    "            weight=1,\n",
    "            fill=True,\n",
    "            fill_opacity=0.4,\n",
    "            tooltip=f\"Tile ID: {tile_id}\"\n",
    "        ).add_to(m)\n",
    "        \n",
    "        tiles_added += 1\n",
    "\n",
    "print(f\"Added {tiles_added} tiles to the map\")\n",
    "\n",
    "# Display map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoTIFF to PNG Conversion\n",
    "\n",
    "Note: PNG was for Roboflow, which was not used in the methodology. Supervisely admits directly GeoTIFF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data before conversion\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tiff_to_png(sample_df, output_dir):\n",
    "    \"\"\"\n",
    "    Convert GeoTIFF files to PNG format for machine learning workflows.\n",
    "    \n",
    "    Uses GDAL to convert with optimized settings for image quality and\n",
    "    file size. Creates timestamped output directory to track conversions.\n",
    "    \n",
    "    Parameters:\n",
    "        sample_df: DataFrame containing tile_path column with GeoTIFF paths\n",
    "        output_dir: Base directory for PNG output\n",
    "        \n",
    "    Returns:\n",
    "        Path: Output directory path containing converted files\n",
    "    \"\"\"\n",
    "    # Create timestamped output directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = Path(output_dir) / f\"PNG_dataset_roboflow_{timestamp}\"\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logging.info(f\"Output directory created: {output_dir}\")\n",
    "\n",
    "    # Extract unique TIFF files from dataset\n",
    "    tiff_files = sample_df[\"tile_path\"].dropna().unique().tolist()\n",
    "    \n",
    "    # Ensure Path objects\n",
    "    tiff_files = [Path(file) if not isinstance(file, Path) else file for file in tiff_files]\n",
    "    \n",
    "    logging.info(f\"Found {len(tiff_files)} unique TIFF files to process\")\n",
    "\n",
    "    # Process each TIFF file\n",
    "    for tiff_file in tqdm(tiff_files, desc=\"Converting to PNG\"):\n",
    "        # Validate source file\n",
    "        if not Path(tiff_file).exists():\n",
    "            logging.warning(f\"Source file not found: {tiff_file}\")\n",
    "            continue\n",
    "\n",
    "        # Define output path\n",
    "        png_file = output_dir / f\"{Path(tiff_file).stem}.png\"\n",
    "\n",
    "        # Skip if already converted\n",
    "        if not png_file.exists():\n",
    "            try:\n",
    "                # Execute GDAL conversion with optimized parameters\n",
    "                subprocess.run(\n",
    "                    [\n",
    "                        \"gdal_translate\",      # GDAL conversion tool\n",
    "                        \"-of\", \"PNG\",          # Output format\n",
    "                        \"-co\", \"ZLEVEL=9\",     # Maximum PNG compression\n",
    "                        \"-co\", \"PREDICTOR=2\",  # Optimization for compression\n",
    "                        \"-ot\", \"Byte\",         # 8-bit output\n",
    "                        \"-r\", \"nearest\",       # Nearest neighbor resampling\n",
    "                        \"-co\", \"COMPRESS=PNG\", # Use PNG compression\n",
    "                        str(tiff_file),        # Input file\n",
    "                        str(png_file),         # Output file\n",
    "                    ],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                )\n",
    "                logging.info(f\"Converted {Path(tiff_file).name}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                logging.error(f\"Error converting {tiff_file}: {e.stderr}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Unexpected error processing {tiff_file}: {str(e)}\")\n",
    "        else:\n",
    "            logging.info(f\"Skipping {Path(tiff_file).name} (already exists)\")\n",
    "    \n",
    "    logging.info(f\"Conversion complete. Files saved to {output_dir}\")\n",
    "    \n",
    "    # Save metadata for reference\n",
    "    sample_df.to_csv(output_dir / \"sampled_tiles.csv\", index=False)\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute conversion if enabled\n",
    "if CONVERT_GEOTIFF_TO_PNG:\n",
    "    convert_tiff_to_png(\n",
    "        sampled_df,\n",
    "        PNG_OUTPUT_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rooftops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
