{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca67a47f",
   "metadata": {},
   "source": [
    "# YOLO Cross validation datasets\n",
    "\n",
    "**Objective:** Prepare Supervisely CV dataset to YOLO format with data augmentation\n",
    "\n",
    "**Workflow:**\n",
    "1. Convert binary masks to YOLO segmentation format\n",
    "2. Create cross-validation datasets with augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e13e83",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3024dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "# from ultralytics import YOLO\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da128b9",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamp for unique naming\n",
    "todaysdate = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Output paths\n",
    "CREATE_DATASET_PROCESSED_PATH = f\"datasets/supervisely/yolo_processed_{todaysdate}\"\n",
    "DEVICE = \"2\"\n",
    "\n",
    "# Binary mask conversion paths\n",
    "ANNOTATIONS_BINARY_PNG_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/masks\"\n",
    "YOLO_ANNOTATIONS_OUTPUT_PATH = f\"{CREATE_DATASET_PROCESSED_PATH}/labels\"\n",
    "TEST_MASK_OUTPUT_PATH = os.path.join(CREATE_DATASET_PROCESSED_PATH, \"test_masks\")\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_PATH = \"datasets/supervisely/341575_free_space_rooftop_geneva_20250511_yolo\"\n",
    "FOLD_PATHS = {\n",
    "    0: \"datasets/supervisely/dataset_processed_20250523-173715/fold_0_dataset.txt\",\n",
    "    1: \"datasets/supervisely/dataset_processed_20250523-173715/fold_1_dataset.txt\",\n",
    "    2: \"datasets/supervisely/dataset_processed_20250523-173715/fold_2_dataset.txt\",\n",
    "    3: \"datasets/supervisely/dataset_processed_20250523-173715/fold_3_dataset.txt\",\n",
    "    4: \"datasets/supervisely/dataset_processed_20250523-173715/fold_4_dataset.txt\"\n",
    "}\n",
    "TEST_DATASET_TXT_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/test_dataset.txt\"\n",
    "IMG_DATASET_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/images\"\n",
    "\n",
    "# Augmentation parameters\n",
    "NUM_AUGMENTATIONS_PER_IMAGE = 10  # Number of augmented versions per original\n",
    "AUGMENTATION_WORKERS = 8  # Number of parallel workers for augmentation\n",
    "\n",
    "# Training configuration\n",
    "DATASET_PROCESSED_PATH = \"datasets/supervisely/yolo_processed_20250618_201019\"\n",
    "MODEL_NAME = \"yolo12x-seg.yaml\" # yolo11n-seg.pt\n",
    "OUTPUT_DIR_YOLO = \"training_yolo\"\n",
    "PROJECT_NAME = f\"yolo_free_space_rooftop_{todaysdate}\"\n",
    "CLASS_NAMES = [\"free_space\"]\n",
    "CUSTOM_PARAMS = {\n",
    "    'epochs': 5000,\n",
    "    'batch': 1,\n",
    "    'imgsz': 1280,\n",
    "    'patience': 30,\n",
    "    'lr0': 0.005,\n",
    "}\n",
    "\n",
    "# Evaluation parameters\n",
    "OUTPUT_EVALUATE_TEST_DIR = os.path.join(OUTPUT_DIR_YOLO, f\"auto_cv_evaluation_results_{todaysdate}\")\n",
    "CONF_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.7\n",
    "CLASS_NAMES = [\"free_space\"]\n",
    "\n",
    "# Feature flags\n",
    "CONVERT_BINARY_MASKS_TO_YOLO_FORMAT = True\n",
    "SPLIT_DATASET = True\n",
    "APPLY_AUGMENTATION = True\n",
    "TRAIN_YOLO = False\n",
    "EVALUATE_YOLO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create required directories\n",
    "if CONVERT_BINARY_MASKS_TO_YOLO_FORMAT:\n",
    "    os.makedirs(CREATE_DATASET_PROCESSED_PATH, exist_ok=True)\n",
    "    os.makedirs(YOLO_ANNOTATIONS_OUTPUT_PATH, exist_ok=True)\n",
    "    os.makedirs(TEST_MASK_OUTPUT_PATH, exist_ok=True)\n",
    "if EVALUATE_YOLO:\n",
    "    os.makedirs(OUTPUT_EVALUATE_TEST_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipeline for data augmentation\n",
    "AUGMENTATION_PIPELINE = A.Compose([\n",
    "    # Basic Geometric\n",
    "    A.SquareSymmetry(p=0.5),\n",
    "    # Affine and Perspective\n",
    "    A.Affine(\n",
    "        scale=(0.95, 1.05), translate_percent=0.1, rotate=(-45, 45), p=0.6\n",
    "    ),\n",
    "    # Blur\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.MotionBlur(blur_limit=(3, 7), p=0.5),\n",
    "        ],\n",
    "        p=0.2,\n",
    "    ),\n",
    "    # Noise\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.ISONoise(\n",
    "                color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5\n",
    "            ),\n",
    "            A.MultiplicativeNoise(\n",
    "                multiplier=(0.9, 1.1), per_channel=True, p=0.5\n",
    "            ),\n",
    "            A.SaltAndPepper(p=0.5),\n",
    "        ],\n",
    "        p=0.2,\n",
    "    ),\n",
    "    # Weather effects\n",
    "    A.RandomSunFlare(p=0.2),\n",
    "    A.RandomFog(p=0.2),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9ce96",
   "metadata": {},
   "source": [
    "## Binary Mask to YOLO Format Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_join(parent_contour, child_contour):\n",
    "    \"\"\"\n",
    "    Join parent contour with child contour for handling donut-shaped masks.\n",
    "    \n",
    "    Handles cases where masks have holes (e.g., donut shapes) by properly\n",
    "    joining outer and inner contours. The inside of the donut should not\n",
    "    be detected as positive area.\n",
    "    \n",
    "    Parameters:\n",
    "        parent_contour: Outer contour points\n",
    "        child_contour: Inner contour points (hole)\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Merged contour preserving the hole\n",
    "        \n",
    "    Reference:\n",
    "        https://github.com/ultralytics/ultralytics/issues/3085\n",
    "    \"\"\"\n",
    "    def is_clockwise(contour):\n",
    "        value = 0\n",
    "        num = len(contour)\n",
    "        for i in range(num):\n",
    "            p1 = contour[i]\n",
    "            p2 = contour[(i + 1) % num]  # More efficient modulo operation\n",
    "            value += (p2[0][0] - p1[0][0]) * (p2[0][1] + p1[0][1])\n",
    "        return value < 0\n",
    "\n",
    "    def get_merge_point_idx(contour1, contour2):\n",
    "        min_distance = float('inf')\n",
    "        idx1, idx2 = 0, 0\n",
    "        \n",
    "        # Vectorized distance calculation for better performance\n",
    "        for i, p1 in enumerate(contour1):\n",
    "            distances = np.sum((contour2[:, 0] - p1[0]) ** 2, axis=1)\n",
    "            min_idx = np.argmin(distances)\n",
    "            if distances[min_idx] < min_distance:\n",
    "                min_distance = distances[min_idx]\n",
    "                idx1, idx2 = i, min_idx\n",
    "        return idx1, idx2\n",
    "\n",
    "    def merge_contours(contour1, contour2, idx1, idx2):\n",
    "        # More efficient concatenation\n",
    "        part1 = contour1[:idx1 + 1]\n",
    "        part2 = contour2[idx2:]\n",
    "        part3 = contour2[:idx2 + 1]\n",
    "        part4 = contour1[idx1:]\n",
    "        \n",
    "        contour = np.concatenate([part1, part2, part3, part4], axis=0)\n",
    "        return contour.astype(np.int32)\n",
    "\n",
    "    def merge_with_parent(parent_contour, contour):\n",
    "        if not is_clockwise(parent_contour):\n",
    "            parent_contour = parent_contour[::-1]\n",
    "        if is_clockwise(contour):\n",
    "            contour = contour[::-1]\n",
    "        idx1, idx2 = get_merge_point_idx(parent_contour, contour)\n",
    "        return merge_contours(parent_contour, contour, idx1, idx2)\n",
    "\n",
    "    return merge_with_parent(parent_contour=parent_contour, contour=child_contour)\n",
    "\n",
    "\n",
    "def group_child_contours_with_parent(hierarchy):\n",
    "    \"\"\"\n",
    "    Group child contours with their parent contours based on hierarchy.\n",
    "    \n",
    "    Parameters:\n",
    "        hierarchy: OpenCV contour hierarchy array\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mapping parent indices to their child indices\n",
    "              Format: {parent_idx: {\"parent\": idx, \"child\": [child_indices]}}\n",
    "    \"\"\"\n",
    "    groups = {}\n",
    "    hierarchy_flat = hierarchy.squeeze()\n",
    "    \n",
    "    for i, h in enumerate(hierarchy_flat):\n",
    "        parent_index = h[3]\n",
    "        if parent_index != -1:\n",
    "            if parent_index in groups:\n",
    "                groups[parent_index][\"child\"].append(i)\n",
    "            else:\n",
    "                groups[parent_index] = {\"parent\": parent_index, \"child\": [i]}\n",
    "        else:\n",
    "            if i not in groups:\n",
    "                groups[i] = {\"parent\": i, \"child\": []}\n",
    "            else:\n",
    "                groups[i][\"parent\"] = i\n",
    "    return groups\n",
    "\n",
    "\n",
    "def convert_mask_to_yolo_seg_label(mask_path, create_test_mask=True):\n",
    "    \"\"\"\n",
    "    Convert a single binary mask to YOLO segmentation format.\n",
    "    \n",
    "    Processes binary mask images and converts them to YOLO polygon format\n",
    "    with normalized coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        mask_path: Path to the binary mask file\n",
    "        create_test_mask: Whether to create test mask for verification\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (label_str, test_mask, error_msg)\n",
    "            - label_str: YOLO format label string\n",
    "            - test_mask: Reconstructed mask for verification (if requested)\n",
    "            - error_msg: Error message if conversion failed, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        label_str = \"\"\n",
    "        test_mask = None\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            return label_str, test_mask, f\"Could not read mask from {mask_path}\"\n",
    "        \n",
    "        height, width = mask.shape\n",
    "        \n",
    "        # Threshold (optimized for 0/1 masks)\n",
    "        _, thresh = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return label_str, test_mask, None\n",
    "        \n",
    "        # Initialize test mask only if needed\n",
    "        if create_test_mask:\n",
    "            test_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        \n",
    "        # Process contours\n",
    "        if len(contours) > 1 and hierarchy is not None:\n",
    "            contour_groups = group_child_contours_with_parent(hierarchy)\n",
    "            for contour_group in contour_groups.values():\n",
    "                parent_contour = contours[contour_group[\"parent\"]]\n",
    "                \n",
    "                # Join with child contours\n",
    "                for child in contour_group[\"child\"]:\n",
    "                    parent_contour = contours_join(parent_contour=parent_contour, child_contour=contours[child])\n",
    "                \n",
    "                # Process contour\n",
    "                contour_label = process_contour(parent_contour, width, height)\n",
    "                if contour_label:\n",
    "                    label_str += f\"0{contour_label}\\n\"\n",
    "                \n",
    "                # Draw test mask\n",
    "                if create_test_mask and test_mask is not None:\n",
    "                    parent_contour = np.expand_dims(parent_contour, axis=0)\n",
    "                    cv2.drawContours(test_mask, parent_contour, -1, 255, -1)\n",
    "        else:\n",
    "            # Single contour\n",
    "            contour_label = process_contour(contours[0], width, height)\n",
    "            if contour_label:\n",
    "                label_str += f\"0{contour_label}\\n\"\n",
    "            \n",
    "            if create_test_mask:\n",
    "                test_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "                cv2.drawContours(test_mask, [contours[0]], -1, 255, -1)\n",
    "        \n",
    "        label_str = label_str.rstrip()  # Remove last \\n\n",
    "        return label_str, test_mask, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return \"\", None, str(e)\n",
    "\n",
    "\n",
    "def process_contour(contour, width, height):\n",
    "    \"\"\"\n",
    "    Process a single contour and return normalized coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        contour: OpenCV contour array\n",
    "        width: Image width for normalization\n",
    "        height: Image height for normalization\n",
    "        \n",
    "    Returns:\n",
    "        str: Space-separated normalized coordinates string\n",
    "    \"\"\"\n",
    "    contour_squeezed = contour.squeeze()\n",
    "    \n",
    "    # Handle single point case\n",
    "    if contour_squeezed.ndim == 1:\n",
    "        return \"\"\n",
    "    \n",
    "    contour_list = contour_squeezed.tolist()\n",
    "    \n",
    "    if len(contour_list) < 3:\n",
    "        return \"\"\n",
    "    \n",
    "    # Filter valid points and normalize coordinates\n",
    "    contour_label = \"\"\n",
    "    for point in contour_list:\n",
    "        if isinstance(point, list) and len(point) == 2:\n",
    "            x_norm = round(float(point[0]) / float(width), 6)\n",
    "            y_norm = round(float(point[1]) / float(height), 6)\n",
    "            contour_label += f\" {x_norm} {y_norm}\"\n",
    "    \n",
    "    return contour_label\n",
    "\n",
    "\n",
    "def process_single_mask(args):\n",
    "    \"\"\"\n",
    "    Process a single mask file for multiprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "        args: Tuple containing (mask_path, yolo_output_path, test_output_path, create_test_masks)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, message)\n",
    "            - success: Boolean indicating if processing succeeded\n",
    "            - message: Success message with filename or error description\n",
    "    \"\"\"\n",
    "    mask_path, yolo_output_path, test_output_path, create_test_masks = args\n",
    "    \n",
    "    mask_filename = Path(mask_path).stem\n",
    "    \n",
    "    # Convert mask\n",
    "    label_str, test_mask, error = convert_mask_to_yolo_seg_label(mask_path, create_test_masks)\n",
    "    \n",
    "    if error:\n",
    "        return False, f\"Error processing {mask_filename}: {error}\"\n",
    "    \n",
    "    if not label_str:\n",
    "        return False, f\"No valid contours found in {mask_filename}\"\n",
    "    \n",
    "    # Save YOLO label\n",
    "    label_output_path = os.path.join(yolo_output_path, f\"{mask_filename}.txt\")\n",
    "    with open(label_output_path, 'w') as f:\n",
    "        f.write(label_str)\n",
    "    \n",
    "    # Save test mask if created\n",
    "    if create_test_masks and test_mask is not None:\n",
    "        test_mask_output_path = os.path.join(test_output_path, f\"{mask_filename}_test.png\")\n",
    "        cv2.imwrite(test_mask_output_path, test_mask)\n",
    "    \n",
    "    return True, mask_filename\n",
    "\n",
    "\n",
    "def batch_convert_masks_to_yolo(ANNOTATIONS_BINARY_PNG_PATH, \n",
    "                               YOLO_ANNOTATIONS_OUTPUT_PATH, \n",
    "                               TEST_MASK_OUTPUT_PATH,\n",
    "                               create_test_masks=True,\n",
    "                               num_workers=None,\n",
    "                               create_empty_labels=True):\n",
    "    \"\"\"\n",
    "    Convert all mask files to YOLO format using parallel processing.\n",
    "    \n",
    "    Efficiently processes large batches of binary mask files and converts\n",
    "    them to YOLO segmentation format with optional verification masks.\n",
    "    \n",
    "    Parameters:\n",
    "        ANNOTATIONS_BINARY_PNG_PATH: Input directory with mask files\n",
    "        YOLO_ANNOTATIONS_OUTPUT_PATH: Output directory for YOLO labels\n",
    "        TEST_MASK_OUTPUT_PATH: Output directory for test masks\n",
    "        create_test_masks: Whether to create test masks for verification\n",
    "        num_workers: Number of parallel workers (None = auto-detect)\n",
    "        create_empty_labels: Whether to create empty label files for images without valid contours\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all mask files\n",
    "    mask_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "    mask_files = []\n",
    "    \n",
    "    print(\"Searching for mask files...\")\n",
    "    for extension in mask_extensions:\n",
    "        pattern = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, extension)\n",
    "        mask_files.extend(glob.glob(pattern))\n",
    "    \n",
    "    if not mask_files:\n",
    "        print(f\"No mask files found in {ANNOTATIONS_BINARY_PNG_PATH}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(mask_files)} mask files to process...\")\n",
    "    \n",
    "    # Set up multiprocessing\n",
    "    if num_workers is None:\n",
    "        num_workers = min(multiprocessing.cpu_count(), len(mask_files))\n",
    "    \n",
    "    print(f\"Using {num_workers} workers for parallel processing...\")\n",
    "    \n",
    "    # Prepare arguments for multiprocessing\n",
    "    process_args = [\n",
    "        (mask_path, YOLO_ANNOTATIONS_OUTPUT_PATH, TEST_MASK_OUTPUT_PATH, create_test_masks)\n",
    "        for mask_path in mask_files\n",
    "    ]\n",
    "    \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    errors = []\n",
    "    failed_files = []  # Track files that failed\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all jobs at once\n",
    "        futures = {executor.submit(process_single_mask, args): args for args in process_args}\n",
    "        \n",
    "        # Use tqdm for progress tracking with as_completed for real-time updates\n",
    "        with tqdm(total=len(mask_files), desc=\"Converting masks\", unit=\"files\") as pbar:\n",
    "            # Process results as they complete\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    success, message = future.result()\n",
    "                    if success:\n",
    "                        processed_count += 1\n",
    "                        pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        errors.append(message)\n",
    "                        # Extract filename from error message for empty label creation\n",
    "                        if \"No valid contours found in\" in message:\n",
    "                            filename = message.split(\"No valid contours found in \")[-1]\n",
    "                            failed_files.append(filename)\n",
    "                        pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    errors.append(f\"Unexpected error: {str(e)}\")\n",
    "                    pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Create empty label files for images without valid contours\n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"\\nCreating empty label files for {len(failed_files)} images without valid contours...\")\n",
    "        empty_labels_created = 0\n",
    "        \n",
    "        for filename in failed_files:\n",
    "            empty_label_path = os.path.join(YOLO_ANNOTATIONS_OUTPUT_PATH, f\"{filename}.txt\")\n",
    "            try:\n",
    "                # Create empty label file\n",
    "                with open(empty_label_path, 'w') as f:\n",
    "                    pass  # Empty file\n",
    "                empty_labels_created += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create empty label for {filename}: {e}\")\n",
    "        \n",
    "        print(f\"Created {empty_labels_created} empty label files\")\n",
    "        processed_count += empty_labels_created  # Update count to include empty labels\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CONVERSION COMPLETED!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Successfully processed: {processed_count} files\")\n",
    "    print(f\"Errors: {error_count - len(failed_files) if create_empty_labels else error_count} files\")\n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"Empty labels created: {len(failed_files)} files (images without annotations)\")\n",
    "    print(f\"Success rate: {processed_count/(len(mask_files))*100:.1f}%\")\n",
    "    print(f\"YOLO labels saved to: {YOLO_ANNOTATIONS_OUTPUT_PATH}\")\n",
    "    if create_test_masks:\n",
    "        print(f\"Test masks saved to: {TEST_MASK_OUTPUT_PATH}\")\n",
    "    \n",
    "    # Show first few errors if any (excluding \"no contours\" if empty labels were created)\n",
    "    remaining_errors = [e for e in errors if not (create_empty_labels and \"No valid contours found in\" in e)]\n",
    "    if remaining_errors:\n",
    "        print(f\"\\nRemaining errors ({len(remaining_errors)}):\")\n",
    "        for error in remaining_errors[:5]:\n",
    "            print(f\"  - {error}\")\n",
    "        if len(remaining_errors) > 5:\n",
    "            print(f\"  ... and {len(remaining_errors) - 5} more errors\")\n",
    "    \n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"\\nNote: {len(failed_files)} images had no valid annotations and got empty label files.\")\n",
    "        print(\"This is normal for datasets where some images contain no objects of interest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_failed_masks(ANNOTATIONS_BINARY_PNG_PATH, failed_filenames, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze why specific masks failed to convert to YOLO format.\n",
    "    \n",
    "    Provides detailed analysis of failed mask conversions to help\n",
    "    diagnose issues with the mask files or conversion process.\n",
    "    \n",
    "    Parameters:\n",
    "        ANNOTATIONS_BINARY_PNG_PATH: Path to mask directory\n",
    "        failed_filenames: List of filenames that failed\n",
    "        sample_size: Number of files to analyze in detail\n",
    "    \"\"\"\n",
    "    if not failed_filenames:\n",
    "        print(\"No failed masks to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nAnalyzing {min(sample_size, len(failed_filenames))} failed masks...\")\n",
    "    \n",
    "    for i, filename in enumerate(failed_filenames[:sample_size]):\n",
    "        mask_path = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, f\"{filename}.png\")\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            # Try other extensions\n",
    "            for ext in ['.jpg', '.jpeg', '.bmp', '.tif', '.tiff']:\n",
    "                alt_path = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, f\"{filename}{ext}\")\n",
    "                if os.path.exists(alt_path):\n",
    "                    mask_path = alt_path\n",
    "                    break\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"  {filename}: File not found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read and analyze mask\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(f\"  {filename}: Could not read image\")\n",
    "                continue\n",
    "            \n",
    "            height, width = mask.shape\n",
    "            unique_values = np.unique(mask)\n",
    "            foreground_pixels = np.sum(mask > 0)\n",
    "            foreground_percentage = (foreground_pixels / (height * width)) * 100\n",
    "            \n",
    "            print(f\"  {filename}:\")\n",
    "            print(f\"    - Size: {width}x{height}\")\n",
    "            print(f\"    - Unique values: {unique_values}\")\n",
    "            print(f\"    - Foreground pixels: {foreground_pixels} ({foreground_percentage:.2f}%)\")\n",
    "            \n",
    "            if foreground_pixels == 0:\n",
    "                print(\"    - Issue: Completely empty mask (no annotations)\")\n",
    "            elif foreground_pixels < 10:\n",
    "                print(\"    - Issue: Very few foreground pixels (likely noise)\")\n",
    "            else:\n",
    "                # Check contours\n",
    "                _, thresh = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                if contours:\n",
    "                    contour_sizes = [len(c) for c in contours]\n",
    "                    print(f\"    - Contours found: {len(contours)}\")\n",
    "                    print(f\"    - Contour sizes: {contour_sizes}\")\n",
    "                    print(\"    - Issue: Contours too small (< 3 points) or invalid shape\")\n",
    "                else:\n",
    "                    print(\"    - Issue: No contours detected\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  {filename}: Error analyzing - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e49cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_BINARY_MASKS_TO_YOLO_FORMAT:\n",
    "    print(\"Converting binary masks to YOLO format...\")\n",
    "    batch_convert_masks_to_yolo(\n",
    "        ANNOTATIONS_BINARY_PNG_PATH=ANNOTATIONS_BINARY_PNG_PATH,\n",
    "        YOLO_ANNOTATIONS_OUTPUT_PATH=YOLO_ANNOTATIONS_OUTPUT_PATH,\n",
    "        TEST_MASK_OUTPUT_PATH=TEST_MASK_OUTPUT_PATH,\n",
    "        create_test_masks=True,\n",
    "        num_workers=16,\n",
    "        create_empty_labels=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10750b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below if you want to investigate the failed conversions\n",
    "# failed_files = [\n",
    "#     \"24991113_tile_1_3_14c592\", \"25001124_tile_18_16_c9d875\", \n",
    "#     \"24971118_tile_15_17_5212bb\", \"25001121_tile_16_12_6e2b70\", \n",
    "#     \"24921119_tile_4_17_b09eb4\"\n",
    "# ]\n",
    "# analyze_failed_masks(ANNOTATIONS_BINARY_PNG_PATH, failed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc8e0",
   "metadata": {},
   "source": [
    "## Dataset Splitting and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8140e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastYOLOAugmentationPipeline:\n",
    "    \"\"\"\n",
    "    Optimized data augmentation pipeline for YOLO segmentation datasets.\n",
    "    \n",
    "    Provides efficient augmentation of images and corresponding segmentation\n",
    "    masks with proper YOLO format conversion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, augmentation_pipeline=None, num_augmentations=10):\n",
    "        \"\"\"\n",
    "        Initialize augmentation pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "            augmentation_pipeline: Albumentations pipeline (uses default if None)\n",
    "            num_augmentations: Number of augmented versions per image\n",
    "        \"\"\"\n",
    "        import albumentations as A\n",
    "        \n",
    "        if augmentation_pipeline is None:\n",
    "            # Optimized pipeline - fewer heavy operations\n",
    "            self.aug_pipeline = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.3),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.4),\n",
    "                # Removed heavy operations like blur for speed\n",
    "            ], additional_targets={'mask': 'mask'})\n",
    "        else:\n",
    "            self.aug_pipeline = augmentation_pipeline\n",
    "            \n",
    "        self.num_augmentations = num_augmentations\n",
    "    \n",
    "    def yolo_label_to_mask_fast(self, label_path, img_width, img_height):\n",
    "        \"\"\"\n",
    "        Convert YOLO label to binary mask with optimized performance.\n",
    "        \n",
    "        Parameters:\n",
    "            label_path: Path to YOLO label file\n",
    "            img_width: Image width\n",
    "            img_height: Image height\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Binary mask array\n",
    "        \"\"\"\n",
    "        mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        \n",
    "        if not Path(label_path).exists() or Path(label_path).stat().st_size == 0:\n",
    "            return mask\n",
    "            \n",
    "        try:\n",
    "            with open(label_path, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "            \n",
    "            if not content:\n",
    "                return mask\n",
    "                \n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.split()\n",
    "                if len(parts) < 7:\n",
    "                    continue\n",
    "                \n",
    "                # Vectorized coordinate conversion\n",
    "                coords = np.array([float(x) for x in parts[1:]])\n",
    "                coords = coords.reshape(-1, 2)\n",
    "                \n",
    "                # Convert to pixel coordinates in one go\n",
    "                pixel_coords = coords * np.array([img_width, img_height])\n",
    "                pixel_coords = np.clip(pixel_coords, 0, [img_width-1, img_height-1]).astype(np.int32)\n",
    "                \n",
    "                if len(pixel_coords) >= 3:\n",
    "                    cv2.fillPoly(mask, [pixel_coords], 255)\n",
    "                    \n",
    "        except Exception:\n",
    "            pass  # Return empty mask on error\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def mask_to_yolo_label_fast(self, mask, img_width, img_height, class_id=0):\n",
    "        \"\"\"\n",
    "        Convert binary mask to YOLO label with optimized performance.\n",
    "        \n",
    "        Parameters:\n",
    "            mask: Binary mask array\n",
    "            img_width: Image width\n",
    "            img_height: Image height\n",
    "            class_id: Object class ID\n",
    "            \n",
    "        Returns:\n",
    "            str: YOLO format label string\n",
    "        \"\"\"\n",
    "        if mask.max() == 0:  # Empty mask\n",
    "            return \"\"\n",
    "            \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return \"\"\n",
    "        \n",
    "        label_lines = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Less aggressive simplification for speed\n",
    "            epsilon = 0.002 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            if len(approx) < 3 or cv2.contourArea(approx) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Vectorized coordinate normalization\n",
    "            points = approx.reshape(-1, 2)\n",
    "            normalized = points / np.array([img_width, img_height])\n",
    "            normalized = np.clip(normalized, 0, 1)\n",
    "            \n",
    "            if len(normalized) >= 3:\n",
    "                coords_str = ' '.join([f\"{coord:.6f}\" for coord in normalized.flatten()])\n",
    "                label_lines.append(f\"{class_id} {coords_str}\")\n",
    "        \n",
    "        return '\\n'.join(label_lines)\n",
    "    \n",
    "    def augment_single_image_batch(self, image_path, label_path, output_images_dir, output_labels_dir):\n",
    "        \"\"\"\n",
    "        Generate all augmentations for a single image.\n",
    "        \n",
    "        Parameters:\n",
    "            image_path: Path to source image\n",
    "            label_path: Path to source label\n",
    "            output_images_dir: Output directory for augmented images\n",
    "            output_labels_dir: Output directory for augmented labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (successful_count, failed_count, message)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image once\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                return 0, self.num_augmentations, f\"Could not load image: {image_path}\"\n",
    "            \n",
    "            img_height, img_width = image.shape[:2]\n",
    "            stem = Path(image_path).stem\n",
    "            \n",
    "            # Convert YOLO label to mask once\n",
    "            mask = self.yolo_label_to_mask_fast(label_path, img_width, img_height)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            # Create all augmentations in batch\n",
    "            for aug_idx in range(1, self.num_augmentations + 1):\n",
    "                try:\n",
    "                    # Apply augmentation\n",
    "                    augmented = self.aug_pipeline(image=image, mask=mask)\n",
    "                    aug_image = augmented['image']\n",
    "                    aug_mask = augmented['mask']\n",
    "                    \n",
    "                    # Save files\n",
    "                    aug_image_name = f\"{stem}_aug{aug_idx}.png\"\n",
    "                    aug_label_name = f\"{stem}_aug{aug_idx}.txt\"\n",
    "                    \n",
    "                    aug_image_path = output_images_dir / aug_image_name\n",
    "                    aug_label_path = output_labels_dir / aug_label_name\n",
    "                    \n",
    "                    # Faster image saving\n",
    "                    cv2.imwrite(str(aug_image_path), aug_image, [cv2.IMWRITE_PNG_COMPRESSION, 1])\n",
    "                    \n",
    "                    # Convert and save label\n",
    "                    yolo_label = self.mask_to_yolo_label_fast(aug_mask, img_width, img_height)\n",
    "                    with open(aug_label_path, 'w') as f:\n",
    "                        f.write(yolo_label)\n",
    "                    \n",
    "                    successful += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    failed += 1\n",
    "                    if failed <= 2:  # Limit error messages\n",
    "                        logger.warning(f\"Aug {aug_idx} failed for {stem}: {e}\")\n",
    "            \n",
    "            return successful, failed, f\"Processed {stem}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0, self.num_augmentations, f\"Error processing {Path(image_path).name}: {e}\"\n",
    "    \n",
    "    def augment_dataset_folder_fast(self, images_dir, labels_dir, output_images_dir, output_labels_dir, \n",
    "                                   num_workers=None, use_threads=True):\n",
    "        \"\"\"\n",
    "        Apply augmentation to entire dataset folder with parallel processing.\n",
    "        \n",
    "        Parameters:\n",
    "            images_dir: Source images directory\n",
    "            labels_dir: Source labels directory\n",
    "            output_images_dir: Output images directory\n",
    "            output_labels_dir: Output labels directory\n",
    "            num_workers: Number of parallel workers\n",
    "            use_threads: Use ThreadPoolExecutor if True, ProcessPoolExecutor if False\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (total_successful, total_failed)\n",
    "        \"\"\"\n",
    "        images_dir = Path(images_dir)\n",
    "        labels_dir = Path(labels_dir)\n",
    "        output_images_dir = Path(output_images_dir)\n",
    "        output_labels_dir = Path(output_labels_dir)\n",
    "        \n",
    "        # Find all images\n",
    "        image_files = []\n",
    "        for ext in ['*.png', '*.jpg', '*.jpeg', '*.tif']:\n",
    "            image_files.extend(images_dir.glob(ext))\n",
    "        \n",
    "        if not image_files:\n",
    "            logger.warning(f\"No images found in {images_dir}\")\n",
    "            return 0, 0\n",
    "        \n",
    "        logger.info(f\"Found {len(image_files)} images to augment\")\n",
    "        logger.info(f\"Creating {self.num_augmentations} versions each = {len(image_files) * self.num_augmentations} total\")\n",
    "        \n",
    "        # Set optimal number of workers\n",
    "        if num_workers is None:\n",
    "            num_workers = min(multiprocessing.cpu_count(), len(image_files), 8)\n",
    "        \n",
    "        total_successful = 0\n",
    "        total_failed = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if use_threads and len(image_files) > 1:\n",
    "            # Use ThreadPoolExecutor for I/O-bound operations\n",
    "            logger.info(f\"Using {num_workers} threads for parallel augmentation\")\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                # Submit all tasks\n",
    "                future_to_image = {}\n",
    "                for image_path in image_files:\n",
    "                    label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                    future = executor.submit(\n",
    "                        self.augment_single_image_batch,\n",
    "                        image_path, label_path, output_images_dir, output_labels_dir\n",
    "                    )\n",
    "                    future_to_image[future] = image_path\n",
    "                \n",
    "                # Process results with progress bar\n",
    "                with tqdm(total=len(image_files), desc=\"Augmenting images (threaded)\") as pbar:\n",
    "                    for future in as_completed(future_to_image):\n",
    "                        try:\n",
    "                            successful, failed, message = future.result(timeout=60)\n",
    "                            total_successful += successful\n",
    "                            total_failed += failed\n",
    "                            pbar.update(1)\n",
    "                            pbar.set_postfix({\n",
    "                                \"Success\": total_successful, \n",
    "                                \"Failed\": total_failed,\n",
    "                                \"Rate\": f\"{total_successful/(time.time()-start_time):.1f}/s\"\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            total_failed += self.num_augmentations\n",
    "                            logger.error(f\"Task failed: {e}\")\n",
    "                            pbar.update(1)\n",
    "        \n",
    "        else:\n",
    "            # Fallback to sequential processing\n",
    "            logger.info(\"Using sequential processing\")\n",
    "            \n",
    "            for image_path in tqdm(image_files, desc=\"Augmenting images (sequential)\"):\n",
    "                label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                successful, failed, message = self.augment_single_image_batch(\n",
    "                    image_path, label_path, output_images_dir, output_labels_dir\n",
    "                )\n",
    "                total_successful += successful\n",
    "                total_failed += failed\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        rate = total_successful / duration if duration > 0 else 0\n",
    "        \n",
    "        logger.info(f\"Augmentation completed in {duration:.1f}s\")\n",
    "        logger.info(f\"Rate: {rate:.1f} augmentations/second\")\n",
    "        logger.info(f\"Results: {total_successful} successful, {total_failed} failed\")\n",
    "        \n",
    "        return total_successful, total_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f550d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_list(txt_path):\n",
    "    \"\"\"\n",
    "    Read image filenames from text file.\n",
    "    \n",
    "    Parameters:\n",
    "        txt_path: Path to text file containing image filenames\n",
    "        \n",
    "    Returns:\n",
    "        list: List of image filenames\n",
    "    \"\"\"\n",
    "    with open(txt_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def get_image_name_without_ext(filename):\n",
    "    \"\"\"\n",
    "    Extract image name without extension.\n",
    "    \n",
    "    Parameters:\n",
    "        filename: Image filename\n",
    "        \n",
    "    Returns:\n",
    "        str: Filename without extension\n",
    "    \"\"\"\n",
    "    return Path(filename).stem\n",
    "\n",
    "def create_directory_structure(base_path):\n",
    "    \"\"\"\n",
    "    Create YOLO dataset directory structure.\n",
    "    \n",
    "    Creates train/val/test directories with images and labels subdirectories.\n",
    "    \n",
    "    Parameters:\n",
    "        base_path: Base directory path\n",
    "    \"\"\"\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for subdir in ['images', 'labels']:\n",
    "            dir_path = Path(base_path) / split / subdir\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def convert_tiff_to_png(tiff_path, png_path, quality=95):\n",
    "    \"\"\"\n",
    "    Convert TIFF image to high-quality PNG.\n",
    "    \n",
    "    Parameters:\n",
    "        tiff_path: Path to TIFF file\n",
    "        png_path: Output path for PNG file\n",
    "        quality: PNG compression quality\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if conversion successful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(tiff_path) as img:\n",
    "            # Convert to RGB if needed (TIFF might be in different color modes)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save as PNG with high quality\n",
    "            img.save(png_path, 'PNG', optimize=True, compress_level=1)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to convert {tiff_path} to {png_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def copy_label_file(source_labels_dir, target_labels_dir, image_filename):\n",
    "    \"\"\"\n",
    "    Copy corresponding label file for an image.\n",
    "    \n",
    "    Parameters:\n",
    "        source_labels_dir: Source labels directory\n",
    "        target_labels_dir: Target labels directory\n",
    "        image_filename: Image filename to find corresponding label\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if copy successful\n",
    "    \"\"\"\n",
    "    # Get image name without extension\n",
    "    image_name = get_image_name_without_ext(image_filename)\n",
    "    \n",
    "    # YOLO labels have exact same name as images (just .txt extension)\n",
    "    label_filename = f\"{image_name}.txt\"\n",
    "    \n",
    "    source_label = Path(source_labels_dir) / label_filename\n",
    "    target_label = Path(target_labels_dir) / label_filename\n",
    "    \n",
    "    if source_label.exists():\n",
    "        shutil.copy2(source_label, target_label)\n",
    "        return True\n",
    "    else:\n",
    "        logger.warning(f\"Label file not found: {source_label}\")\n",
    "        return False\n",
    "\n",
    "def validate_setup():\n",
    "    \"\"\"\n",
    "    Validate dataset paths and configuration.\n",
    "    \n",
    "    Checks that all required paths exist and files are accessible\n",
    "    before starting dataset creation.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if validation passes\n",
    "    \"\"\"\n",
    "    logger.info(\"Validating setup for YOLO dataset creation...\")\n",
    "    \n",
    "    all_good = True\n",
    "    \n",
    "    # Check original dataset path for reference\n",
    "    if not Path(DATASET_PATH).exists():\n",
    "        logger.warning(f\"Original dataset path does not exist: {DATASET_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        logger.success(f\"Original dataset path exists: {DATASET_PATH}\")\n",
    "    \n",
    "    # Check YOLO labels directory (main requirement)\n",
    "    yolo_labels_dir = Path(YOLO_ANNOTATIONS_OUTPUT_PATH)\n",
    "    if not yolo_labels_dir.exists():\n",
    "        logger.error(f\"YOLO labels directory does not exist: {yolo_labels_dir}\")\n",
    "        logger.error(\"Please run the binary mask to YOLO conversion first!\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        label_count = len(list(yolo_labels_dir.glob(\"*.txt\")))\n",
    "        logger.success(f\"YOLO labels directory exists: {yolo_labels_dir} ({label_count} label files)\")\n",
    "    \n",
    "    # Check image path\n",
    "    if not Path(IMG_DATASET_PATH).exists():\n",
    "        logger.warning(f\"Image dataset path does not exist: {IMG_DATASET_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        image_count = len(list(Path(IMG_DATASET_PATH).glob(\"*.tif\")))  # Fixed: only .tif\n",
    "        logger.success(f\"Image dataset path exists: {IMG_DATASET_PATH} ({image_count} image files)\")\n",
    "    \n",
    "    # Check/create processed output path\n",
    "    if not Path(CREATE_DATASET_PROCESSED_PATH).exists():\n",
    "        logger.info(f\"Creating processed dataset directory: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "        Path(CREATE_DATASET_PROCESSED_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        logger.success(f\"Processed dataset path exists: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "    \n",
    "    # Check fold txt files\n",
    "    total_fold_images = 0\n",
    "    for fold_num, txt_path in FOLD_PATHS.items():\n",
    "        if not Path(txt_path).exists():\n",
    "            logger.warning(f\"Fold {fold_num} txt file does not exist: {txt_path}\")\n",
    "            all_good = False\n",
    "        else:\n",
    "            images = read_image_list(txt_path)\n",
    "            total_fold_images += len(images)\n",
    "            logger.success(f\"Fold {fold_num}: {len(images)} images\")\n",
    "    \n",
    "    # Check test file\n",
    "    if not Path(TEST_DATASET_TXT_PATH).exists():\n",
    "        logger.warning(f\"Test dataset txt file does not exist: {TEST_DATASET_TXT_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        test_images = read_image_list(TEST_DATASET_TXT_PATH)\n",
    "        logger.success(f\"Test set: {len(test_images)} images\")\n",
    "        logger.info(f\"Total dataset size: {total_fold_images + len(test_images)} images\")\n",
    "    \n",
    "    # Validate that images and labels match (critical check)\n",
    "    if Path(YOLO_ANNOTATIONS_OUTPUT_PATH).exists() and FOLD_PATHS.get(0) and Path(FOLD_PATHS[0]).exists():\n",
    "        logger.info(\"Validating image-label correspondence...\")\n",
    "        \n",
    "        sample_images = read_image_list(FOLD_PATHS[0])[:10]  # Check first 10 images\n",
    "        missing_labels = []\n",
    "        missing_images = []\n",
    "        \n",
    "        for image_filename in sample_images:\n",
    "            image_name = get_image_name_without_ext(image_filename)\n",
    "            \n",
    "            # Check label exists\n",
    "            label_file = Path(YOLO_ANNOTATIONS_OUTPUT_PATH) / f\"{image_name}.txt\"\n",
    "            if not label_file.exists():\n",
    "                missing_labels.append(f\"{image_name}.txt\")\n",
    "            \n",
    "            # Check image exists (only .tif)\n",
    "            tif_file = Path(IMG_DATASET_PATH) / f\"{image_name}.tif\"\n",
    "            if not tif_file.exists():\n",
    "                missing_images.append(f\"{image_name}.tif\")\n",
    "        \n",
    "        if missing_labels:\n",
    "            logger.error(f\"Missing label files: {missing_labels}\")\n",
    "            all_good = False\n",
    "        \n",
    "        if missing_images:\n",
    "            logger.error(f\"Missing image files: {missing_images}\")\n",
    "            all_good = False\n",
    "        \n",
    "        if not missing_labels and not missing_images:\n",
    "            logger.success(\"Image-label correspondence validation passed!\")\n",
    "    \n",
    "    # Summary\n",
    "    if all_good:\n",
    "        logger.success(\"All validations passed! Ready to create cross-validation datasets.\")\n",
    "        logger.info(f\"Output will be saved to: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "    else:\n",
    "        logger.error(\"Setup validation failed. Please fix the issues above before proceeding.\")\n",
    "    \n",
    "    return all_good\n",
    "\n",
    "def process_image_list(image_list, split_name, target_base_dir):\n",
    "    \"\"\"\n",
    "    Process a list of images for a specific dataset split.\n",
    "    \n",
    "    Converts TIFF images to PNG and copies corresponding labels.\n",
    "    \n",
    "    Parameters:\n",
    "        image_list: List of image filenames\n",
    "        split_name: Split name (train/val/test)\n",
    "        target_base_dir: Target base directory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (successful_copies, failed_copies)\n",
    "    \"\"\"\n",
    "    # Use YOLO labels directory\n",
    "    source_labels_dir = Path(YOLO_ANNOTATIONS_OUTPUT_PATH)\n",
    "    target_images_dir = Path(target_base_dir) / split_name / \"images\"\n",
    "    target_labels_dir = Path(target_base_dir) / split_name / \"labels\"\n",
    "    \n",
    "    successful_copies = 0\n",
    "    failed_copies = 0\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for image_filename in tqdm(image_list, desc=f\"Processing {split_name}\", leave=False):\n",
    "        image_name = get_image_name_without_ext(image_filename)\n",
    "        \n",
    "        # Source TIF image path (only .tif extension)\n",
    "        source_tif = Path(IMG_DATASET_PATH) / f\"{image_name}.tif\"\n",
    "        \n",
    "        # Target PNG image path\n",
    "        target_png = target_images_dir / f\"{image_name}.png\"\n",
    "        \n",
    "        # Convert TIF to PNG and copy label\n",
    "        if source_tif.exists():\n",
    "            if convert_tiff_to_png(source_tif, target_png):\n",
    "                # Copy corresponding label file\n",
    "                if copy_label_file(source_labels_dir, target_labels_dir, image_filename):\n",
    "                    successful_copies += 1\n",
    "                else:\n",
    "                    failed_copies += 1\n",
    "            else:\n",
    "                failed_copies += 1\n",
    "        else:\n",
    "            logger.warning(f\"Source image not found: {image_name}.tif\")\n",
    "            failed_copies += 1\n",
    "    \n",
    "    logger.info(f\"{split_name}: {successful_copies} successful, {failed_copies} failed\")\n",
    "    return successful_copies, failed_copies\n",
    "\n",
    "def create_single_fold_dataset(val_fold, fold_data, test_data):\n",
    "    \"\"\"\n",
    "    Create a single cross-validation dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        val_fold: Validation fold number\n",
    "        fold_data: Dictionary of fold data\n",
    "        test_data: List of test images\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (total_success, total_fail)\n",
    "    \"\"\"\n",
    "    dataset_name = f\"fold_{val_fold}_dataset\"\n",
    "    # Use the updated CREATE_DATASET_PROCESSED_PATH for output\n",
    "    dataset_path = Path(CREATE_DATASET_PROCESSED_PATH) / dataset_name\n",
    "    \n",
    "    logger.info(f\"Creating {dataset_name}\")\n",
    "    \n",
    "    # Create directory structure\n",
    "    create_directory_structure(dataset_path)\n",
    "    \n",
    "    # Validation data: current fold\n",
    "    val_data = fold_data[val_fold]\n",
    "    \n",
    "    # Training data: all other folds\n",
    "    train_data = []\n",
    "    for fold_num, images in fold_data.items():\n",
    "        if fold_num != val_fold:\n",
    "            train_data.extend(images)\n",
    "    \n",
    "    logger.info(f\"Training: {len(train_data)} images\")\n",
    "    logger.info(f\"Validation: {len(val_data)} images\")\n",
    "    logger.info(f\"Test: {len(test_data)} images\")\n",
    "    \n",
    "    # Process each split\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_success, train_fail = process_image_list(train_data, \"train\", dataset_path)\n",
    "    val_success, val_fail = process_image_list(val_data, \"val\", dataset_path)\n",
    "    test_success, test_fail = process_image_list(test_data, \"test\", dataset_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    total_success = train_success + val_success + test_success\n",
    "    total_fail = train_fail + val_fail + test_fail\n",
    "    \n",
    "    logger.success(f\"{dataset_name} completed in {duration:.1f}s\")\n",
    "    logger.success(f\"Total: {total_success} successful, {total_fail} failed\")\n",
    "    \n",
    "    return total_success, total_fail\n",
    "\n",
    "def create_single_fold_dataset_with_augmentation_fast(val_fold, fold_data, test_data):\n",
    "    \"\"\"\n",
    "    Create dataset with optimized augmentation pipeline.\n",
    "    \n",
    "    Creates base dataset then applies augmentation to training set.\n",
    "    \n",
    "    Parameters:\n",
    "        val_fold: Validation fold number\n",
    "        fold_data: Dictionary of fold data\n",
    "        test_data: List of test images\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (total_success, total_fail)\n",
    "    \"\"\"\n",
    "    # First create normal dataset\n",
    "    total_success, total_fail = create_single_fold_dataset(val_fold, fold_data, test_data)\n",
    "    \n",
    "    # Then apply augmentation if enabled\n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.info(f\"Applying FAST augmentation to fold {val_fold} training set...\")\n",
    "        \n",
    "        dataset_path = Path(CREATE_DATASET_PROCESSED_PATH) / f\"fold_{val_fold}_dataset\"\n",
    "        train_images_dir = dataset_path / \"train\" / \"images\"\n",
    "        train_labels_dir = dataset_path / \"train\" / \"labels\"\n",
    "        \n",
    "        if train_images_dir.exists() and train_labels_dir.exists():\n",
    "            # Count original images\n",
    "            original_count = len(list(train_images_dir.glob(\"*.png\")))\n",
    "            logger.info(f\"  Original training images: {original_count}\")\n",
    "            \n",
    "            # Initialize fast augmenter\n",
    "            augmenter = FastYOLOAugmentationPipeline(\n",
    "                augmentation_pipeline=AUGMENTATION_PIPELINE,\n",
    "                num_augmentations=NUM_AUGMENTATIONS_PER_IMAGE\n",
    "            )\n",
    "            \n",
    "            # Apply fast augmentation\n",
    "            start_time = time.time()\n",
    "            aug_success, aug_fail = augmenter.augment_dataset_folder_fast(\n",
    "                images_dir=train_images_dir,\n",
    "                labels_dir=train_labels_dir,\n",
    "                output_images_dir=train_images_dir,  # In-place\n",
    "                output_labels_dir=train_labels_dir,  # In-place\n",
    "                num_workers=AUGMENTATION_WORKERS,\n",
    "                use_threads=True  # Set to False for CPU-intensive augmentations\n",
    "            )\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            final_count = len(list(train_images_dir.glob(\"*.png\")))\n",
    "            \n",
    "            logger.success(f\"Fold {val_fold} augmentation completed in {duration:.1f}s:\")\n",
    "            logger.success(f\"  Created: {aug_success} augmented images\")\n",
    "            logger.success(f\"  Failed: {aug_fail} augmentations\")\n",
    "            logger.success(f\"  Final training set: {final_count} images ({original_count}  {final_count})\")\n",
    "            \n",
    "            total_success += aug_success\n",
    "            total_fail += aug_fail\n",
    "        else:\n",
    "            logger.warning(f\"Training directories not found for fold {val_fold}\")\n",
    "    \n",
    "    return total_success, total_fail\n",
    "\n",
    "def create_cross_validation_datasets(APPLY_AUGMENTATION):\n",
    "    \"\"\"\n",
    "    Create all cross-validation datasets with optional augmentation.\n",
    "    \n",
    "    Generates 5-fold cross-validation split with proper train/val/test\n",
    "    separation and optional data augmentation.\n",
    "    \n",
    "    Parameters:\n",
    "        APPLY_AUGMENTATION: Whether to apply augmentation to training sets\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (total_success, total_fail)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not SPLIT_DATASET:\n",
    "        logger.warning(\"Dataset creation is disabled. Set SPLIT_DATASET = True to enable.\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Starting cross-validation dataset creation...\")\n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.info(\"Augmentation is ENABLED - will augment training sets\")\n",
    "        logger.info(f\"Augmentations per image: {NUM_AUGMENTATIONS_PER_IMAGE}\")\n",
    "    else:\n",
    "        logger.info(\"Augmentation is DISABLED\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read all fold datasets\n",
    "    fold_data = {}\n",
    "    for fold_num, txt_path in FOLD_PATHS.items():\n",
    "        fold_data[fold_num] = read_image_list(txt_path)\n",
    "        logger.info(f\"Fold {fold_num}: {len(fold_data[fold_num])} images\")\n",
    "    \n",
    "    # Read test dataset\n",
    "    test_data = read_image_list(TEST_DATASET_TXT_PATH)\n",
    "    logger.info(f\"Test set: {len(test_data)} images\")\n",
    "    \n",
    "    # Create 5 cross-validation datasets\n",
    "    total_success = 0\n",
    "    total_fail = 0\n",
    "    \n",
    "    for val_fold in range(5):\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"PROCESSING FOLD {val_fold}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        if APPLY_AUGMENTATION:\n",
    "            logger.info(f\"Creating dataset for fold {val_fold} WITH augmentation...\")\n",
    "            success, fail = create_single_fold_dataset_with_augmentation_fast(val_fold, fold_data, test_data)\n",
    "        else:\n",
    "            logger.info(f\"Creating dataset for fold {val_fold} WITHOUT augmentation...\")\n",
    "            success, fail = create_single_fold_dataset(val_fold, fold_data, test_data)\n",
    "        \n",
    "        total_success += success\n",
    "        total_fail += fail\n",
    "        \n",
    "        logger.info(f\"Fold {val_fold} completed: {success} successful, {fail} failed\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_duration = end_time - start_time\n",
    "    \n",
    "    logger.success(\"\\n\" + \"=\"*60)\n",
    "    logger.success(\"ALL CROSS-VALIDATION DATASETS COMPLETED!\")\n",
    "    logger.success(\"=\"*60)\n",
    "    logger.success(f\"Total time: {total_duration/60:.1f} minutes\")\n",
    "    logger.success(f\"Overall: {total_success} successful, {total_fail} failed\")\n",
    "    \n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.success(f\"Augmentation applied to all training sets with {NUM_AUGMENTATIONS_PER_IMAGE} versions per image\")\n",
    "    \n",
    "    return total_success, total_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_DATASET:\n",
    "    if validate_setup():\n",
    "        # Create cross-validation datasets\n",
    "        create_cross_validation_datasets(APPLY_AUGMENTATION=APPLY_AUGMENTATION)\n",
    "    else:\n",
    "        logger.error(\"Setup validation failed. Please fix the issues before proceeding.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
