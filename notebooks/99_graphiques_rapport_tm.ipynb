{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diviser dataset annoté en train/val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from cairosvg import svg2png\n",
    "from IPython.display import display, SVG\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "GRAPHICS_BASE_PATH = \"data/notebook_99/graphics\"\n",
    "GRAPHICS_PATH = os.path.join(GRAPHICS_BASE_PATH, todays_date)\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "\n",
    "TILE_1024_FOLDER_PATH = \"data/notebook_04/geotiff/tile_1024_split\"\n",
    "GEOTIFF_ORTHO2019_PATH = \"data/SITG/ortho2019\"\n",
    "\n",
    "#------------------------------------\n",
    "# Noms des images\n",
    "# -----------------------------------\n",
    "\n",
    "# Schéma principal machine learning supervisé\n",
    "ML_WORKFLOW_PNG = \"01_ML_workflow.png\"\n",
    "\n",
    "# Classification\n",
    "CLASSIFICATION_WORKFLOW_PNG = \"ch3_piste_exploree_classification_01_workflow.png\"\n",
    "\n",
    "# ETL données\n",
    "ETL_WORKFLOW_PNG = \"ch3_preparation_donnees_01_etl.png\"\n",
    "\n",
    "# orthophotos \n",
    "ETL_ORTHOPHOTOS_PNG = \"ch3_preparation_donnees_orthophotos_01_etl.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG = \"ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG = \"ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_03_PNG = \"ch3_preparation_donnees_orthophotos_04_exemple_decoupe_orthophoto3.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_04_PNG = \"ch3_preparation_donnees_orthophotos_05_exemple_decoupe_orthophoto4.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_05_PNG = \"ch3_preparation_donnees_orthophotos_06_exemple_decoupe_orthophoto5.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_06_PNG = \"ch3_preparation_donnees_orthophotos_07_exemple_decoupe_orthophoto6.png\"\n",
    "\n",
    "# post-traitement dataset\n",
    "POST_TREATMENT_DATASET_01_OVERVIEW_PNG = \"ch3_postprocessing_dataset_03_overview.png\"\n",
    "\n",
    "# entrainement modèle\n",
    "ARCHITECTURE_SIZE_DECODER_PNG = \"ch36_architecture_02_architecture_taille_decodeur.png\"\n",
    "BACKBONE_SIZE_ENCODER_FAMILY_PNG = \"ch36_architecture_03_backbone_taille_encodeur_famille.png\"\n",
    "BACKBONE_SIZE_ENCODER_ORDER_PNG = \"ch36_architecture_04_backbone_taille_encodeur_ordonnee.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_svg_as_png(svg_content, filename, dpi=2400, scale=4.0):\n",
    "    \"\"\"\n",
    "    Convert SVG content to a high-resolution PNG file.\n",
    "\n",
    "    Args:\n",
    "        svg_content (str): SVG content as a string.\n",
    "        filename (str): Output filename for the PNG file.\n",
    "        dpi (int): Output resolution in dots per inch.\n",
    "        scale (float): Additional scaling factor for the output image.\n",
    "    \"\"\"\n",
    "    # Try to extract width and height from the SVG string\n",
    "    width_match = re.search(r'width=\"([^\"]*)\"', svg_content)\n",
    "    height_match = re.search(r'height=\"([^\"]*)\"', svg_content)\n",
    "\n",
    "    if width_match and height_match:\n",
    "        # Remove units and convert to float\n",
    "        width = float(re.sub(r'[^\\d.]', '', width_match.group(1)))\n",
    "        height = float(re.sub(r'[^\\d.]', '', height_match.group(1)))\n",
    "\n",
    "        # Calculate output dimensions using scale\n",
    "        output_width = int(width * scale)\n",
    "        output_height = int(height * scale)\n",
    "\n",
    "        # Convert SVG to PNG with specified dimensions and DPI\n",
    "        svg2png(\n",
    "            bytestring=svg_content.encode('utf-8'),\n",
    "            write_to=filename,\n",
    "            output_width=output_width,\n",
    "            output_height=output_height,\n",
    "            dpi=dpi\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: Could not determine SVG width and height. Using default scale and DPI.\")\n",
    "        # Fallback: use scale and DPI only\n",
    "        svg2png(\n",
    "            bytestring=svg_content.encode('utf-8'),\n",
    "            write_to=filename,\n",
    "            scale=scale,\n",
    "            dpi=dpi\n",
    "        )\n",
    "\n",
    "    # Display the SVG in the notebook\n",
    "    display(SVG(svg_content))\n",
    "\n",
    "    print(f\"High-resolution PNG saved to {filename} (DPI: {dpi}, Scale: {scale}x)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_high_quality_kroki(img_obj, filename):\n",
    "    \"\"\"\n",
    "    Save an IPython Image object (such as from kroki diagrams) to a file.\n",
    "\n",
    "    Args:\n",
    "        img_obj: IPython Image object containing PNG data.\n",
    "        filename (str): Path to save the PNG file.\n",
    "    \"\"\"\n",
    "    # Attempt to extract binary PNG data from the image object\n",
    "    binary_data = None\n",
    "\n",
    "    if hasattr(img_obj, 'data') and img_obj.data:\n",
    "        binary_data = img_obj.data\n",
    "    elif hasattr(img_obj, '_repr_png_') and img_obj._repr_png_():\n",
    "        binary_data = img_obj._repr_png_()\n",
    "    elif hasattr(img_obj, '_data') and img_obj._data:\n",
    "        binary_data = img_obj._data\n",
    "    else:\n",
    "        # Fallback: search for any attribute containing binary data\n",
    "        for attr_name in dir(img_obj):\n",
    "            if not attr_name.startswith('__'):\n",
    "                attr_value = getattr(img_obj, attr_name)\n",
    "                if isinstance(attr_value, bytes) and len(attr_value) > 1000:\n",
    "                    binary_data = attr_value\n",
    "                    break\n",
    "\n",
    "    if binary_data:\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(binary_data)\n",
    "\n",
    "        file_size = os.path.getsize(filename)\n",
    "\n",
    "        # Format file size for display\n",
    "        if file_size < 1024:\n",
    "            size_str = f\"{file_size} B\"\n",
    "        elif file_size < 1024**2:\n",
    "            size_str = f\"{file_size/1024:.1f} KB\"\n",
    "        elif file_size < 1024**3:\n",
    "            size_str = f\"{file_size/(1024**2):.1f} MB\"\n",
    "        else:\n",
    "            size_str = f\"{file_size/(1024**3):.1f} GB\"\n",
    "\n",
    "        # Attempt to get image dimensions\n",
    "        try:\n",
    "            from PIL import Image\n",
    "            with Image.open(filename) as img:\n",
    "                width, height = img.size\n",
    "                dimensions = f\"{width}x{height}\"\n",
    "        except ImportError:\n",
    "            dimensions = \"dimensions unknown (PIL not available)\"\n",
    "        except Exception:\n",
    "            dimensions = \"dimensions unknown\"\n",
    "\n",
    "        print(f\"PNG saved: {filename} ({size_str}, {dimensions})\")\n",
    "    else:\n",
    "        available_attrs = [attr for attr in dir(img_obj) if not attr.startswith('__')]\n",
    "        print(f\"No binary data found. Available attributes: {available_attrs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schéma machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "digraph MLWorkflow {\n",
    "    rankdir=TB;\n",
    "    ranksep=\"0.5 equally\";\n",
    "    nodesep=0.5;\n",
    "    dpi=300;\n",
    "    \n",
    "    graph [splines=ortho];\n",
    "    edge [color=\"#2E86AB\", penwidth=1.5, arrowsize=0.6];\n",
    "    \n",
    "    // Define base style\n",
    "    node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=11,\n",
    "          height=0.65, width=1.5, fixedsize=true];\n",
    "    \n",
    "    // Planning style - Blue theme\n",
    "    A [label=<<FONT POINT-SIZE=\"14\">①</FONT><BR/>Définition de la tâche>, \n",
    "       fillcolor=\"#e3f2fd\", color=\"#1976d2\", penwidth=1];\n",
    "    B [label=<<FONT POINT-SIZE=\"14\">②</FONT><BR/>Choix algorithme>, \n",
    "       fillcolor=\"#e3f2fd\", color=\"#1976d2\", penwidth=1];\n",
    "    \n",
    "    // Data preparation style - Green theme\n",
    "    C [label=<<FONT POINT-SIZE=\"14\">③</FONT><BR/>Sélection données>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    D [label=<<FONT POINT-SIZE=\"14\">④</FONT><BR/>Labellisation>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    E [label=<<FONT POINT-SIZE=\"14\">⑤</FONT><BR/>Datasets>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    \n",
    "    // Training style - Orange theme\n",
    "    F [label=<<FONT POINT-SIZE=\"14\">⑥</FONT><BR/>Entraînement>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    G [label=<<FONT POINT-SIZE=\"14\">⑦</FONT><BR/>Validation>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    H [label=<<FONT POINT-SIZE=\"14\">⑧</FONT><BR/>Test>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    \n",
    "    // Production style - Purple theme\n",
    "    I [label=<<FONT POINT-SIZE=\"14\">⑨</FONT><BR/>Production>, \n",
    "       fillcolor=\"#f3e5f5\", color=\"#7b1fa2\", penwidth=2];\n",
    "    \n",
    "    // Control horizontal positioning\n",
    "    {rank=same; A, B}\n",
    "    B -> A [dir=back];\n",
    "    \n",
    "    {rank=same; C, D, E}\n",
    "    C -> D -> E;\n",
    "    \n",
    "    {rank=same; H, G, F}\n",
    "    H -> G -> F [dir=back];\n",
    "    \n",
    "    {rank=same; I}\n",
    "    \n",
    "    // Workflow edges\n",
    "    B -> C [weight=1];\n",
    "    E -> F [weight=1];\n",
    "    H -> I [label=\" OK\", fontsize=10, fontcolor=\"darkgreen\"];\n",
    "    \n",
    "    // Feedback loop\n",
    "    H -> C [style=\"dashed\", color=\"red\", constraint=false, \n",
    "            taillabel=\"KO \", fontsize=10, fontcolor=\"red\"];\n",
    "    H -> F [style=\"dashed\", color=\"red\", constraint=false, \n",
    "            taillabel=\"KO \", fontsize=10, fontcolor=\"red\"];\n",
    "}\n",
    "'''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# write to file\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, ML_WORKFLOW_PNG))\n",
    "\n",
    "# display(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph RoofClassification {\n",
    "        rankdir=TB;\n",
    "        bgcolor=transparent;\n",
    "        fontname=\"Arial\";\n",
    "        pad=\"1.0\";\n",
    "        nodesep=\"0.2\";        // Reduced from 1.0 to 0.3 (less horizontal spacing)\n",
    "        ranksep=\"0.4\";        // Reduced from 0.8 to 0.6 (tighter vertical spacing)\n",
    "        ratio=compress;\n",
    "        dpi=300;\n",
    "        size=\"8,12!\";         // Limit width to 8 inches, height to 12 inches\n",
    "        \n",
    "        // Base node style - auto-sized to content with larger font\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=14,\n",
    "              margin=\"0.15\"];  // Increased fontsize from 10 to 14\n",
    "        \n",
    "        // Edge style with larger font for labels\n",
    "        edge [color=\"#2E86AB\", penwidth=1.5, arrowsize=0.6, fontsize=12];\n",
    "        \n",
    "        // Subgraph for classification section\n",
    "        subgraph cluster_1 {\n",
    "            label=\"2. Classification des Toitures\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            margin=20;\n",
    "            fontsize=16;        // Increased cluster title font size\n",
    "            fontname=\"Arial\";\n",
    "            \n",
    "            // Process nodes - Green theme\n",
    "            classify_start [label=\"Classification\\\\nToitures\", \n",
    "                          fillcolor=\"#F1F8E9\", color=\"#558B2F\"];\n",
    "            \n",
    "            // Validation nodes - Orange theme (diamonds)\n",
    "            surface_check [label=\"Surface > 2m²?\", \n",
    "                          fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            trou_check [label=\"Polygone toiture avec\\\\ntrou contenu dedans?\", \n",
    "                       fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            sp_check_avec_trou [label=\"Superstructure?\", \n",
    "                              fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            sp_check_sans_trou [label=\"Superstructure?\", \n",
    "                              fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            // Action nodes - Purple theme\n",
    "            classe2a [label=\"Classe 2a\\\\nPartiellement occupée\\\\nPas de trou\\\\nSuperstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe2b [label=\"Classe 2b:\\\\nPartiellement occupée\\\\nTrou\\\\nSuperstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe3a [label=\"Classe 3a:\\\\nLibre\\\\nPas de trou\\\\nPas de superstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe3b [label=\"Classe 3b:\\\\nLibre\\\\nTrou\\\\nPas de superstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            // Action on image nodes - Red theme\n",
    "            classe2a_sans_sp [label=\"Action sur image:\\\\nSupprimer SP\\\\nde l'image\", \n",
    "                             fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe2a_avec_sp [label=\"Pas d'action sur image\", \n",
    "                             fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe3b_sans_trou [label=\"Action sur image:\\\\nSupprimer trou\\\\nde l'image\", \n",
    "                               fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe3b_avec_trou [label=\"Pas d'action sur image\", \n",
    "                               fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            // Output files - Blue theme with bold border\n",
    "            classe1 [label=\"Classe 1:\\\\nTotalement occupée\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "            \n",
    "            classe2 [label=\"Classe 2:\\\\nPartiellement occupée\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "            \n",
    "            classe3 [label=\"Classe 3:\\\\nLibre\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for better layout - stack more vertically\n",
    "        {rank=source; classify_start, surface_check}\n",
    "        {rank=same; trou_check}\n",
    "        // Split the superstructure checks into separate ranks to reduce width\n",
    "        {rank=same; sp_check_sans_trou}\n",
    "        {rank=same; sp_check_avec_trou}\n",
    "        // Stack classification nodes vertically instead of horizontally\n",
    "        {rank=same; classe2a, classe3a}\n",
    "        {rank=same; classe2b, classe3b}\n",
    "        {rank=same; classe2a_sans_sp, classe2a_avec_sp}\n",
    "        {rank=same; classe3b_sans_trou, classe3b_avec_trou}\n",
    "        {rank=sink; classe1, classe2, classe3}\n",
    "        \n",
    "        // Flow edges\n",
    "        classify_start -> surface_check;\n",
    "        surface_check -> classe1 [label=\" ≤ 2m²\", fontsize=12];\n",
    "        surface_check -> trou_check [label=\" > 2m²\", fontsize=12];\n",
    "        trou_check -> sp_check_sans_trou [label=\" Non\", fontsize=12];\n",
    "        trou_check -> sp_check_avec_trou [label=\" Oui\", fontsize=12];\n",
    "        sp_check_avec_trou -> classe2b [label=\" Oui\", fontsize=12];\n",
    "        sp_check_avec_trou -> classe3b [label=\" Non\", fontsize=12];\n",
    "        sp_check_sans_trou -> classe2a [label=\" Oui\", fontsize=12];\n",
    "        sp_check_sans_trou -> classe3a [label=\" Non\", fontsize=12];\n",
    "        \n",
    "        // Action connections\n",
    "        classe2a -> classe2a_sans_sp;\n",
    "        classe2a -> classe2a_avec_sp;\n",
    "        classe3b -> classe3b_sans_trou;\n",
    "        classe3b -> classe3b_avec_trou;\n",
    "        \n",
    "        // Final classification\n",
    "        classe2a_sans_sp -> classe3;\n",
    "        classe2a_avec_sp -> classe2;\n",
    "        classe3b_sans_trou -> classe3;\n",
    "        classe3b_avec_trou -> classe2;\n",
    "        classe3a -> classe3;\n",
    "        classe2b -> classe2;\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# write to file\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, CLASSIFICATION_WORKFLOW_PNG))\n",
    "\n",
    "# display(png_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph SimplifiedDataFlow {\n",
    "        rankdir=TB;\n",
    "        bgcolor=transparent;\n",
    "        fontname=\"Arial\";\n",
    "        pad=\"1.0\";\n",
    "        nodesep=\"0.8\";\n",
    "        ranksep=\"0.6\";\n",
    "        ratio=compress;\n",
    "        dpi=300;\n",
    "        size=\"10,8!\";\n",
    "        ordering=out;\n",
    "        \n",
    "        // Base node style\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=12,\n",
    "              margin=\"0.3\", width=\"2.5\", height=\"0.6\"];\n",
    "        \n",
    "        // Edge style\n",
    "        edge [color=\"#2E86AB\", penwidth=2, arrowsize=0.8, fontsize=11];\n",
    "        \n",
    "        // Subgraph for simplified workflow\n",
    "        subgraph cluster_0 {\n",
    "            label=\"Traitement des données GPKG - Workflow simplifié\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            margin=25;\n",
    "            fontsize=16;\n",
    "            fontname=\"Arial\";\n",
    "            \n",
    "            // Input files - Blue theme\n",
    "            input_files [label=\"Fichiers GPKG de SITG\\\\n\\\\n CAD_COMMUNE\\\\n CAD_BATIMENT_HORSOL_TOIT\\\\n CAD_BATIMENT_HORSOL_TOIT_SP\\\\n CAD_BATIMENT_HORSOL\", \n",
    "                        fillcolor=\"#E3F2FD\", color=\"#1565C0\", height=\"0.8\"];\n",
    "            \n",
    "            // Process nodes - Green theme\n",
    "            validation [label=\"Nettoyage données\\\\n\\\\n Géométries\\\\n CRS (EPSG:2056)\\\\n Types de données\\\\n Bug Céligny\", \n",
    "                       fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            filter_canton [label=\"Filtrage hors GE\\\\n\\\\n Retirer polygones hors canton\", \n",
    "                          fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            filter_egid [label=\"Filtrage EGID\\\\n\\\\n Associer toitures aux bâtiments\\\\n Éliminer EGID non valables\\\\n\", \n",
    "                        fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            add_categories [label=\"Classification SIA\\\\n\\\\n Ajout catégories SIA\\\\n Validation données\", \n",
    "                           fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            // Output file - Blue theme with bold border\n",
    "            output_file [label=\"Données finales\\\\n\\\\n gdf_toiture_ajout_cat_sia.parquet\", \n",
    "                        fillcolor=\"#E3F2FD\", color=\"#1565C0\", height=\"0.8\", \n",
    "                        penwidth=\"3\", style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for clean vertical layout\n",
    "        {rank=source; input_files}\n",
    "        {rank=same; validation, filter_canton}\n",
    "        {rank=same; add_categories, filter_egid}\n",
    "        {rank=sink; output_file}\n",
    "        \n",
    "        // Sequential flow\n",
    "        input_files -> validation;\n",
    "        validation -> filter_canton;\n",
    "        filter_canton -> filter_egid;\n",
    "        add_categories -> filter_egid [dir=back];\n",
    "        add_categories -> output_file;\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# Save to file (adjust path as needed)\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, ETL_WORKFLOW_PNG))\n",
    "\n",
    "display(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch3 données vectorielles finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf_toiture_3_ajout_cat_sia = gpd.read_parquet(\"data/notebook_02/parquet/02_gdf_toiture_3_ajout_cat_sia.parquet\")\n",
    "display(gdf_toiture_3_ajout_cat_sia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_toiture_3_ajout_cat_sia.dtypes\n",
    "# cast egid as int\n",
    "gdf_toiture_3_ajout_cat_sia['egid'] = gdf_toiture_3_ajout_cat_sia['egid'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def latex_truncate(text, max_length=25):\n",
    "    # Truncate long strings and format for LaTeX table display\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    truncated = text[:max_length-3]\n",
    "    return f\"\\\\parbox{{3cm}}{{{truncated}...}}\"\n",
    "\n",
    "def latex_truncate_float(value, max_length=25, decimal_places=2):\n",
    "    \"\"\"Truncate and format float values for LaTeX tables.\"\"\"\n",
    "    if not isinstance(value, (int, float)):\n",
    "        return value\n",
    "    formatted = f\"{value:.{decimal_places}f}\"\n",
    "    if len(formatted) > max_length:\n",
    "        truncated = formatted[:max_length-3]\n",
    "        return f\"\\\\parbox{{3cm}}{{{truncated}...}}\"\n",
    "    return formatted\n",
    "\n",
    "def auto_truncate_dataframe(df, drop_columns, max_length=25, threshold=30):\n",
    "    \"\"\"\n",
    "    Detect and truncate long columns in a DataFrame for LaTeX export.\n",
    "    Returns a copy of the DataFrame with truncated columns, a list of truncated columns, and the LaTeX column format string.\n",
    "    \"\"\"\n",
    "\n",
    "    df_display = df.copy()\n",
    "    long_columns = []\n",
    "\n",
    "    # Drop specified columns if present\n",
    "    if drop_columns:\n",
    "        df_display.drop(columns=[col for col in drop_columns if col in df_display.columns], inplace=True, errors='ignore')\n",
    "\n",
    "    # Escape underscores in column names for LaTeX\n",
    "    new_column_names = {}\n",
    "    for col in df_display.columns:\n",
    "        new_col = col\n",
    "        if \"__\" in col:\n",
    "            new_col = col.replace(\"__\", \"\\\\_\\\\_\")\n",
    "        elif \"_\" in col:\n",
    "            new_col = col.replace(\"_\", \"\\\\_\")\n",
    "        new_column_names[col] = new_col\n",
    "\n",
    "    df_display.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "    # Truncate columns based on length or type\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            if df[col].dtype in ['int64', 'int32', 'float64', 'float32']:\n",
    "                if df[col].dtype in ['float64', 'float32']:\n",
    "                    new_col_name = new_column_names[col]\n",
    "                    df_display[new_col_name] = df[col].apply(\n",
    "                        lambda x: f\"{x:.2f}...\" if pd.notna(x) else x\n",
    "                    )\n",
    "                else:\n",
    "                    formatted_lengths = df[col].astype(str).str.len()\n",
    "                    max_len_in_col = formatted_lengths.max()\n",
    "                    if max_len_in_col > 15:\n",
    "                        new_col_name = new_column_names[col]\n",
    "                        long_columns.append(new_col_name)\n",
    "                        df_display[new_col_name] = df[col].apply(\n",
    "                            lambda x: latex_truncate(str(x), max_length)\n",
    "                        )\n",
    "                continue\n",
    "\n",
    "            string_series = df[col].astype(str)\n",
    "            max_len_in_col = string_series.str.len().max()\n",
    "            avg_len_in_col = string_series.str.len().mean()\n",
    "            is_long = (max_len_in_col > threshold) or (avg_len_in_col > threshold * 0.7)\n",
    "            is_geometry = 'geometry' in col.lower() or str(df[col].dtype).startswith('geometry')\n",
    "\n",
    "            if is_long or is_geometry:\n",
    "                new_col_name = new_column_names[col]\n",
    "                long_columns.append(new_col_name)\n",
    "                df_display[new_col_name] = df[col].apply(\n",
    "                    lambda x: latex_truncate(str(x), max_length)\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process column '{col}': {e}\")\n",
    "            continue\n",
    "\n",
    "    # Build LaTeX column format string\n",
    "    column_format = \"@{}\"\n",
    "    for col in df_display.columns:\n",
    "        if col in long_columns:\n",
    "            column_format += \"p{3cm}\"\n",
    "        elif df_display[col].dtype in ['int64', 'float64'] or col.endswith('...'):\n",
    "            column_format += \"r\"\n",
    "        else:\n",
    "            column_format += \"l\"\n",
    "    column_format += \"@{}\"\n",
    "\n",
    "    return df_display, long_columns, column_format\n",
    "\n",
    "def add_line_spacing_to_latex_table(latex_code, spacing_factor=2):\n",
    "    \"\"\"\n",
    "    Insert arraystretch command to adjust line spacing in LaTeX tables.\n",
    "    \"\"\"\n",
    "    lines = latex_code.split('\\n')\n",
    "    result_lines = []\n",
    "    for line in lines:\n",
    "        result_lines.append(line)\n",
    "        if line.strip().startswith('\\\\begin{table}'):\n",
    "            result_lines.append(f'\\\\renewcommand{{\\\\arraystretch}}{{{spacing_factor}}}')\n",
    "    return '\\n'.join(result_lines)\n",
    "\n",
    "# Prepare DataFrame for LaTeX export with truncated columns and custom formatting\n",
    "df_display, truncated_cols, col_format = auto_truncate_dataframe(\n",
    "    gdf_toiture_3_ajout_cat_sia.head(3),\n",
    "    drop_columns=[\"SHAPE__Area\", \"SHAPE__Length\", \"altitude_min\", \"altitude_max\", \"date_leve\"],\n",
    "    max_length=20,\n",
    "    threshold=25,\n",
    ")\n",
    "\n",
    "latex_code = df_display.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Principales colonnes de gdf\\\\_toiture\\\\_ajout\\\\_cat\\\\_sia.parquet\",\n",
    "    label=\"tab:gdf_toiture_ajout_cat_sia_parquet_head\",\n",
    "    escape=False,\n",
    "    column_format=col_format,\n",
    ")\n",
    "\n",
    "# Add custom line spacing to the LaTeX table\n",
    "latex_code_with_spacing = add_line_spacing_to_latex_table(latex_code, spacing_factor=1.3)\n",
    "\n",
    "print(latex_code_with_spacing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch3 données ortophotos\n",
    "### schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<svg viewBox=\"0 0 800 600\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "  <!-- Background -->\n",
    "  <rect x=\"0\" y=\"0\" width=\"800\" height=\"600\" fill=\"#f8f9fa\" rx=\"6\" ry=\"6\"/>\n",
    "  \n",
    "  <!-- Title -->\n",
    "  <text x=\"400\" y=\"30\" font-family=\"Arial\" font-size=\"22\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#333\">GeoTIFF Building Detection and Tiling Process</text>\n",
    "  \n",
    "  <!-- Input Files Section -->\n",
    "  <rect x=\"50\" y=\"60\" width=\"700\" height=\"80\" rx=\"10\" ry=\"10\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"85\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#0d47a1\">Input Data</text>\n",
    "  \n",
    "  <!-- Input Icons -->\n",
    "  <rect x=\"100\" y=\"95\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#bbdefb\" stroke=\"#1976d2\" stroke-width=\"1\"/>\n",
    "  <text x=\"225\" y=\"115\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#0d47a1\">GeoTIFF SITG 20000x20000</text>\n",
    "  \n",
    "  <rect x=\"450\" y=\"95\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#bbdefb\" stroke=\"#1976d2\" stroke-width=\"1\"/>\n",
    "  <text x=\"575\" y=\"115\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#0d47a1\">Parquet Toitures</text>\n",
    "  \n",
    "  <!-- Process Flow -->\n",
    "  <rect x=\"50\" y=\"160\" width=\"700\" height=\"310\" rx=\"10\" ry=\"10\" fill=\"#e8f5e9\" stroke=\"#4caf50\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"185\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">Génération des tuiles</text>\n",
    "\n",
    "  <!-- Main Image Processing -->\n",
    "  <rect x=\"70\" y=\"200\" width=\"320\" height=\"250\" rx=\"8\" ry=\"8\" fill=\"#fff\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <text x=\"230\" y=\"225\" font-family=\"Arial\" font-size=\"16\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">GeoTIFF 200000x20000</text>\n",
    "  \n",
    "  <!-- Main Image Representation -->\n",
    "  <rect x=\"100\" y=\"240\" width=\"140\" height=\"140\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"240\" x2=\"240\" y2=\"240\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"270\" x2=\"240\" y2=\"270\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"300\" x2=\"240\" y2=\"300\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"330\" x2=\"240\" y2=\"330\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"240\" x2=\"100\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"135\" y1=\"240\" x2=\"135\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"170\" y1=\"240\" x2=\"170\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"205\" y1=\"240\" x2=\"205\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"240\" y1=\"240\" x2=\"240\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  \n",
    "  <!-- Building Polygons -->\n",
    "  <polygon points=\"125,260 145,250 165,265 155,280 135,275\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <polygon points=\"205,320 220,310 230,330 210,340\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <polygon points=\"110,340 130,330 140,350 120,360\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  \n",
    "  <!-- Tiling Process -->\n",
    "  <text x=\"170\" y=\"395\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#1b5e20\">GeoTIFF + Parquet Toitures</text>\n",
    "  \n",
    "  <!-- Tiling Result -->\n",
    "  <rect x=\"410\" y=\"200\" width=\"320\" height=\"250\" rx=\"8\" ry=\"8\" fill=\"#fff\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <text x=\"570\" y=\"225\" font-family=\"Arial\" font-size=\"16\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">Tuile 1280x1280</text>\n",
    "  \n",
    "  <!-- Tile Representations -->\n",
    "  <rect x=\"430\" y=\"240\" width=\"90\" height=\"90\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"2\"/>\n",
    "  <polygon points=\"470,260 485,250 500,265 490,280 475,275\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <rect x=\"430\" y=\"240\" width=\"90\" height=\"90\" fill=\"none\" stroke=\"#2e7d32\" stroke-width=\"1\" stroke-dasharray=\"4,2\"/>\n",
    "  \n",
    "  <rect x=\"530\" y=\"240\" width=\"90\" height=\"90\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"1\" fill-opacity=\"0.3\"/>\n",
    "  \n",
    "  <rect x=\"430\" y=\"340\" width=\"90\" height=\"90\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"1\" fill-opacity=\"0.3\"/>\n",
    "  \n",
    "  <rect x=\"530\" y=\"340\" width=\"90\" height=\"90\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"2\"/>\n",
    "  <polygon points=\"570,360 590,355 600,375 580,380\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <rect x=\"530\" y=\"340\" width=\"90\" height=\"90\" fill=\"none\" stroke=\"#2e7d32\" stroke-width=\"1\" stroke-dasharray=\"4,2\"/>\n",
    "  \n",
    "  <!-- Buffer Illustration -->\n",
    "  <rect x=\"420\" y=\"230\" width=\"110\" height=\"110\" fill=\"none\" stroke=\"#ff9800\" stroke-width=\"1.5\" stroke-dasharray=\"5,3\"/>\n",
    "  <rect x=\"520\" y=\"330\" width=\"110\" height=\"110\" fill=\"none\" stroke=\"#ff9800\" stroke-width=\"1.5\" stroke-dasharray=\"5,3\"/>\n",
    "  \n",
    "  <text x=\"640\" y=\"390\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">Overlap</text>\n",
    "  <text x=\"640\" y=\"405\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">256 pixels</text>\n",
    "  <text x=\"640\" y=\"420\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">entre tuiles</text>\n",
    "  \n",
    "  <!-- Process Arrows -->\n",
    "  <path d=\"M 250 310 L 400 310\" stroke=\"#2e7d32\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n",
    "  # <text x=\"325\" y=\"300\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#1b5e20\">Quadrillage</text>\n",
    "  \n",
    "  <!-- Arrow Marker -->\n",
    "  <defs>\n",
    "    <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#2e7d32\"/>\n",
    "    </marker>\n",
    "  </defs>\n",
    "  \n",
    "  <!-- Output Section -->\n",
    "  <rect x=\"50\" y=\"490\" width=\"700\" height=\"80\" rx=\"10\" ry=\"10\" fill=\"#fff3e0\" stroke=\"#ff9800\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"515\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#e65100\">Output Data</text>\n",
    "  \n",
    "  <!-- Output Icons -->\n",
    "  <rect x=\"100\" y=\"525\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#ffe0b2\" stroke=\"#f57c00\" stroke-width=\"1\"/>\n",
    "  <text x=\"225\" y=\"545\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#e65100\">Tuiles GeoTIFF 1280x1280</text>\n",
    "  \n",
    "  <rect x=\"450\" y=\"525\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#ffe0b2\" stroke=\"#f57c00\" stroke-width=\"1\"/>\n",
    "  <text x=\"575\" y=\"545\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#e65100\">Dataframe tuiles (Parquet)</text>\n",
    "  \n",
    "\n",
    "\n",
    "  <!-- Final Arrow -->\n",
    "  <path d=\"M 400 470 L 400 490\" stroke=\"#e65100\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead2)\"/>\n",
    "  \n",
    "  <!-- Arrow Marker -->\n",
    "  <defs>\n",
    "    <marker id=\"arrowhead2\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#e65100\"/>\n",
    "    </marker>\n",
    "  </defs>\n",
    "\n",
    "</svg>\n",
    "\"\"\"\n",
    "\n",
    "svg2png(bytestring=svg, scale=2, dpi=600, write_to=os.path.join(GRAPHICS_PATH, ETL_ORTHOPHOTOS_PNG))\n",
    "# display the png file\n",
    "# display(Image.open(os.path.join(GRAPHICS_PATH, ETL_ORTHOPHOTOS_PNG)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### images découpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "def images_decoupe(\n",
    "    GEOTIFF_ORTHO2019_PATH,\n",
    "    TILE_1024_FOLDER_PATH,\n",
    "    GRAPHICS_PATH,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG,\n",
    "    selected_tile=None,\n",
    "    text_number_on_tiles=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes the tiling of orthophotos and their corresponding tiles.\n",
    "\n",
    "    Parameters:\n",
    "        GEOTIFF_ORTHO2019_PATH (str): Path to the folder containing GeoTIFF orthophotos.\n",
    "        TILE_1024_FOLDER_PATH (str): Path to the folder containing 1024x1024 tiles.\n",
    "        GRAPHICS_PATH (str): Path to save the generated graphics.\n",
    "        EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG (str): Filename for the first example image.\n",
    "        EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG (str): Filename for the second example image.\n",
    "        selected_tile (str, optional): Specific orthophoto file to use. If None, a random file is selected.\n",
    "        text_number_on_tiles (bool): Whether to display tile numbers on the visualization.\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    random.seed(21)\n",
    "\n",
    "    if selected_tile:\n",
    "        print(f\"Using selected tile: {selected_tile}\")\n",
    "        random_ortho_file = selected_tile\n",
    "    else:\n",
    "        # List all GeoTIFF files in the orthophoto folder, excluding those ending with 'with_crs.tif'\n",
    "        ortho_files = [\n",
    "            f for f in os.listdir(GEOTIFF_ORTHO2019_PATH)\n",
    "            if f.endswith('.tif') and not f.endswith('with_crs.tif')\n",
    "        ]\n",
    "        print(f\"Found {len(ortho_files)} ortho files\")\n",
    "        random_ortho_file = random.choice(ortho_files)\n",
    "        print(f\"Selected random ortho file: {random_ortho_file}\")\n",
    "\n",
    "    ortho_path = os.path.join(GEOTIFF_ORTHO2019_PATH, random_ortho_file)\n",
    "    try:\n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            print(f\"Ortho file shape: {src.shape}\")\n",
    "            print(f\"Ortho file CRS: {src.crs}\")\n",
    "            print(f\"Ortho file bounds: {src.bounds}\")\n",
    "\n",
    "            ortho_basename = os.path.splitext(random_ortho_file)[0]\n",
    "            print(f\"\\nSearching for tiles matching: {ortho_basename}\")\n",
    "\n",
    "            tile_bounds_list = []\n",
    "            tile_files = []\n",
    "\n",
    "            if os.path.exists(TILE_1024_FOLDER_PATH):\n",
    "                # Find all tiles corresponding to the selected orthophoto\n",
    "                matching_tiles = [\n",
    "                    f for f in os.listdir(TILE_1024_FOLDER_PATH)\n",
    "                    if f.startswith(ortho_basename) and f.endswith('.tif')\n",
    "                ]\n",
    "                print(f\"Found {len(matching_tiles)} corresponding tiles\")\n",
    "\n",
    "                # Read bounds for each tile\n",
    "                for tile_file in matching_tiles:\n",
    "                    tile_path = os.path.join(TILE_1024_FOLDER_PATH, tile_file)\n",
    "                    try:\n",
    "                        with rasterio.open(tile_path) as tile_src:\n",
    "                            tile_bounds_list.append(tile_src.bounds)\n",
    "                            tile_files.append(tile_file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {tile_file}: {e}\")\n",
    "\n",
    "                print(f\"Successfully processed {len(tile_bounds_list)} tiles\")\n",
    "\n",
    "                # Sort tiles by position (top-left to bottom-right)\n",
    "                tile_data = []\n",
    "                for bounds, filename in zip(tile_bounds_list, tile_files):\n",
    "                    center_x = (bounds[0] + bounds[2]) / 2\n",
    "                    center_y = (bounds[1] + bounds[3]) / 2\n",
    "                    tile_data.append((bounds, filename, center_x, center_y))\n",
    "\n",
    "                tile_data.sort(key=lambda x: (-x[3], x[2]))\n",
    "                tile_bounds_list = [item[0] for item in tile_data]\n",
    "                tile_files = [item[1] for item in tile_data]\n",
    "\n",
    "                # Plot the orthophoto with tile overlays\n",
    "                fig, ax = plt.subplots(figsize=(6.5, 6.5))\n",
    "                show(src, ax=ax, title=f\"Découpage pour l'orthophoto {random_ortho_file}\")\n",
    "\n",
    "                colors = sns.color_palette(\"pastel\", len(tile_bounds_list))\n",
    "\n",
    "                for i, (bounds, tile_file) in enumerate(zip(tile_bounds_list, tile_files)):\n",
    "                    left, bottom, right, top = bounds\n",
    "                    width = right - left\n",
    "                    height = top - bottom\n",
    "\n",
    "                    rect = patches.Rectangle(\n",
    "                        (left, bottom), width, height,\n",
    "                        linewidth=1.2,\n",
    "                        edgecolor=colors[i],\n",
    "                        facecolor='none',\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "\n",
    "                    if text_number_on_tiles:\n",
    "                        center_x = left + width / 2\n",
    "                        center_y = bottom + height / 2\n",
    "                        ax.text(\n",
    "                            center_x, center_y, str(i + 1),\n",
    "                            ha='center', va='center',\n",
    "                            fontsize=7, color=\"white\",\n",
    "                            fontweight='semibold'\n",
    "                        )\n",
    "\n",
    "                ax.set_xlabel('x (m)')\n",
    "                ax.set_ylabel('y (m)')\n",
    "\n",
    "                legend_text = f\"Tuiles découpées: {len(tile_bounds_list)}/400\"\n",
    "                ax.text(\n",
    "                    0.02, 0.98, legend_text, transform=ax.transAxes,\n",
    "                    verticalalignment='top', ha=\"left\",\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "                )\n",
    "\n",
    "                ax.grid(False)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\n",
    "                    os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG),\n",
    "                    dpi=300, bbox_inches='tight'\n",
    "                )\n",
    "                plt.show()\n",
    "\n",
    "                # Plot the tile grid only\n",
    "                fig2, ax2 = plt.subplots(figsize=(6.5, 6.5))\n",
    "\n",
    "                main_bounds = src.bounds\n",
    "                main_rect = patches.Rectangle(\n",
    "                    (main_bounds[0], main_bounds[1]),\n",
    "                    main_bounds[2] - main_bounds[0],\n",
    "                    main_bounds[3] - main_bounds[1],\n",
    "                    linewidth=3, edgecolor='black', facecolor='lightgray', alpha=0.3\n",
    "                )\n",
    "                ax2.add_patch(main_rect)\n",
    "\n",
    "                for i, (bounds, tile_file) in enumerate(zip(tile_bounds_list, tile_files)):\n",
    "                    left, bottom, right, top = bounds\n",
    "                    width = right - left\n",
    "                    height = top - bottom\n",
    "\n",
    "                    rect = patches.Rectangle(\n",
    "                        (left, bottom), width, height,\n",
    "                        linewidth=1,\n",
    "                        edgecolor=colors[i],\n",
    "                        facecolor=colors[i],\n",
    "                        alpha=0.6\n",
    "                    )\n",
    "                    ax2.add_patch(rect)\n",
    "\n",
    "                    center_x = left + width / 2\n",
    "                    center_y = bottom + height / 2\n",
    "                    ax2.text(\n",
    "                        center_x, center_y, str(i + 1),\n",
    "                        ha='center', va='center', fontsize=8\n",
    "                    )\n",
    "\n",
    "                ax2.set_xlim(main_bounds[0], main_bounds[2])\n",
    "                ax2.set_ylim(main_bounds[1], main_bounds[3])\n",
    "                ax2.set_xlabel('x (m)')\n",
    "                ax2.set_ylabel('y (m)')\n",
    "                ax2.set_title(\n",
    "                    f\"Calepinage des tuiles pour l'orthophoto {random_ortho_file}\",\n",
    "                    fontsize=12, fontweight='bold'\n",
    "                )\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_aspect('equal')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\n",
    "                    os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG),\n",
    "                    dpi=300, bbox_inches='tight'\n",
    "                )\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print(f\"Tile folder does not exist: {TILE_1024_FOLDER_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ortho file {ortho_path}: {e}\")\n",
    "\n",
    "images_decoupe(\n",
    "    GEOTIFF_ORTHO2019_PATH,\n",
    "    TILE_1024_FOLDER_PATH,\n",
    "    GRAPHICS_PATH,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG,\n",
    "    selected_tile=\"24991118.tif\",\n",
    "    text_number_on_tiles=False\n",
    ")\n",
    "\n",
    "images_decoupe(\n",
    "    GEOTIFF_ORTHO2019_PATH,\n",
    "    TILE_1024_FOLDER_PATH,\n",
    "    GRAPHICS_PATH,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_04_PNG,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_05_PNG,\n",
    "    selected_tile=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.close()\n",
    "\n",
    "# Configure plot style and font sizes\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "\n",
    "# Specify the target tile filename\n",
    "target_tile = '24991118_tile_11_7_4db66f.tif'\n",
    "print(f\"Target tile: {target_tile}\")\n",
    "\n",
    "# List all tile files in the specified folder\n",
    "tile_files = [f for f in os.listdir(TILE_1024_FOLDER_PATH) if f.startswith('24991118_tile_') and f.endswith('.tif')]\n",
    "\n",
    "# Check if the target tile exists; if not, try to find a similar one\n",
    "if target_tile not in tile_files:\n",
    "    print(f\"Error: {target_tile} not found in tile_files list\")\n",
    "    similar_tiles = [t for t in tile_files if '24991118_tile_11_7' in t]\n",
    "    print(f\"Similar tiles found: {similar_tiles}\")\n",
    "    if similar_tiles:\n",
    "        target_tile = similar_tiles[0]\n",
    "        print(f\"Using: {target_tile}\")\n",
    "    else:\n",
    "        print(\"No similar tiles found. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "# Open the target tile and extract its properties\n",
    "tile_path = os.path.join(TILE_1024_FOLDER_PATH, target_tile)\n",
    "with rasterio.open(tile_path) as tile_src:\n",
    "    print(f\"Tile shape: {tile_src.shape}\")\n",
    "    print(f\"Tile CRS: {tile_src.crs}\")\n",
    "    print(f\"Tile bounds: {tile_src.bounds}\")\n",
    "    \n",
    "    target_bounds = tile_src.bounds\n",
    "    \n",
    "    # Extract row and column indices from the filename\n",
    "    parts = target_tile.split('_')\n",
    "    target_row = int(parts[2])\n",
    "    target_col = int(parts[3])\n",
    "    print(f\"Target tile coordinates: row={target_row}, col={target_col}\")\n",
    "    \n",
    "    # Prepare to find all adjacent tiles (8 neighbors)\n",
    "    adjacent_tiles = []\n",
    "    adjacent_positions = [\n",
    "        (target_row-1, target_col-1),  # Northwest\n",
    "        (target_row-1, target_col),    # North\n",
    "        (target_row-1, target_col+1),  # Northeast\n",
    "        (target_row, target_col-1),    # West\n",
    "        (target_row, target_col+1),    # East\n",
    "        (target_row+1, target_col-1),  # Southwest\n",
    "        (target_row+1, target_col),    # South\n",
    "        (target_row+1, target_col+1),  # Southeast\n",
    "    ]\n",
    "    \n",
    "    # Search for adjacent tiles in the file list\n",
    "    for filename in tile_files:\n",
    "        if filename.startswith('24991118_tile_'):\n",
    "            parts = filename.split('_')\n",
    "            try:\n",
    "                row = int(parts[2])\n",
    "                col = int(parts[3])\n",
    "                if (row, col) in adjacent_positions:\n",
    "                    tile_path_check = os.path.join(TILE_1024_FOLDER_PATH, filename)\n",
    "                    try:\n",
    "                        with rasterio.open(tile_path_check) as check_src:\n",
    "                            bounds = check_src.bounds\n",
    "                            adjacent_tiles.append((bounds, filename, row, col))\n",
    "                            print(f\"Found adjacent tile: {filename} at ({row},{col})\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not read bounds for {filename}: {e}\")\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    print(f\"Found {len(adjacent_tiles)} adjacent tiles\")\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.5, 6.5))\n",
    "    \n",
    "    # Display the target tile\n",
    "    show(tile_src, ax=ax, alpha=0.8)\n",
    "    \n",
    "    # Define pastel colors for tile borders\n",
    "    pastel_colors = [\n",
    "        '#FFB3BA',  # Light pink\n",
    "        '#BAFFC9',  # Light green  \n",
    "        '#BAE1FF',  # Light blue\n",
    "        '#FFFFBA',  # Light yellow\n",
    "        '#FFDFBA',  # Light peach\n",
    "        '#E0BBE4',  # Light purple\n",
    "        '#C7CEEA',  # Light lavender\n",
    "        '#B5EAD7',  # Light mint\n",
    "        '#FFE5CC'   # Light orange\n",
    "    ]\n",
    "    \n",
    "    all_bounds = [target_bounds]\n",
    "    \n",
    "    # Overlay adjacent tiles and add borders/labels\n",
    "    for i, (bounds, filename, row, col) in enumerate(adjacent_tiles):\n",
    "        tile_path_adj = os.path.join(TILE_1024_FOLDER_PATH, filename)\n",
    "        try:\n",
    "            with rasterio.open(tile_path_adj) as adj_src:\n",
    "                show(adj_src, ax=ax, alpha=0.6)\n",
    "                left, bottom, right, top = bounds\n",
    "                width_tile = right - left\n",
    "                height_tile = top - bottom\n",
    "                color = pastel_colors[i % len(pastel_colors)]\n",
    "                rect = patches.Rectangle(\n",
    "                    (left, bottom), width_tile, height_tile,\n",
    "                    linewidth=3, \n",
    "                    edgecolor=color, \n",
    "                    facecolor='none',\n",
    "                    alpha=0.8\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # Calculate label position\n",
    "                center_x = left + width_tile / 2\n",
    "                center_y = bottom + height_tile / 2\n",
    "                label_offset_x = (center_x - (target_bounds.left + target_bounds.right) / 2) * 0.1\n",
    "                label_offset_y = (center_y - (target_bounds.bottom + target_bounds.top) / 2) * 0.1\n",
    "\n",
    "                # Map tile filenames to numeric labels\n",
    "                tile_dict = {\n",
    "                    \"24991118_tile_10_6_4fc85d.tif\": \"237\",\n",
    "                    \"24991118_tile_10_7_18eac4.tif\": \"238\",\n",
    "                    \"24991118_tile_10_8_2931b8.tif\": \"239\",\n",
    "                    \"24991118_tile_11_6_d743cd.tif\": \"257\",\n",
    "                    \"24991118_tile_11_8_6b34a7.tif\": \"259\",\n",
    "                    \"24991118_tile_12_6_a82c81.tif\": \"277\",\n",
    "                    \"24991118_tile_12_7_7ce219.tif\": \"278\",\n",
    "                    \"24991118_tile_12_8_83485c.tif\": \"279\",\n",
    "                }\n",
    "                tile_label = tile_dict.get(filename, filename)\n",
    "                \n",
    "                ax.text(center_x + label_offset_x, center_y + label_offset_y, \n",
    "                       tile_label, \n",
    "                       ha='center', va='center', \n",
    "                       fontsize=10, color='black', fontweight='demibold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', \n",
    "                               facecolor='white', \n",
    "                               alpha=0.9,\n",
    "                               edgecolor=color,\n",
    "                               linewidth=2))\n",
    "                \n",
    "                all_bounds.append(bounds)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Could not load adjacent tile {filename}: {e}\")\n",
    "    \n",
    "    # Highlight the target tile with a red border and label\n",
    "    left, bottom, right, top = target_bounds\n",
    "    width_tile = right - left\n",
    "    height_tile = top - bottom\n",
    "    target_rect = patches.Rectangle(\n",
    "        (left, bottom), width_tile, height_tile,\n",
    "        linewidth=6, \n",
    "        edgecolor='red', \n",
    "        facecolor='none',\n",
    "        alpha=1.0,\n",
    "        ls = \":\"  # Dashed line for emphasis\n",
    "    )\n",
    "    ax.add_patch(target_rect)\n",
    "    \n",
    "    # Add label for the target tile\n",
    "    center_x = left + width_tile / 2\n",
    "    center_y = bottom + height_tile / 2\n",
    "    ax.text(center_x, center_y, \n",
    "           \"258\",\n",
    "           ha='center', va='center', \n",
    "           fontsize=10, color='white', fontweight='bold',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', \n",
    "                   facecolor='red', \n",
    "                   alpha=0.8,\n",
    "                   edgecolor='red',\n",
    "                   linewidth=2))\n",
    "   \n",
    "    # Adjust plot limits to fit all tiles with padding\n",
    "    if all_bounds:\n",
    "        min_x = min(b.left if hasattr(b, 'left') else b[0] for b in all_bounds)\n",
    "        max_x = max(b.right if hasattr(b, 'right') else b[2] for b in all_bounds)\n",
    "        min_y = min(b.bottom if hasattr(b, 'bottom') else b[1] for b in all_bounds)\n",
    "        max_y = max(b.top if hasattr(b, 'top') else b[3] for b in all_bounds)\n",
    "        ax.set_xlim(min_x, max_x)\n",
    "        ax.set_ylim(min_y, max_y)\n",
    "    \n",
    "    # Set axis labels and plot title\n",
    "    ax.set_xlabel('x (m)', fontsize=10)\n",
    "    ax.set_ylabel('y (m)', fontsize=10)\n",
    "    ax.set_title('Tuile 258 et adjacentes', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=10)\n",
    "    ax.xaxis.get_offset_text().set_fontsize(10)\n",
    "    ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "    ax.grid(False, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure to file\n",
    "    plt.savefig(os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_03_PNG), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print a summary of adjacent tiles\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ADJACENT TILES SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Target tile: {target_tile} at position ({target_row},{target_col})\")\n",
    "    print(f\"Adjacent tiles found: {len(adjacent_tiles)}\")\n",
    "    print(\"\\nAdjacent tiles list:\")\n",
    "    for bounds, filename, row, col in sorted(adjacent_tiles, key=lambda x: (x[2], x[3])):\n",
    "        direction = \"\"\n",
    "        if row < target_row and col < target_col:\n",
    "            direction = \"NW\"\n",
    "        elif row < target_row and col == target_col:\n",
    "            direction = \"N\"\n",
    "        elif row < target_row and col > target_col:\n",
    "            direction = \"NE\"\n",
    "        elif row == target_row and col < target_col:\n",
    "            direction = \"W\"\n",
    "        elif row == target_row and col > target_col:\n",
    "            direction = \"E\"\n",
    "        elif row > target_row and col < target_col:\n",
    "            direction = \"SW\"\n",
    "        elif row > target_row and col == target_col:\n",
    "            direction = \"S\"\n",
    "        elif row > target_row and col > target_col:\n",
    "            direction = \"SE\"\n",
    "        \n",
    "        print(f\"  {filename} at ({row},{col}) - {direction} of target\")\n",
    "    print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "plt.close()\n",
    "# Set seaborn style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "def read_single_orthophoto_metadata(args):\n",
    "    \"\"\"\n",
    "    Reads metadata for a single orthophoto file.\n",
    "    Returns filename and metadata dictionary or None on error.\n",
    "    \"\"\"\n",
    "    ortho_file, ortho_path = args\n",
    "    ortho_filepath = os.path.join(ortho_path, ortho_file)\n",
    "    try:\n",
    "        with rasterio.open(ortho_filepath) as src:\n",
    "            return ortho_file, {\n",
    "                'bounds': src.bounds,\n",
    "                'crs': src.crs,\n",
    "                'shape': src.shape,\n",
    "                'path': ortho_filepath,\n",
    "                'tiles': []\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {ortho_file}: {e}\")\n",
    "        return ortho_file, None\n",
    "\n",
    "def collect_orthophoto_metadata(ortho_path, max_workers=None):\n",
    "    \"\"\"\n",
    "    Collects metadata for all orthophoto files in a directory using parallel processing.\n",
    "    Returns a dictionary of metadata and the overall spatial extent.\n",
    "    \"\"\"\n",
    "    print(\"Scanning orthophoto files...\")\n",
    "    ortho_files = [f for f in os.listdir(ortho_path) if f.endswith('.tif') and not f.endswith('with_crs.tif')]\n",
    "    print(f\"Found {len(ortho_files)} orthophoto files\")\n",
    "    if max_workers is None:\n",
    "        max_workers = min(mp.cpu_count(), 16)\n",
    "    ortho_data = {}\n",
    "    all_bounds = []\n",
    "    args_list = [(ortho_file, ortho_path) for ortho_file in ortho_files]\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(read_single_orthophoto_metadata, args): args[0] \n",
    "                         for args in args_list}\n",
    "        for future in tqdm(as_completed(future_to_file), total=len(ortho_files), \n",
    "                          desc=\"Reading orthophoto metadata\"):\n",
    "            ortho_file = future_to_file[future]\n",
    "            try:\n",
    "                filename, data = future.result()\n",
    "                if data is not None:\n",
    "                    ortho_data[filename] = data\n",
    "                    all_bounds.append(data['bounds'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ortho_file}: {e}\")\n",
    "    if all_bounds:\n",
    "        min_x = min(b[0] for b in all_bounds)\n",
    "        min_y = min(b[1] for b in all_bounds)\n",
    "        max_x = max(b[2] for b in all_bounds)\n",
    "        max_y = max(b[3] for b in all_bounds)\n",
    "        overall_bounds = (min_x, min_y, max_x, max_y)\n",
    "        print(f\"Overall extent: {overall_bounds}\")\n",
    "        print(f\"Successfully processed {len(ortho_data)} orthophoto files\")\n",
    "    else:\n",
    "        overall_bounds = None\n",
    "    return ortho_data, overall_bounds\n",
    "\n",
    "def read_single_tile_metadata(args):\n",
    "    \"\"\"\n",
    "    Reads metadata for a single tile file.\n",
    "    Returns filename and bounds or None on error.\n",
    "    \"\"\"\n",
    "    tile_file, tile_path = args\n",
    "    tile_filepath = os.path.join(tile_path, tile_file)\n",
    "    try:\n",
    "        with rasterio.open(tile_filepath) as tile_src:\n",
    "            return tile_file, tile_src.bounds\n",
    "    except Exception:\n",
    "        return tile_file, None\n",
    "\n",
    "def match_tiles_to_orthophotos(ortho_data, tile_path, max_workers=None):\n",
    "    \"\"\"\n",
    "    Matches tile files to their corresponding orthophotos.\n",
    "    Updates the orthophoto metadata with tile information.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tile_path):\n",
    "        print(f\"Tile folder does not exist: {tile_path}\")\n",
    "        return ortho_data\n",
    "    print(\"Scanning tile files...\")\n",
    "    tile_files = [f for f in os.listdir(tile_path) if f.endswith('.tif')]\n",
    "    print(f\"Found {len(tile_files)} tile files\")\n",
    "    if max_workers is None:\n",
    "        max_workers = min(mp.cpu_count(), 16)\n",
    "    ortho_basenames = {}\n",
    "    for ortho_file in ortho_data.keys():\n",
    "        ortho_name = os.path.splitext(ortho_file)[0]\n",
    "        ortho_basenames[ortho_name] = ortho_file\n",
    "    args_list = [(tile_file, tile_path) for tile_file in tile_files]\n",
    "    tile_metadata = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(read_single_tile_metadata, args): args[0] \n",
    "                         for args in args_list}\n",
    "        for future in tqdm(as_completed(future_to_file), total=len(tile_files), \n",
    "                          desc=\"Reading tile metadata\"):\n",
    "            tile_file = future_to_file[future]\n",
    "            try:\n",
    "                filename, bounds = future.result()\n",
    "                if bounds is not None:\n",
    "                    tile_metadata[filename] = bounds\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tile_file}: {e}\")\n",
    "                continue\n",
    "    tiles_processed = 0\n",
    "    print(\"Matching tiles to orthophotos...\")\n",
    "    for tile_file, tile_bounds in tqdm(tile_metadata.items(), desc=\"Matching tiles\"):\n",
    "        matched_ortho = None\n",
    "        for ortho_name, ortho_file in ortho_basenames.items():\n",
    "            if tile_file.startswith(ortho_name):\n",
    "                matched_ortho = ortho_file\n",
    "                break\n",
    "        if matched_ortho:\n",
    "            ortho_data[matched_ortho]['tiles'].append({\n",
    "                'filename': tile_file,\n",
    "                'bounds': tile_bounds\n",
    "            })\n",
    "            tiles_processed += 1\n",
    "    print(f\"Successfully matched {tiles_processed} tiles to orthophotos\")\n",
    "    # Sort tiles for each orthophoto by spatial position\n",
    "    print(\"Sorting tiles by spatial position...\")\n",
    "    for ortho_file in tqdm(ortho_data.keys(), desc=\"Sorting tiles\"):\n",
    "        tiles = ortho_data[ortho_file]['tiles']\n",
    "        if tiles:\n",
    "            tile_data = []\n",
    "            for tile in tiles:\n",
    "                bounds = tile['bounds']\n",
    "                center_x = (bounds[0] + bounds[2]) * 0.5\n",
    "                center_y = (bounds[1] + bounds[3]) * 0.5\n",
    "                tile_data.append((tile, center_x, center_y))\n",
    "            # Sort by y descending (top first), then x ascending (left first)\n",
    "            tile_data.sort(key=lambda x: (-x[2], x[1]))\n",
    "            ortho_data[ortho_file]['tiles'] = [item[0] for item in tile_data]\n",
    "    return ortho_data\n",
    "\n",
    "def process_single_orthophoto(args):\n",
    "    \"\"\"\n",
    "    Processes a single orthophoto for visualization.\n",
    "    Returns image data, extent, tile patches, and tile count.\n",
    "    \"\"\"\n",
    "    ortho_file, data, tile_color, downsample_target = args\n",
    "    try:\n",
    "        with rasterio.open(data['path']) as src:\n",
    "            downsample_factor = max(1, max(src.shape) // downsample_target)\n",
    "            downsampled_data = src.read(\n",
    "                out_shape=(src.count, src.height // downsample_factor, src.width // downsample_factor),\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "            extent = [data['bounds'][0], data['bounds'][2], data['bounds'][1], data['bounds'][3]]\n",
    "            if downsampled_data.shape[0] >= 3:\n",
    "                img_data = np.transpose(downsampled_data[:3], (1, 2, 0))\n",
    "                p98 = np.percentile(img_data, 98)\n",
    "                if p98 > 0:\n",
    "                    img_data = np.clip(img_data / p98 * 255, 0, 255).astype(np.uint8)\n",
    "            else:\n",
    "                img_data = downsampled_data[0]\n",
    "            tile_patches = []\n",
    "            for tile in data['tiles']:\n",
    "                tile_bounds = tile['bounds']\n",
    "                left, bottom, right, top = tile_bounds\n",
    "                width_tile = right - left\n",
    "                height_tile = top - bottom\n",
    "                rect_data = {\n",
    "                    'xy': (left, bottom),\n",
    "                    'width': width_tile,\n",
    "                    'height': height_tile,\n",
    "                    'color': tile_color\n",
    "                }\n",
    "                tile_patches.append(rect_data)\n",
    "            return ortho_file, img_data, extent, tile_patches, len(data['tiles'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ortho_file}: {e}\")\n",
    "        return ortho_file, None, None, None, 0\n",
    "\n",
    "def create_canton_visualization(ortho_data, overall_bounds, output_path=None, downsample_target=600):\n",
    "    \"\"\"\n",
    "    Creates a visualization showing all orthophotos and their tile divisions.\n",
    "    \"\"\"\n",
    "    print(\"Creating canton-wide visualization...\")\n",
    "    width = overall_bounds[2] - overall_bounds[0]\n",
    "    height = overall_bounds[3] - overall_bounds[1]\n",
    "    aspect_ratio = width / height\n",
    "    fig_width = 6.5\n",
    "    fig_height = fig_width / aspect_ratio\n",
    "    if fig_height > 30:\n",
    "        fig_height = 30\n",
    "        fig_width = fig_height * aspect_ratio\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    orthos_with_tiles = {k: v for k, v in ortho_data.items() if v['tiles']}\n",
    "    print(f\"Processing {len(orthos_with_tiles)} orthophotos with tiles\")\n",
    "    tile_color = '#FF0000'  # Use red for tile boundaries\n",
    "    max_workers = min(16, mp.cpu_count())\n",
    "    batch_size = 20\n",
    "    ortho_items = list(orthos_with_tiles.items())\n",
    "    total_tiles = 0\n",
    "    ortho_count = 0\n",
    "    for batch_start in tqdm(range(0, len(ortho_items), batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, len(ortho_items))\n",
    "        batch_items = ortho_items[batch_start:batch_end]\n",
    "        args_list = [(ortho_file, data, tile_color, downsample_target) \n",
    "                    for ortho_file, data in batch_items]\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(process_single_orthophoto, args) for args in args_list]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    ortho_file, img_data, extent, tile_patches, num_tiles = future.result()\n",
    "                    if img_data is not None:\n",
    "                        # Show orthophoto with reduced alpha for tile visibility\n",
    "                        ax.imshow(img_data, extent=extent, alpha=0.6)\n",
    "                        # Draw tile boundaries with white outline and red border\n",
    "                        for patch_data in tile_patches:\n",
    "                            rect_outline = patches.Rectangle(\n",
    "                                patch_data['xy'], patch_data['width'], patch_data['height'],\n",
    "                                linewidth=4.0, \n",
    "                                edgecolor='white', \n",
    "                                facecolor='none',\n",
    "                                alpha=0.8,\n",
    "                                zorder=1\n",
    "                            )\n",
    "                            ax.add_patch(rect_outline)\n",
    "                            rect_main = patches.Rectangle(\n",
    "                                patch_data['xy'], patch_data['width'], patch_data['height'],\n",
    "                                linewidth=2.5, \n",
    "                                edgecolor=tile_color, \n",
    "                                facecolor='none',\n",
    "                                alpha=1.0,\n",
    "                                zorder=2\n",
    "                            )\n",
    "                            ax.add_patch(rect_main)\n",
    "                        total_tiles += num_tiles\n",
    "                        ortho_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch processing: {e}\")\n",
    "        gc.collect()\n",
    "    ax.set_xlim(overall_bounds[0], overall_bounds[2])\n",
    "    ax.set_ylim(overall_bounds[1], overall_bounds[3])\n",
    "    ax.set_xlabel('x (m)')\n",
    "    ax.set_ylabel('y (m)')\n",
    "    ax.set_title('Tuiles pour toutes les orthophotos', fontsize=12, fontweight='bold')\n",
    "    info_text = f\"Orthophotos: {ortho_count}\\nTuiles totales: 38294\"\n",
    "    ax.text(0.02, 0.98, info_text, transform=ax.transAxes, \n",
    "           verticalalignment='top', horizontalalignment='left', \n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    ax.grid(False)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    if output_path:\n",
    "        print(f\"Saving to: {output_path}\")\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Visualization complete: {ortho_count} orthophotos, {total_tiles} tiles\")\n",
    "    return fig, ax\n",
    "\n",
    "def process_all_orthophotos(ortho_path, tile_path, output_path=None, max_workers=None):\n",
    "    \"\"\"\n",
    "    Runs the workflow to process all orthophotos and create a visualization.\n",
    "    \"\"\"\n",
    "    print(\"Starting optimized processing pipeline...\")\n",
    "    ortho_data, overall_bounds = collect_orthophoto_metadata(ortho_path, max_workers)\n",
    "    if not ortho_data:\n",
    "        print(\"No orthophoto data found\")\n",
    "        return None\n",
    "    ortho_data = match_tiles_to_orthophotos(ortho_data, tile_path, max_workers)\n",
    "    fig, ax = create_canton_visualization(ortho_data, overall_bounds, output_path)\n",
    "    return ortho_data, overall_bounds, fig, ax\n",
    "\n",
    "def run_optimized_processing(ortho_path, tile_path, output_path):\n",
    "    \"\"\"\n",
    "    Runs the complete processing pipeline with optimal worker count.\n",
    "    \"\"\"\n",
    "    cpu_count = mp.cpu_count()\n",
    "    optimal_workers = min(cpu_count, 16)\n",
    "    print(f\"Using {optimal_workers} workers for parallel processing\")\n",
    "    print(f\"Available CPU cores: {cpu_count}\")\n",
    "    return process_all_orthophotos(ortho_path, tile_path, output_path, optimal_workers)\n",
    "\n",
    "# Example usage with existing variables\n",
    "result = run_optimized_processing(\n",
    "    GEOTIFF_ORTHO2019_PATH, \n",
    "    TILE_1024_FOLDER_PATH, \n",
    "    os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_06_PNG)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch3 post_traitement dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph DatasetDistributionProcess {\n",
    "        rankdir=TB;\n",
    "        bgcolor=white;\n",
    "        fontname=\"Arial\";\n",
    "        fontsize=11;\n",
    "        pad=\"0.03\";\n",
    "        nodesep=\"0.8\";\n",
    "        ranksep=\"0.8\";\n",
    "        ratio=compress;\n",
    "        dpi=600;\n",
    "        size=\"10,10\"\n",
    "        ordering=out;\n",
    "        \n",
    "        // Base node style\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=11,\n",
    "              margin=\"0.15\", width=\"1.5\", height=\"0.4\", penwidth=1];\n",
    "        \n",
    "        // Edge style\n",
    "        edge [color=\"#2E86AB\", penwidth=2, arrowsize=0.8, fontsize=11];\n",
    "        \n",
    "        // Subgraph for dataset distribution workflow\n",
    "        subgraph cluster_0 {\n",
    "            label=\"Processus de répartition en datasets 5 k-folds et test\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            fontsize=11;\n",
    "            \n",
    "            // Step 1 - Light Blue\n",
    "            step1 [label=\"Rogner tuiles\\\\nannotées avec\\\\ncouche toitures\", \n",
    "                   fillcolor=\"#e7f5ff\", color=\"#4dabf7\"];\n",
    "            \n",
    "            // Step 2 - Light Green  \n",
    "            step2 [label=\"Problème fuite\\\\nde données\\\\nentre datasets\", \n",
    "                   fillcolor=\"#e6fcf5\", color=\"#38d9a9\"];\n",
    "            \n",
    "            // Step 3 - Light Yellow\n",
    "            step3 [label=\"Traitement des\\\\nchevauchements\\\\nentre les tuiles\", \n",
    "                   fillcolor=\"#fff9db\", color=\"#fcc419\"];\n",
    "            \n",
    "            // Step 4 - Light Orange\n",
    "            step4 [label=\"Distribution\\\\nstratifiée\\\\n5-fold CV + test\", \n",
    "                   fillcolor=\"#fff4e6\", color=\"#fd7e14\"];\n",
    "            \n",
    "            // Step 5 - Light Purple\n",
    "            step5 [label=\"Validation\\\\nde la distribution\\\\ndes datasets\", \n",
    "                   fillcolor=\"#f3f0ff\", color=\"#845ef7\"];\n",
    "            \n",
    "            // Step 6 - Light Pink\n",
    "            step6 [label=\"Datasets\\\\nprêts pour\\\\nl'entraînement\", \n",
    "                   fillcolor=\"#fdf2f8\", color=\"#ec4899\",\n",
    "                   penwidth=\"2\", style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for clean vertical layout\n",
    "        {rank=source; step1, step2, step3}\n",
    "        {rank=same; step4, step5, step6}\n",
    "        \n",
    "        // Sequential flow\n",
    "        step1 -> step2 -> step3;\n",
    "        step4 -> step3 [dir=back];\n",
    "        step6 -> step5 -> step4 [dir=back];\n",
    "\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# Save to file (adjust path as needed)\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, POST_TREATMENT_DATASET_01_OVERVIEW_PNG))\n",
    "\n",
    "display(png_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "df= gpd.read_parquet(TILE_1024_FOLDER_PATH + \"/combined_metadata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"egid\"].unique())\n",
    "# len(df[\"tile_path\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_toiture_7_classification = gpd.read_parquet(\"data/notebook_02/parquet/02_gdf_toiture_7_classification.parquet\")\n",
    "len(gdf_toiture_7_classification[\"egid\"].unique())\n",
    "\n",
    "# display the values that are in df[\"egid\"].unique() but not in gdf_toiture_7_classification[\"egid\"].unique()\n",
    "missing_egids = set(df[\"egid\"].unique()) - set(gdf_toiture_7_classification[\"egid\"].unique())\n",
    "print(f\"Missing EGIDs: {missing_egids}\")\n",
    "\n",
    "# remove from df egid that are not in gdf_toiture_7_classification\n",
    "df = df[df[\"egid\"].isin(gdf_toiture_7_classification[\"egid\"].unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch36 modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import logging\n",
    "import warnings\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings and set minimal logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('timm').setLevel(logging.ERROR)\n",
    "logging.getLogger('__main__').setLevel(logging.ERROR)\n",
    "\n",
    "@dataclass\n",
    "class ModelStats:\n",
    "    \"\"\"Stores statistics for a segmentation model.\"\"\"\n",
    "    architecture: str\n",
    "    backbone: str\n",
    "    encoder_params: int\n",
    "    decoder_params: int\n",
    "    head_params: int\n",
    "    total_params: int\n",
    "    decoder_ratio: float\n",
    "    encoder_ratio: float\n",
    "    status: str = \"success\"\n",
    "    error: Optional[str] = None\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    \"\"\"Analyzes segmentation model architectures and backbones.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Mapping of architecture names to model classes\n",
    "        self.model_creators = {\n",
    "            \"U-Net\": smp.Unet,\n",
    "            \"U-Net++\": smp.UnetPlusPlus,\n",
    "            \"MAnet\": smp.MAnet,\n",
    "            \"LinkNet\": smp.Linknet,\n",
    "            \"FPN\": smp.FPN,\n",
    "            \"PAN\": smp.PAN,\n",
    "            \"PSPNet\": smp.PSPNet,\n",
    "            \"SegFormer\": smp.Segformer,\n",
    "            \"DeepLabV3+\": smp.DeepLabV3Plus,\n",
    "            \"UPerNet\": smp.UPerNet,\n",
    "            \"DPT\": smp.DPT,\n",
    "        }\n",
    "        \n",
    "        # List of common backbones to test\n",
    "        self.common_backbones = [\n",
    "            \"timm-efficientnet-b3\",\n",
    "            \"tu-efficientvit_b2.r224_in1k\",\n",
    "            \"tu-fastvit_t8.apple_in1k\",\n",
    "            \"tu-repvit_m1.dist_in1k\",\n",
    "            \"tu-regnety_032.ra_in1k\",\n",
    "            \"tu-mambaout_small\",\n",
    "            \"tu-efficientnetv2_rw_s.ra2_in1k\",\n",
    "            \"tu-regnety_080.ra3_in1k\",\n",
    "            \"timm-res2net101_26w_4s\",\n",
    "            \"resnext50_32x4d\",\n",
    "            \"tu-mambaout_base\",\n",
    "            \"tu-efficientnetv2_rw_m.agc_in1k\",\n",
    "            \"timm-resnest200e\",\n",
    "            \"resnext101_32x8d\",\n",
    "            \"timm-efficientnet-b5\",\n",
    "            \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\"\n",
    "        ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_parameters(model_part) -> int:\n",
    "        \"\"\"Returns the number of parameters in a model component.\"\"\"\n",
    "        return sum(p.numel() for p in model_part.parameters())\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_params(count: int) -> str:\n",
    "        \"\"\"Formats parameter count for readability.\"\"\"\n",
    "        if count >= 1e9:\n",
    "            return f\"{count/1e9:.2f}B\"\n",
    "        elif count >= 1e6:\n",
    "            return f\"{count/1e6:.2f}M\"\n",
    "        elif count >= 1e3:\n",
    "            return f\"{count/1e3:.2f}K\"\n",
    "        else:\n",
    "            return str(count)\n",
    "    \n",
    "    def analyze_model(self, architecture: str, model_class, backbone: str = \"resnet34\") -> ModelStats:\n",
    "        \"\"\"Analyzes a single model architecture with the specified backbone.\"\"\"\n",
    "        try:\n",
    "            model_params = {\n",
    "                \"encoder_name\": backbone,\n",
    "                \"encoder_weights\": \"imagenet\",\n",
    "                \"in_channels\": 3,\n",
    "                \"classes\": 1,\n",
    "                \"activation\": None,\n",
    "            }\n",
    "            model = model_class(**model_params)\n",
    "            total_params = self.count_parameters(model)\n",
    "            encoder_params = self.count_parameters(model.encoder) if hasattr(model, 'encoder') else 0\n",
    "            decoder_params = self.count_parameters(model.decoder) if hasattr(model, 'decoder') else 0\n",
    "            head_params = 0\n",
    "            if hasattr(model, 'segmentation_head'):\n",
    "                head_params = self.count_parameters(model.segmentation_head)\n",
    "            elif hasattr(model, 'classification_head'):\n",
    "                head_params = self.count_parameters(model.classification_head)\n",
    "            decoder_ratio = (decoder_params / total_params * 100) if total_params > 0 else 0\n",
    "            encoder_ratio = (encoder_params / total_params * 100) if total_params > 0 else 0\n",
    "            return ModelStats(\n",
    "                architecture=architecture,\n",
    "                backbone=backbone,\n",
    "                encoder_params=encoder_params,\n",
    "                decoder_params=decoder_params,\n",
    "                head_params=head_params,\n",
    "                total_params=total_params,\n",
    "                decoder_ratio=decoder_ratio,\n",
    "                encoder_ratio=encoder_ratio\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return ModelStats(\n",
    "                architecture=architecture,\n",
    "                backbone=backbone,\n",
    "                encoder_params=0,\n",
    "                decoder_params=0,\n",
    "                head_params=0,\n",
    "                total_params=0,\n",
    "                decoder_ratio=0,\n",
    "                encoder_ratio=0,\n",
    "                status=\"error\",\n",
    "                error=str(e)[:100]\n",
    "            )\n",
    "    \n",
    "    def analyze_architectures(self, backbone: str = \"resnet34\") -> List[ModelStats]:\n",
    "        \"\"\"Analyzes all architectures using the specified backbone.\"\"\"\n",
    "        print(f\"Analyzing Model Architectures (Backbone: {backbone})\")\n",
    "        print(\"=\" * 90)\n",
    "        results = []\n",
    "        for arch_name, model_class in self.model_creators.items():\n",
    "            print(f\"Testing {arch_name}...\", end=\" \")\n",
    "            stats = self.analyze_model(arch_name, model_class, backbone)\n",
    "            results.append(stats)\n",
    "            if stats.status == \"success\":\n",
    "                print(\"OK\")\n",
    "            else:\n",
    "                print(f\"FAILED ({stats.error[:30]}...)\")\n",
    "        self._display_architecture_results(results, backbone)\n",
    "        return results\n",
    "    \n",
    "    def analyze_backbones(self, architecture: str = \"U-Net\") -> List[ModelStats]:\n",
    "        \"\"\"Analyzes different backbones for a single architecture.\"\"\"\n",
    "        print(f\"\\nAnalyzing Backbones (Architecture: {architecture})\")\n",
    "        print(\"=\" * 90)\n",
    "        model_class = self.model_creators.get(architecture)\n",
    "        if not model_class:\n",
    "            print(f\"FAILED: Architecture '{architecture}' not found!\")\n",
    "            return []\n",
    "        results = []\n",
    "        for backbone in self.common_backbones:\n",
    "            print(f\"Testing {backbone}...\", end=\" \")\n",
    "            stats = self.analyze_model(architecture, model_class, backbone)\n",
    "            results.append(stats)\n",
    "            if stats.status == \"success\":\n",
    "                print(\"OK\")\n",
    "            else:\n",
    "                print(f\"FAILED ({stats.error[:30]}...)\")\n",
    "        self._display_backbone_results(results)\n",
    "        return results\n",
    "    \n",
    "    def _display_architecture_results(self, results: List[ModelStats], backbone: str):\n",
    "        \"\"\"Displays a table comparing architectures.\"\"\"\n",
    "        print(\"\\nArchitecture Comparison Results\")\n",
    "        print(\"-\" * 90)\n",
    "        successful_results = [r for r in results if r.status == \"success\"]\n",
    "        failed_results = [r for r in results if r.status == \"error\"]\n",
    "        if successful_results:\n",
    "            successful_results.sort(key=lambda x: x.decoder_params, reverse=True)\n",
    "            headers = [\"Architecture\", \"Decoder\", \"Encoder\", \"Head\", \"Total\", \"Dec%\", \"Enc%\"]\n",
    "            table_data = []\n",
    "            for stats in successful_results:\n",
    "                table_data.append([\n",
    "                    stats.architecture,\n",
    "                    self.format_params(stats.decoder_params),\n",
    "                    self.format_params(stats.encoder_params),\n",
    "                    self.format_params(stats.head_params),\n",
    "                    self.format_params(stats.total_params),\n",
    "                    f\"{stats.decoder_ratio:.1f}%\",\n",
    "                    f\"{stats.encoder_ratio:.1f}%\"\n",
    "                ])\n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "            self._print_architecture_summary(successful_results, backbone)\n",
    "        if failed_results:\n",
    "            print(f\"\\nFailed Models ({len(failed_results)}):\")\n",
    "            for result in failed_results:\n",
    "                print(f\"  • {result.architecture}: {result.error}\")\n",
    "    \n",
    "    def _display_backbone_results(self, results: List[ModelStats]):\n",
    "        \"\"\"Displays a table comparing backbones.\"\"\"\n",
    "        print(\"\\nBackbone Comparison Results\")\n",
    "        print(\"-\" * 70)\n",
    "        successful_results = [r for r in results if r.status == \"success\"]\n",
    "        failed_results = [r for r in results if r.status == \"error\"]\n",
    "        if successful_results:\n",
    "            successful_results.sort(key=lambda x: x.total_params)\n",
    "            headers = [\"Backbone\", \"Encoder\", \"Decoder\", \"Total\", \"Enc%\"]\n",
    "            table_data = []\n",
    "            for stats in successful_results:\n",
    "                table_data.append([\n",
    "                    stats.backbone,\n",
    "                    self.format_params(stats.encoder_params),\n",
    "                    self.format_params(stats.decoder_params),\n",
    "                    self.format_params(stats.total_params),\n",
    "                    f\"{stats.encoder_ratio:.1f}%\"\n",
    "                ])\n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "            self._print_backbone_summary(successful_results)\n",
    "        if failed_results:\n",
    "            print(f\"\\nFailed Backbones ({len(failed_results)}):\")\n",
    "            for result in failed_results:\n",
    "                print(f\"  • {result.backbone}: {result.error}\")\n",
    "    \n",
    "    def _print_architecture_summary(self, results: List[ModelStats], backbone: str):\n",
    "        \"\"\"Prints summary statistics for architecture analysis.\"\"\"\n",
    "        print(f\"\\nSummary Statistics (Backbone: {backbone})\")\n",
    "        print(\"-\" * 50)\n",
    "        if not results:\n",
    "            print(\"No successful results to analyze.\")\n",
    "            return\n",
    "        decoder_sizes = [r.decoder_params for r in results]\n",
    "        min_decoder = min(results, key=lambda x: x.decoder_params)\n",
    "        max_decoder = max(results, key=lambda x: x.decoder_params)\n",
    "        print(f\"Models analyzed: {len(results)}\")\n",
    "        print(f\"Encoder size: {self.format_params(results[0].encoder_params)} (consistent)\")\n",
    "        print(f\"Decoder range: {self.format_params(min(decoder_sizes))} - {self.format_params(max(decoder_sizes))}\")\n",
    "        print(f\"Smallest decoder: {min_decoder.architecture} ({self.format_params(min_decoder.decoder_params)})\")\n",
    "        print(f\"Largest decoder: {max_decoder.architecture} ({self.format_params(max_decoder.decoder_params)})\")\n",
    "        efficient_models = [r for r in results if r.decoder_ratio < 10]\n",
    "        heavy_models = [r for r in results if r.decoder_ratio > 25]\n",
    "        print(\"\\nInsights:\")\n",
    "        print(f\"  • Efficient models (<10% decoder): {[r.architecture for r in efficient_models]}\")\n",
    "        print(f\"  • Heavy decoders (>25% decoder): {[r.architecture for r in heavy_models]}\")\n",
    "        print(\"\\nRecommendations:\")\n",
    "        print(f\"  • For speed: {min_decoder.architecture} (smallest decoder)\")\n",
    "        print(f\"  • For accuracy: {max_decoder.architecture} (largest decoder)\")\n",
    "        balanced = min(results, key=lambda x: abs(x.decoder_ratio - 15))\n",
    "        print(f\"  • For balance: {balanced.architecture} ({balanced.decoder_ratio:.1f}% decoder)\")\n",
    "    \n",
    "    def _print_backbone_summary(self, results: List[ModelStats]):\n",
    "        \"\"\"Prints summary statistics for backbone analysis.\"\"\"\n",
    "        print(\"\\nSummary Statistics\")\n",
    "        print(\"-\" * 30)\n",
    "        if not results:\n",
    "            print(\"No successful results to analyze.\")\n",
    "            return\n",
    "        min_total = min(results, key=lambda x: x.total_params)\n",
    "        max_total = max(results, key=lambda x: x.total_params)\n",
    "        print(f\"Backbones tested: {len(results)}\")\n",
    "        print(f\"Size range: {self.format_params(min_total.total_params)} - {self.format_params(max_total.total_params)}\")\n",
    "        print(f\"Smallest: {min_total.backbone} ({self.format_params(min_total.total_params)})\")\n",
    "        print(f\"Largest: {max_total.backbone} ({self.format_params(max_total.total_params)})\")\n",
    "        decoder_sizes = [r.decoder_params for r in results]\n",
    "        if len(set(decoder_sizes)) == 1:\n",
    "            print(f\"Decoder size: {self.format_params(decoder_sizes[0])} (consistent across backbones)\")\n",
    "        else:\n",
    "            print(f\"Decoder varies: {self.format_params(min(decoder_sizes))} - {self.format_params(max(decoder_sizes))}\")\n",
    "    \n",
    "    def create_comparison_plot(self, arch_results: List[ModelStats], backbone_results: List[ModelStats]):\n",
    "        \"\"\"Creates plots for architecture and backbone comparisons.\"\"\"\n",
    "       \n",
    "        def compare_architectures(arch_results):\n",
    "            \"\"\"Plots decoder sizes for different architectures.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            pastel_palette = sns.color_palette(\"pastel\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            successful_arch = [r for r in arch_results if r.status == \"success\"]\n",
    "            if successful_arch:\n",
    "                archs = [r.architecture for r in successful_arch]\n",
    "                archs_ordered = ['U-Net', 'FPN', 'PSPNet', 'LinkNet', 'U-Net++', 'DeepLabV3+', 'PAN', 'UPerNet', 'MAnet', 'SegFormer', 'DPT']\n",
    "                archs = sorted(archs, key=lambda x: archs_ordered.index(x) if x in archs_ordered else len(archs_ordered))\n",
    "                decoder_sizes = [r.decoder_params / 1e6 for r in successful_arch]\n",
    "                ax1.bar(archs, decoder_sizes, color=pastel_palette[:len(archs)], alpha=0.85)\n",
    "                ax1.set_title('Decoder Size', fontsize=11, fontweight='bold')\n",
    "                ax1.set_ylabel('Parameters (Millions)')\n",
    "                ax1.tick_params(axis='x', rotation=45)\n",
    "                for i, v in enumerate(decoder_sizes):\n",
    "                    ax1.text(i, v + 1.5, f\"{v:.1f}\", ha='center', va='top', fontsize=10)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, ARCHITECTURE_SIZE_DECODER_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        def compare_backbones_family(backbone_results):\n",
    "            \"\"\"Plots encoder sizes grouped by backbone family.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            backbone_families = {\n",
    "                \"ResNext\": ['resnext50', 'resnext101'],\n",
    "                \"EfficientNet\" : [\"efficientnet-b3\", \"efficientnet-b5\"],\n",
    "                \"RegNetY\" : [\"regnety_032\", \"regnety_080\"],\n",
    "                \"ResNeSt\": [\"resnest200e\"],\n",
    "                \"EfficientNetV2\": [\"efficientnetv2_rw_s\", \"efficientnetv2_rw_m\", \"tf_efficientnetv2_xl\"],\n",
    "                \"Res2Net\": [\"res2net101_26w_4s\"],\n",
    "                \"FastViT\": [\"fastvit_t8\"],\n",
    "                \"RepViT\": [\"repvit_m1\"],\n",
    "                \"MambaOut\": [\"mambaout_small\", \"mambaout_base\"],\n",
    "                \"EfficientViT\": [\"efficientvit_b2\"],\n",
    "            }\n",
    "            grouped = {}\n",
    "            for family in backbone_families.keys():\n",
    "                grouped[family] = []\n",
    "            successful_backbones = [r for r in backbone_results if r.status == \"success\"]\n",
    "            for result in successful_backbones:\n",
    "                backbone_name = result.backbone.lower()\n",
    "                family_found = False\n",
    "                for family, keywords in backbone_families.items():\n",
    "                    if family == 'Others':\n",
    "                        continue\n",
    "                    if any(keyword in backbone_name for keyword in keywords):\n",
    "                        grouped[family].append(result)\n",
    "                        family_found = True\n",
    "                        break\n",
    "                if not family_found:\n",
    "                    grouped['Others'].append(result)\n",
    "            grouped = {family: results for family, results in grouped.items() if results}\n",
    "            for family in grouped:\n",
    "                grouped[family].sort(key=lambda x: x.encoder_params)\n",
    "            all_backbones = []\n",
    "            all_encoder_sizes = []\n",
    "            family_colors = []\n",
    "            family_boundaries = []\n",
    "            family_names = list(grouped.keys())\n",
    "            family_palette = sns.color_palette(\"pastel\", len(family_names))\n",
    "            color_map = {family: color for family, color in zip(family_names, family_palette)}\n",
    "            current_pos = 0\n",
    "            for family, results in grouped.items():\n",
    "                for result in results:\n",
    "                    all_backbones.append(result.backbone)\n",
    "                    all_encoder_sizes.append(result.encoder_params / 1e6)\n",
    "                    family_colors.append(color_map[family])\n",
    "                    current_pos += 1\n",
    "                family_end = current_pos - 1\n",
    "                family_boundaries.append(family_end + 0.5)\n",
    "            if family_boundaries:\n",
    "                family_boundaries.pop()\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            bars = ax1.bar(range(len(all_backbones)), all_encoder_sizes, \n",
    "                        color=family_colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "            ax1.set_title(\"Encoders Grouped by Architecture Type\", fontsize=11, fontweight='bold')\n",
    "            ax1.set_ylabel('Parameters (Millions)')\n",
    "            ax1.set_xticks(range(len(all_backbones)))\n",
    "            bb_readable = {\n",
    "                \"timm-efficientnet-b3\": \"EfficientNet-B3\",\n",
    "                \"timm-efficientnet-b5\": \"EfficientNet-B5\",\n",
    "                \"tu-efficientvit_b2.r224_in1k\": \"EfficientViT-B2\",\n",
    "                \"tu-fastvit_t8.apple_in1k\": \"FastViT-T8\",\n",
    "                \"tu-repvit_m1.dist_in1k\": \"RepViT-M1\",\n",
    "                \"tu-regnety_032.ra_in1k\": \"RegNetY-032\",\n",
    "                \"tu-regnety_080.ra3_in1k\": \"RegNetY-080\",\n",
    "                \"tu-mambaout_small\": \"MambaOut-Small\",\n",
    "                \"tu-mambaout_base\": \"MambaOut-Base\",\n",
    "                \"tu-efficientnetv2_rw_s.ra2_in1k\": \"EfficientNetV2-S\",\n",
    "                \"tu-efficientnetv2_rw_m.agc_in1k\": \"EfficientNetV2-M\",\n",
    "                \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\": \"EfficientNetV2-XL\",\n",
    "                \"timm-res2net101_26w_4s\": \"Res2Net-101\",\n",
    "                \"resnext50_32x4d\": \"ResNeXt-50\",\n",
    "                \"resnext101_32x8d\": \"ResNeXt-101\",\n",
    "                \"timm-resnest200e\": \"ResNeSt-200E\",\n",
    "            }\n",
    "            readable_labels = [bb_readable.get(bb, bb) for bb in all_backbones]\n",
    "            ax1.set_xticklabels(readable_labels, rotation=90, ha='center', fontsize=10)\n",
    "            for i, v in enumerate(all_encoder_sizes):\n",
    "                ax1.text(i, v + max(all_encoder_sizes) * 0.005, f\"{v:.1f}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            for boundary in family_boundaries:\n",
    "                ax1.axvline(x=boundary, color='lightgray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            plt.ylim(0, max(all_encoder_sizes) * 1.07)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, BACKBONE_SIZE_ENCODER_FAMILY_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        def compare_backbones_size(backbone_results):\n",
    "            \"\"\"Plots encoder sizes ordered by parameter count.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            backbone_families = {\n",
    "                \"ResNext\": ['resnext50', 'resnext101'],\n",
    "                \"EfficientNet\" : [\"efficientnet-b3\", \"efficientnet-b5\"],\n",
    "                \"RegNetY\" : [\"regnety_032\", \"regnety_080\"],\n",
    "                \"ResNeSt\": [\"resnest200e\"],\n",
    "                \"EfficientNetV2\": [\"efficientnetv2_rw_s\", \"efficientnetv2_rw_m\", \"tf_efficientnetv2_xl\"],\n",
    "                \"Res2Net\": [\"res2net101_26w_4s\"],\n",
    "                \"FastViT\": [\"fastvit_t8\"],\n",
    "                \"RepViT\": [\"repvit_m1\"],\n",
    "                \"MambaOut\": [\"mambaout_small\", \"mambaout_base\"],\n",
    "                \"EfficientViT\": [\"efficientvit_b2\"],\n",
    "            }\n",
    "            family_names = list(backbone_families.keys())\n",
    "            family_palette = sns.color_palette(\"pastel\", len(family_names))\n",
    "            color_map = {family: color for family, color in zip(family_names, family_palette)}\n",
    "            def get_backbone_family(backbone_name):\n",
    "                backbone_lower = backbone_name.lower()\n",
    "                for family, keywords in backbone_families.items():\n",
    "                    if any(keyword in backbone_lower for keyword in keywords):\n",
    "                        return family\n",
    "                return \"Others\"\n",
    "            successful_backbones = [r for r in backbone_results if r.status == \"success\"]\n",
    "            all_backbones = []\n",
    "            all_encoder_sizes = []\n",
    "            for result in successful_backbones:\n",
    "                all_backbones.append(result.backbone)\n",
    "                all_encoder_sizes.append(result.encoder_params / 1e6)\n",
    "            backbone_size_pairs = list(zip(all_backbones, all_encoder_sizes))\n",
    "            backbone_size_pairs.sort(key=lambda x: x[1])\n",
    "            sorted_backbones, sorted_sizes = zip(*backbone_size_pairs)\n",
    "            sorted_backbones = list(sorted_backbones)\n",
    "            sorted_sizes = list(sorted_sizes)\n",
    "            bar_colors = []\n",
    "            for backbone in sorted_backbones:\n",
    "                family = get_backbone_family(backbone)\n",
    "                if family in color_map:\n",
    "                    bar_colors.append(color_map[family])\n",
    "                else:\n",
    "                    bar_colors.append('lightgray')\n",
    "            bb_readable = {\n",
    "                \"timm-efficientnet-b3\": \"EfficientNet-B3\",\n",
    "                \"timm-efficientnet-b5\": \"EfficientNet-B5\",\n",
    "                \"tu-efficientvit_b2.r224_in1k\": \"EfficientViT-B2\",\n",
    "                \"tu-fastvit_t8.apple_in1k\": \"FastViT-T8\",\n",
    "                \"tu-repvit_m1.dist_in1k\": \"RepViT-M1\",\n",
    "                \"tu-regnety_032.ra_in1k\": \"RegNetY-032\",\n",
    "                \"tu-regnety_080.ra3_in1k\": \"RegNetY-080\",\n",
    "                \"tu-mambaout_small\": \"MambaOut-Small\",\n",
    "                \"tu-mambaout_base\": \"MambaOut-Base\",\n",
    "                \"tu-efficientnetv2_rw_s.ra2_in1k\": \"EfficientNetV2-S\",\n",
    "                \"tu-efficientnetv2_rw_m.agc_in1k\": \"EfficientNetV2-M\",\n",
    "                \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\": \"EfficientNetV2-XL\",\n",
    "                \"timm-res2net101_26w_4s\": \"Res2Net-101\",\n",
    "                \"resnext50_32x4d\": \"ResNeXt-50\",\n",
    "                \"resnext101_32x8d\": \"ResNeXt-101\",\n",
    "                \"timm-resnest200e\": \"ResNeSt-200E\",\n",
    "            }\n",
    "            readable_labels = [bb_readable.get(bb, bb) for bb in sorted_backbones]\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            bars = ax1.bar(range(len(sorted_backbones)), sorted_sizes, \n",
    "                        color=bar_colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "            ax1.set_title(\"Encoders Ordered by Parameter Count\", fontsize=11, fontweight='bold')\n",
    "            ax1.set_ylabel('Parameters (Millions)')\n",
    "            ax1.set_xticks(range(len(readable_labels)))\n",
    "            ax1.set_xticklabels(readable_labels, rotation=90, ha='center', fontsize=10)\n",
    "            for i, v in enumerate(sorted_sizes):\n",
    "                ax1.text(i, v + max(sorted_sizes) * 0.005, f\"{v:.1f}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            plt.ylim(0, max(sorted_sizes) * 1.07)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, BACKBONE_SIZE_ENCODER_ORDER_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        compare_architectures(arch_results)\n",
    "        compare_backbones_family(backbone_results)\n",
    "        compare_backbones_size(backbone_results)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Runs the segmentation model analysis.\"\"\"\n",
    "    print(\"Segmentation Models Analysis Tool\")\n",
    "    print(\"=\" * 50)\n",
    "    analyzer = ModelAnalyzer()\n",
    "    arch_results = analyzer.analyze_architectures(\"tu-resnet34\")\n",
    "    backbone_results = analyzer.analyze_backbones(\"U-Net\")\n",
    "    try:\n",
    "        analyzer.create_comparison_plot(arch_results, backbone_results)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nVisualization skipped: {e}\")\n",
    "    print(\"\\nAnalysis complete.\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
