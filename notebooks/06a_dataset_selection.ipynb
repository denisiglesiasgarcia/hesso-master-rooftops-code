{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset selection pour notebook 04b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's date for output naming\n",
    "todays_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "GEOPARQUET_CLASSIFICATION_PATH = \"data/notebook_02/parquet/02_gdf_toiture_7_classification.parquet\"\n",
    "SPLIT_GEOTIFF_1024_PARQUET = \"data/notebook_04/geotiff/tile_1024_split/combined_metadata.parquet\"\n",
    "SAMPLES_PER_CAT = 8\n",
    "\n",
    "GRAPHICS_PATH = \"data/notebook_06/graphics\"\n",
    "GPKG_SELECTION_DATASET = \"data/notebook_06/parquet/06a_02_dataset.gpkg\"\n",
    "GPKG_CAD_COMMUNE = \"data/SITG/CAD_COMMUNE_2024-11-03.gpkg\"\n",
    "\n",
    "CONVERT_GEOTIFF_TO_PNG = True\n",
    "\n",
    "# Output directory for PNG files\n",
    "PNG_OUTPUT_PATH = f\"data/notebook_06/dataset_{todays_date}\"\n",
    "os.makedirs(PNG_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(os.path.exists(GEOPARQUET_CLASSIFICATION_PATH))\n",
    "assert(os.path.exists(GRAPHICS_PATH))\n",
    "assert(os.path.exists(PNG_OUTPUT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_toiture_7_classification = gpd.read_parquet(GEOPARQUET_CLASSIFICATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(gdf_toiture_7_classification[\"egid\"].isna().sum() == 0)\n",
    "gdf_toiture_7_classification[\"egid\"].duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_toiture_7_classification[\"egid\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage et enrichir les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geotiff parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_geotiff = pd.read_parquet(SPLIT_GEOTIFF_1024_PARQUET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_geotiff.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_toiture_7_classification.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sia_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy split geotiff dataframe\n",
    "df_split_geotiff_sia_cat = df_split_geotiff.copy()\n",
    "\n",
    "# Find common columns, excluding geometry\n",
    "common_columns = set(df_split_geotiff_sia_cat.columns) & set(gdf_toiture_7_classification.columns)\n",
    "common_columns = list(common_columns - {\"geometry\"})\n",
    "\n",
    "# Merge classification with split geotiff data\n",
    "df_split_geotiff_sia_cat = pd.merge(\n",
    "    gdf_toiture_7_classification,\n",
    "    df_split_geotiff_sia_cat,\n",
    "    on=common_columns,\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_geotiff_sia_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all roofs are associated with a tile\n",
    "assert(len(df_split_geotiff_sia_cat[df_split_geotiff_sia_cat[\"tile_path\"].isnull()][[\"egid\", \"SHAPE__Area\", \"globalid\", \"sia_cat\", \"tile_id\"]].sort_values(by=[\"SHAPE__Area\"], ascending=False)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enriched dataframe to Parquet\n",
    "df_split_geotiff_sia_cat.to_parquet(\"data/notebook_06/06a_02_split_geotiff_sia_cat.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the enriched dataframe\n",
    "df_selection = df_split_geotiff_sia_cat.copy()\n",
    "\n",
    "# Shuffle rows for randomness\n",
    "df_selection = df_selection.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "display(df_selection.head(5))\n",
    "display(df_selection.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egid par tile\n",
    "df_selection.groupby(\"tile_id\")[\"egid\"].nunique().reset_index().sort_values(by=[\"egid\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of SHAPE__Area by tile_id\n",
    "df_selection.groupby(\"tile_id\")[\"SHAPE__Area\"].sum().reset_index().sort_values(by=[\"SHAPE__Area\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat SIA par tile\n",
    "df_selection.groupby(\"tile_id\")[\"sia_cat\"].nunique().reset_index().sort_values(by=[\"sia_cat\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique egid per tile\n",
    "df_selection[\"egid_per_tile\"] = df_selection.groupby(\"tile_id\")[\"egid\"].transform(\"nunique\")\n",
    "\n",
    "# Number of unique sia_cat per tile\n",
    "df_selection[\"sia_cat_per_tile\"] = df_selection.groupby(\"tile_id\")[\"sia_cat\"].transform(\"nunique\")\n",
    "\n",
    "# Total SHAPE__Area per tile\n",
    "df_selection[\"SHAPE__Area_sum_per_tile\"] = df_selection.groupby(\"tile_id\")[\"SHAPE__Area\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection SIA_cat + area_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Aggregate roof data by tile_id\n",
    "tile_groups = df_selection.groupby('tile_id').agg({\n",
    "    'globalid': list,\n",
    "    'geometry_x': list,\n",
    "    'sia_cat': list,\n",
    "    'altitude_min': 'mean',\n",
    "    'altitude_max': 'mean',\n",
    "    'date_leve': 'first',\n",
    "    'tile_path': 'first',\n",
    "    'tile_bounds': 'first',\n",
    "    \"SHAPE__Area\": 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Assign dominant SIA class per tile\n",
    "tile_groups['dominant_class'] = tile_groups['sia_cat'].apply(\n",
    "    lambda x: Counter(x).most_common(1)[0][0]\n",
    ")\n",
    "\n",
    "# Bin tiles by total area\n",
    "area_bins = [0, 200, 500, 1000, 2000, 5000, np.inf]\n",
    "tile_groups['area_bin'] = pd.cut(\n",
    "    tile_groups['SHAPE__Area'],\n",
    "    bins=area_bins,\n",
    "    labels=[\n",
    "        '0-200', '200-500', '500-1000',\n",
    "        '1000-2000', '2000-5000', '5000+'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Manual Bins:\")\n",
    "print(tile_groups['area_bin'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample up to SAMPLES_PER_CAT tiles per dominant_class and area_bin\n",
    "def sample_tiles(group, n_samples):\n",
    "    if len(group) > n_samples:\n",
    "        return group.sample(n=n_samples, random_state=42)\n",
    "    return group\n",
    "\n",
    "sampled_df = tile_groups.groupby(['dominant_class', 'area_bin']).apply(\n",
    "    sample_tiles, n_samples=SAMPLES_PER_CAT\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Convert tile_bounds to Polygon geometry\n",
    "def convert_bounds_to_polygon(bounds):\n",
    "    if isinstance(bounds, str):\n",
    "        bounds = tuple(map(float, bounds.strip(\"()\").split(\",\")))\n",
    "    if len(bounds) == 4:\n",
    "        minx, miny, maxx, maxy = bounds\n",
    "        return Polygon([(minx, miny), (maxx, miny), (maxx, maxy), (minx, maxy)])\n",
    "    raise ValueError(f\"Invalid bounds format: {bounds}\")\n",
    "\n",
    "sampled_df['geometry'] = sampled_df['tile_bounds'].apply(convert_bounds_to_polygon)\n",
    "\n",
    "# Create GeoDataFrame and save to file\n",
    "sampled_gdf = gpd.GeoDataFrame(sampled_df, geometry='geometry', crs='EPSG:2056')\n",
    "sampled_gdf.to_file(GPKG_SELECTION_DATASET, driver=\"GPKG\", layer=\"sampled_tiles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "### Graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count dominant SIA classes per tile\n",
    "class_counts = tile_groups['dominant_class'].value_counts().reset_index()\n",
    "class_counts.columns = ['Classe SIA', 'Nombre de tiles']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(6.5, 5.5))\n",
    "plot = sns.barplot(\n",
    "    x='Classe SIA', \n",
    "    y='Nombre de tiles', \n",
    "    data=class_counts.sort_values(by='Classe SIA'),\n",
    "    palette='pastel',\n",
    ")\n",
    "\n",
    "# Improve label readability\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "total_tiles = class_counts['Nombre de tiles'].sum()\n",
    "\n",
    "plt.title(\"Distribution des classes SIA dominantes par tuile\", fontsize=12, pad=10, fontweight='bold')\n",
    "plt.xlabel(\"Classe SIA\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Annotate bar values\n",
    "for p in plot.patches:\n",
    "    plot.annotate(\n",
    "        f'{int(p.get_height())}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black',\n",
    "        xytext=(0, 5), \n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"06a_01_dominant_class_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "# Count tiles per area bin\n",
    "area_counts = tile_groups['area_bin'].value_counts().reset_index()\n",
    "area_counts.columns = ['Area Bin', 'Nombre de tiles']\n",
    "area_counts = area_counts.sort_values(by='Area Bin')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(6.5, 4.5))\n",
    "plot = sns.barplot(\n",
    "    x='Area Bin', \n",
    "    y='Nombre de tiles', \n",
    "    data=area_counts,\n",
    "    palette='pastel',\n",
    ")\n",
    "\n",
    "total_tiles = area_counts['Nombre de tiles'].sum()\n",
    "\n",
    "plt.title(\"Distribution des tuiles par intervalle de surface\", fontsize=12, fontweight='bold', pad=10)\n",
    "plt.xlabel(\"Somme des surfaces par tuile en m²\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=10)\n",
    "plot.xaxis.get_offset_text().set_fontsize(10)\n",
    "plot.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "# Annotate bar values\n",
    "for p in plot.patches:\n",
    "    plot.annotate(\n",
    "        f'{int(p.get_height())}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=10, \n",
    "        color='black',\n",
    "        xytext=(0, 5), \n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"06a_02_area_bin_distribution.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Prepare data for stacked bar plot\n",
    "stacked_data = sampled_df.groupby(['dominant_class', 'area_bin']).size().unstack().fillna(0)\n",
    "area_order = ['0-200', '200-500', '500-1000', '1000-2000', '2000-5000', '5000+']\n",
    "stacked_data = stacked_data.reindex(columns=area_order)\n",
    "\n",
    "colors = sns.color_palette(\"pastel\", len(stacked_data.columns))\n",
    "\n",
    "plt.figure(figsize=(6.5, 5.5))\n",
    "\n",
    "stacked_data.plot(\n",
    "    kind='bar', \n",
    "    stacked=True, \n",
    "    color=colors,\n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "total_samples = stacked_data.sum().sum()\n",
    "plt.title(f\"Distribution du dataset des classes SIA dominantes\\npar intervalle de surface (n={int(total_samples)})\", \n",
    "          fontsize=12, pad=20, fontweight='bold')\n",
    "plt.xlabel(\"Classe SIA dominante\", fontsize=10)\n",
    "plt.ylabel(\"Nombre de tuiles\", fontsize=10)\n",
    "plt.tick_params(axis='both', labelsize=10)\n",
    "plot.xaxis.get_offset_text().set_fontsize(10)\n",
    "plot.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "plt.legend(\n",
    "    title=\"Surface totale\\n par tuile (m²)\", \n",
    "    bbox_to_anchor=(1.05, 1), \n",
    "    loc='upper left',\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    fontsize=10,\n",
    "    title_fontsize=10,\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "plt.ylim(0, 55)\n",
    "sns.despine()\n",
    "plt.grid(False)\n",
    "\n",
    "# Annotate total per bar\n",
    "for i, total in enumerate(stacked_data.sum(axis=1)):\n",
    "    plt.text(i, total + 0.5, f'{int(total)}', \n",
    "             ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# Annotate segments with low sample count\n",
    "for i, (index, row) in enumerate(stacked_data.iterrows()):\n",
    "    bottom = 0\n",
    "    annotation_count = 0\n",
    "    for j, (area_bin, count) in enumerate(row.items()):\n",
    "        if 0 < count < 8:\n",
    "            segment_middle = bottom + count/2\n",
    "            offset = 0.4\n",
    "            x_offset = i + offset if annotation_count % 2 == 0 else i - offset\n",
    "            plt.text(x_offset, segment_middle, f'{int(count)}', \n",
    "                     ha='center', va='center', fontsize=9, \n",
    "                     color='black', fontweight='demibold')\n",
    "            annotation_count += 1\n",
    "        bottom += count\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"06a_03_stacked.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vue en plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_to_polygon(bounds_str):\n",
    "    \"\"\"Convert '(minx, miny, maxx, maxy)' string to Polygon.\"\"\"\n",
    "    try:\n",
    "        coords = [float(x) for x in bounds_str.strip(\"()\").split(\", \")]\n",
    "        return Polygon([\n",
    "            (coords[0], coords[1]),\n",
    "            (coords[2], coords[1]),\n",
    "            (coords[2], coords[3]),\n",
    "            (coords[0], coords[3])\n",
    "        ])\n",
    "    except ValueError:\n",
    "        logging.error(f\"Error converting bounds to polygon: {bounds_str}\")\n",
    "        return None\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Add geometry column\n",
    "tile_groups['geometry'] = tile_groups['tile_bounds'].apply(bounds_to_polygon)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(tile_groups, geometry='geometry', crs=\"EPSG:2056\")\n",
    "\n",
    "unique_classes = sorted(gdf['dominant_class'].unique())\n",
    "palette = sns.color_palette('tab20', n_colors=len(unique_classes))\n",
    "color_dict = dict(zip(unique_classes, palette))\n",
    "\n",
    "# Plot tiles by dominant class\n",
    "ax = gdf.plot(\n",
    "    figsize=(15, 15),\n",
    "    column='dominant_class',\n",
    "    legend=True,\n",
    "    legend_kwds={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
    "    edgecolor='black',\n",
    "    linewidth=0.3,\n",
    "    alpha=0.7,\n",
    "    color=gdf['dominant_class'].map(color_dict)\n",
    ")\n",
    "\n",
    "# Overlay commune boundaries\n",
    "cad_commune = gpd.read_file(GPKG_CAD_COMMUNE, layer=\"CAD_COMMUNE\")\n",
    "cad_commune = cad_commune.to_crs(\"EPSG:2056\")\n",
    "cad_commune.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=0.2)\n",
    "\n",
    "# Custom legend\n",
    "ax.legend(\n",
    "    handles=[plt.Line2D([0], [0], marker='o', color='w', label=cls, \n",
    "                        markerfacecolor=color_dict[cls], markersize=10) for cls in unique_classes],\n",
    "    title=\"Classe SIA dominante\",\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(1, 1)\n",
    ")\n",
    "\n",
    "ax.set_title(f\"Tile par catégorie SIA dominante (total {len(tile_groups)} tiles)\", fontsize=16, pad=20)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"06a_04_map_tiles_group.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "# Geometry from bounds\n",
    "sampled_df['geometry'] = sampled_df['tile_bounds'].apply(bounds_to_polygon)\n",
    "\n",
    "# GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(sampled_df, geometry='geometry', crs=\"EPSG:2056\")\n",
    "\n",
    "unique_classes = sorted(gdf['dominant_class'].unique())\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "vibrant_colors = [\n",
    "    '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', \n",
    "    '#FF9FF3', '#54A0FF', '#5F27CD', '#00D2D3', '#FF9F43',\n",
    "    '#A3CB38', '#C44569'\n",
    "]\n",
    "color_dict = dict(zip(unique_classes, vibrant_colors[:len(unique_classes)]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5, 6.5), dpi=300)\n",
    "\n",
    "# Plot tiles by dominant class\n",
    "gdf.plot(\n",
    "    column='dominant_class',\n",
    "    ax=ax,\n",
    "    edgecolor=gdf['dominant_class'].map(color_dict),\n",
    "    linewidth=2,\n",
    "    alpha=1,\n",
    "    color=gdf['dominant_class'].map(color_dict)\n",
    ")\n",
    "\n",
    "# Plot commune boundaries\n",
    "cad_commune = gpd.read_file(GPKG_CAD_COMMUNE, layer=\"CAD_COMMUNE\")\n",
    "cad_commune = cad_commune.to_crs(\"EPSG:2056\")\n",
    "cad_commune.plot(ax=ax, color=\"none\", edgecolor=\"grey\", linewidth=0.8, alpha=0.6, ls='--')\n",
    "\n",
    "# Shortened labels for legend\n",
    "class_labels = {\n",
    "    'I habitat collectif': 'I Habitat collectif',\n",
    "    'II habitat individuel': 'II Habitat individuel', \n",
    "    'III administration': 'III Administration',\n",
    "    'IV écoles': 'IV Écoles',\n",
    "    'IX industrie': 'IX Industrie',\n",
    "    'V commerce': 'V Commerce',\n",
    "    'VI restauration': 'VI Restauration',\n",
    "    'VII lieux de rassemblement': 'VII Lieux rassemblement',\n",
    "    'VIII hôpitaux': 'VIII Hôpitaux',\n",
    "    'X dépôts': 'X Dépôts',\n",
    "    'XI installations sportives': 'XI Installations sportives',\n",
    "    'XII piscines couvertes': 'XII Piscines couvertes'\n",
    "}\n",
    "\n",
    "legend_elements = []\n",
    "for cls in unique_classes:\n",
    "    label = class_labels.get(cls, cls)\n",
    "    if len(label) > 25:\n",
    "        label = label[:22] + \"...\"\n",
    "    legend_elements.append(\n",
    "        plt.Line2D([0], [0], marker='s', color='w', label=label,\n",
    "                   markerfacecolor=color_dict[cls], markersize=8, \n",
    "                   markeredgecolor='black', markeredgewidth=0.5)\n",
    "    )\n",
    "\n",
    "# Legend\n",
    "legend = ax.legend(\n",
    "    handles=legend_elements,\n",
    "    title=\"Classe SIA dominante\",\n",
    "    loc='upper right',\n",
    "    bbox_to_anchor=(0.35, 0.95),\n",
    "    fontsize=9,\n",
    "    title_fontsize=10,\n",
    ")\n",
    "\n",
    "ax.set_title(f\"Tuiles par catégorie SIA dominante\\n(total {len(sampled_df)} tuiles)\", fontsize=12, pad=-10, fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.02, right=0.98, top=0.95, bottom=0.02)\n",
    "\n",
    "plt.savefig(os.path.join(GRAPHICS_PATH, \"06a_05_map_sampled_df.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pyproj\n",
    "\n",
    "# Coordinate systems\n",
    "swiss_cs = pyproj.CRS(\"EPSG:2056\")\n",
    "wgs84_cs = pyproj.CRS(\"EPSG:4326\")\n",
    "transformer = pyproj.Transformer.from_crs(swiss_cs, wgs84_cs, always_xy=True)\n",
    "\n",
    "def swiss_to_wgs84(east, north):\n",
    "    \"\"\"Convert Swiss coordinates to WGS84 (lat, lon).\"\"\"\n",
    "    lon, lat = transformer.transform(east, north)\n",
    "    return [lat, lon]\n",
    "\n",
    "all_sw_points = []\n",
    "all_ne_points = []\n",
    "\n",
    "for tile_id in sampled_df['tile_id'].tolist():\n",
    "    tile_row = sampled_df[sampled_df['tile_id'] == tile_id]\n",
    "    if len(tile_row) == 0:\n",
    "        continue\n",
    "    bounds = tile_row['tile_bounds'].values[0]\n",
    "    if isinstance(bounds, str):\n",
    "        bounds_clean = bounds.strip('()').replace(' ', '')\n",
    "        bounds_list = bounds_clean.split(',')\n",
    "        bounds = tuple(float(x) for x in bounds_list if x)\n",
    "    if len(bounds) >= 4:\n",
    "        minx, miny, maxx, maxy = bounds[:4]\n",
    "        sw = swiss_to_wgs84(minx, miny)\n",
    "        ne = swiss_to_wgs84(maxx, maxy)\n",
    "        all_sw_points.append(sw)\n",
    "        all_ne_points.append(ne)\n",
    "\n",
    "if all_sw_points and all_ne_points:\n",
    "    avg_lat = np.mean([pt[0] for pt in all_sw_points + all_ne_points])\n",
    "    avg_lon = np.mean([pt[1] for pt in all_sw_points + all_ne_points])\n",
    "    print(f\"Center of all tiles (lat, lon): {avg_lat}, {avg_lon}\")\n",
    "    m = folium.Map(location=[avg_lat, avg_lon], zoom_start=14)\n",
    "else:\n",
    "    print(\"No valid coordinates found\")\n",
    "    m = folium.Map(location=[46.2044, 6.1432], zoom_start=12)\n",
    "\n",
    "tiles_added = 0\n",
    "for tile_id in sampled_df['tile_id'].tolist():\n",
    "    tile_row = sampled_df[sampled_df['tile_id'] == tile_id]\n",
    "    if len(tile_row) == 0:\n",
    "        continue\n",
    "    bounds = tile_row['tile_bounds'].values[0]\n",
    "    if isinstance(bounds, str):\n",
    "        bounds_clean = bounds.strip('()').replace(' ', '')\n",
    "        bounds_list = bounds_clean.split(',')\n",
    "        bounds = tuple(float(x) for x in bounds_list if x)\n",
    "    if len(bounds) >= 4:\n",
    "        minx, miny, maxx, maxy = bounds[:4]\n",
    "        sw = swiss_to_wgs84(minx, miny)\n",
    "        ne = swiss_to_wgs84(maxx, maxy)\n",
    "        nw = swiss_to_wgs84(minx, maxy)\n",
    "        se = swiss_to_wgs84(maxx, miny)\n",
    "        folium.Polygon(\n",
    "            locations=[sw, nw, ne, se],\n",
    "            color='blue',\n",
    "            weight=1,\n",
    "            fill=True,\n",
    "            fill_opacity=0.4,\n",
    "            tooltip=f\"Tile ID: {tile_id}\"\n",
    "        ).add_to(m)\n",
    "        tiles_added += 1\n",
    "\n",
    "print(f\"Added {tiles_added} tiles to the map\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tif to PNG for roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tiff_to_png(sample_df, output_dir):\n",
    "    \"\"\"Convert GeoTIFF files in sample_df['tile_path'] to PNG format for roboflow.\"\"\"\n",
    "    # Create output directory with timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = Path(output_dir) / f\"PNG_dataset_roboflow_{timestamp}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logging.info(f\"Output directory created: {output_dir}\")\n",
    "\n",
    "    # Get unique TIFF file paths\n",
    "    tiff_files = sample_df[\"tile_path\"].dropna().unique().tolist()\n",
    "    tiff_files = [Path(file) if not isinstance(file, Path) else file for file in tiff_files]\n",
    "    logging.info(f\"Found {len(tiff_files)} unique TIFF files to process\")\n",
    "\n",
    "    for tiff_file in tqdm(tiff_files, desc=\"Converting to PNG\"):\n",
    "        if not Path(tiff_file).exists():\n",
    "            logging.warning(f\"Source file not found: {tiff_file}\")\n",
    "            continue\n",
    "\n",
    "        png_file = output_dir / f\"{Path(tiff_file).stem}.png\"\n",
    "        if not png_file.exists():\n",
    "            try:\n",
    "                subprocess.run(\n",
    "                    [\n",
    "                        \"gdal_translate\",\n",
    "                        \"-of\", \"PNG\",\n",
    "                        \"-co\", \"ZLEVEL=9\",\n",
    "                        \"-co\", \"PREDICTOR=2\",\n",
    "                        \"-ot\", \"Byte\",\n",
    "                        \"-r\", \"nearest\",\n",
    "                        \"-co\", \"COMPRESS=PNG\",\n",
    "                        str(tiff_file),\n",
    "                        str(png_file),\n",
    "                    ],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                )\n",
    "                logging.info(f\"Converted {Path(tiff_file).name}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                logging.error(f\"Error converting {tiff_file}: {e.stderr}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Unexpected error processing {tiff_file}: {str(e)}\")\n",
    "        else:\n",
    "            logging.info(f\"Skipping {Path(tiff_file).name} (already exists)\")\n",
    "\n",
    "    logging.info(f\"Conversion complete. Files saved to {output_dir}\")\n",
    "    sample_df.to_csv(output_dir / \"sampled_tiles.csv\", index=False)\n",
    "    return output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GeoTIFF tiles to PNG if enabled\n",
    "if CONVERT_GEOTIFF_TO_PNG:\n",
    "    convert_tiff_to_png(\n",
    "        sampled_df,\n",
    "        PNG_OUTPUT_PATH,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
