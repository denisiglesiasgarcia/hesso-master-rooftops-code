{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca67a47f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8e13e83",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3024dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "# from ultralytics import YOLO\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da128b9",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002fc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "todaysdate = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#------------------------\n",
    "# Constantes\n",
    "#------------------------\n",
    "\n",
    "CREATE_DATASET_PROCESSED_PATH = f\"datasets/supervisely/yolo_processed_{todaysdate}\"\n",
    "\n",
    "DEVICE = \"2\"\n",
    "\n",
    "# Convert binary masks to YOLO format\n",
    "ANNOTATIONS_BINARY_PNG_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/masks\"\n",
    "YOLO_ANNOTATIONS_OUTPUT_PATH = f\"{CREATE_DATASET_PROCESSED_PATH}/labels\"\n",
    "TEST_MASK_OUTPUT_PATH = os.path.join(CREATE_DATASET_PROCESSED_PATH, \"test_masks\")\n",
    "\n",
    "# Datasets\n",
    "DATASET_PATH = \"datasets/supervisely/341575_free_space_rooftop_geneva_20250511_yolo\"\n",
    "FOLD_PATHS = {\n",
    "    0: \"datasets/supervisely/dataset_processed_20250523-173715/fold_0_dataset.txt\",\n",
    "    1: \"datasets/supervisely/dataset_processed_20250523-173715/fold_1_dataset.txt\",\n",
    "    2: \"datasets/supervisely/dataset_processed_20250523-173715/fold_2_dataset.txt\",\n",
    "    3: \"datasets/supervisely/dataset_processed_20250523-173715/fold_3_dataset.txt\",\n",
    "    4: \"datasets/supervisely/dataset_processed_20250523-173715/fold_4_dataset.txt\"\n",
    "}\n",
    "TEST_DATASET_TXT_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/test_dataset.txt\"\n",
    "IMG_DATASET_PATH = \"datasets/supervisely/dataset_processed_20250523-173715/images\"\n",
    "\n",
    "# Augmentations\n",
    "NUM_AUGMENTATIONS_PER_IMAGE = 10  # Number of augmented versions per original\n",
    "AUGMENTATION_WORKERS = 8  # Number of parallel workers for augmentation\n",
    "\n",
    "# Train\n",
    "DATASET_PROCESSED_PATH = \"datasets/supervisely/yolo_processed_20250618_201019\"\n",
    "MODEL_NAME = \"yolo12x-seg.yaml\" # yolo11n-seg.pt\n",
    "OUTPUT_DIR_YOLO = \"training_yolo\"\n",
    "PROJECT_NAME = f\"yolo_free_space_rooftop_{todaysdate}\"\n",
    "CLASS_NAMES = [\"free_space\"]\n",
    "CUSTOM_PARAMS = {\n",
    "    'epochs': 5000,\n",
    "    'batch': 1,\n",
    "    'imgsz': 1280,\n",
    "    'patience': 30,\n",
    "    'lr0': 0.005,\n",
    "}\n",
    "\n",
    "# Evaluation\n",
    "OUTPUT_EVALUATE_TEST_DIR = os.path.join(OUTPUT_DIR_YOLO, f\"auto_cv_evaluation_results_{todaysdate}\")\n",
    "CONF_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.7\n",
    "CLASS_NAMES = [\"free_space\"]\n",
    "\n",
    "#------------------------\n",
    "# Fonctionalit√©s\n",
    "#------------------------\n",
    "\n",
    "CONVERT_BINARY_MASKS_TO_YOLO_FORMAT = True\n",
    "SPLIT_DATASET = True\n",
    "APPLY_AUGMENTATION = True\n",
    "TRAIN_YOLO = False\n",
    "EVALUATE_YOLO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44b2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_BINARY_MASKS_TO_YOLO_FORMAT:\n",
    "    os.makedirs(CREATE_DATASET_PROCESSED_PATH, exist_ok=True)\n",
    "    os.makedirs(YOLO_ANNOTATIONS_OUTPUT_PATH, exist_ok=True)\n",
    "    os.makedirs(TEST_MASK_OUTPUT_PATH, exist_ok=True)\n",
    "if EVALUATE_YOLO:\n",
    "    os.makedirs(OUTPUT_EVALUATE_TEST_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e1a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_PIPELINE = A.Compose([\n",
    "    # Basic Geometric\n",
    "    A.SquareSymmetry(p=0.5),\n",
    "    # Affine and Perspective\n",
    "    A.Affine(\n",
    "        scale=(0.95, 1.05), translate_percent=0.1, rotate=(-45, 45), p=0.6\n",
    "    ),\n",
    "    # Blur\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "            A.MotionBlur(blur_limit=(3, 7), p=0.5),\n",
    "        ],\n",
    "        p=0.2,\n",
    "    ),\n",
    "    # Noise\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.ISONoise(\n",
    "                color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5\n",
    "            ),\n",
    "            A.MultiplicativeNoise(\n",
    "                multiplier=(0.9, 1.1), per_channel=True, p=0.5\n",
    "            ),\n",
    "            A.SaltAndPepper(p=0.5),\n",
    "        ],\n",
    "        p=0.2,\n",
    "    ),\n",
    "    # Weather effects\n",
    "    A.RandomSunFlare(p=0.2),\n",
    "    A.RandomFog(p=0.2),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9ce96",
   "metadata": {},
   "source": [
    "## Convert binary format to YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b96e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours_join(parent_contour, child_contour):\n",
    "    \"\"\"\n",
    "    Join parent contour with child contour\n",
    "    Donut use case. Inside donut shouldn't detect anything\n",
    "    https://github.com/ultralytics/ultralytics/issues/3085\n",
    "    \"\"\"\n",
    "    def is_clockwise(contour):\n",
    "        value = 0\n",
    "        num = len(contour)\n",
    "        for i in range(num):\n",
    "            p1 = contour[i]\n",
    "            p2 = contour[(i + 1) % num]  # More efficient modulo operation\n",
    "            value += (p2[0][0] - p1[0][0]) * (p2[0][1] + p1[0][1])\n",
    "        return value < 0\n",
    "\n",
    "    def get_merge_point_idx(contour1, contour2):\n",
    "        min_distance = float('inf')\n",
    "        idx1, idx2 = 0, 0\n",
    "        \n",
    "        # Vectorized distance calculation for better performance\n",
    "        for i, p1 in enumerate(contour1):\n",
    "            distances = np.sum((contour2[:, 0] - p1[0]) ** 2, axis=1)\n",
    "            min_idx = np.argmin(distances)\n",
    "            if distances[min_idx] < min_distance:\n",
    "                min_distance = distances[min_idx]\n",
    "                idx1, idx2 = i, min_idx\n",
    "        return idx1, idx2\n",
    "\n",
    "    def merge_contours(contour1, contour2, idx1, idx2):\n",
    "        # More efficient concatenation\n",
    "        part1 = contour1[:idx1 + 1]\n",
    "        part2 = contour2[idx2:]\n",
    "        part3 = contour2[:idx2 + 1]\n",
    "        part4 = contour1[idx1:]\n",
    "        \n",
    "        contour = np.concatenate([part1, part2, part3, part4], axis=0)\n",
    "        return contour.astype(np.int32)\n",
    "\n",
    "    def merge_with_parent(parent_contour, contour):\n",
    "        if not is_clockwise(parent_contour):\n",
    "            parent_contour = parent_contour[::-1]\n",
    "        if is_clockwise(contour):\n",
    "            contour = contour[::-1]\n",
    "        idx1, idx2 = get_merge_point_idx(parent_contour, contour)\n",
    "        return merge_contours(parent_contour, contour, idx1, idx2)\n",
    "\n",
    "    return merge_with_parent(parent_contour=parent_contour, contour=child_contour)\n",
    "\n",
    "\n",
    "def group_child_contours_with_parent(hierarchy):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        {\n",
    "            parent_key: {\n",
    "                \"parent\": parent_key,\n",
    "                \"child\": [child_keys]\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    groups = {}\n",
    "    hierarchy_flat = hierarchy.squeeze()\n",
    "    \n",
    "    for i, h in enumerate(hierarchy_flat):\n",
    "        parent_index = h[3]\n",
    "        if parent_index != -1:\n",
    "            if parent_index in groups:\n",
    "                groups[parent_index][\"child\"].append(i)\n",
    "            else:\n",
    "                groups[parent_index] = {\"parent\": parent_index, \"child\": [i]}\n",
    "        else:\n",
    "            if i not in groups:\n",
    "                groups[i] = {\"parent\": i, \"child\": []}\n",
    "            else:\n",
    "                groups[i][\"parent\"] = i\n",
    "    return groups\n",
    "\n",
    "\n",
    "def convert_mask_to_yolo_seg_label(mask_path, create_test_mask=True):\n",
    "    \"\"\"\n",
    "    Convert a single mask to YOLO segmentation format\n",
    "    \n",
    "    Args:\n",
    "        mask_path: Path to the mask file\n",
    "        create_test_mask: Whether to create test mask for verification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        label_str = \"\"\n",
    "        test_mask = None\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            return label_str, test_mask, f\"Could not read mask from {mask_path}\"\n",
    "        \n",
    "        height, width = mask.shape\n",
    "        \n",
    "        # Threshold (optimized for 0/1 masks)\n",
    "        _, thresh = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return label_str, test_mask, None\n",
    "        \n",
    "        # Initialize test mask only if needed\n",
    "        if create_test_mask:\n",
    "            test_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        \n",
    "        # Process contours\n",
    "        if len(contours) > 1 and hierarchy is not None:\n",
    "            contour_groups = group_child_contours_with_parent(hierarchy)\n",
    "            for contour_group in contour_groups.values():\n",
    "                parent_contour = contours[contour_group[\"parent\"]]\n",
    "                \n",
    "                # Join with child contours\n",
    "                for child in contour_group[\"child\"]:\n",
    "                    parent_contour = contours_join(parent_contour=parent_contour, child_contour=contours[child])\n",
    "                \n",
    "                # Process contour\n",
    "                contour_label = process_contour(parent_contour, width, height)\n",
    "                if contour_label:\n",
    "                    label_str += f\"0{contour_label}\\n\"\n",
    "                \n",
    "                # Draw test mask\n",
    "                if create_test_mask and test_mask is not None:\n",
    "                    parent_contour = np.expand_dims(parent_contour, axis=0)\n",
    "                    cv2.drawContours(test_mask, parent_contour, -1, 255, -1)\n",
    "        else:\n",
    "            # Single contour\n",
    "            contour_label = process_contour(contours[0], width, height)\n",
    "            if contour_label:\n",
    "                label_str += f\"0{contour_label}\\n\"\n",
    "            \n",
    "            if create_test_mask:\n",
    "                test_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "                cv2.drawContours(test_mask, [contours[0]], -1, 255, -1)\n",
    "        \n",
    "        label_str = label_str.rstrip()  # Remove last \\n\n",
    "        return label_str, test_mask, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return \"\", None, str(e)\n",
    "\n",
    "\n",
    "def process_contour(contour, width, height):\n",
    "    \"\"\"Process a single contour and return normalized coordinates\"\"\"\n",
    "    contour_squeezed = contour.squeeze()\n",
    "    \n",
    "    # Handle single point case\n",
    "    if contour_squeezed.ndim == 1:\n",
    "        return \"\"\n",
    "    \n",
    "    contour_list = contour_squeezed.tolist()\n",
    "    \n",
    "    if len(contour_list) < 3:\n",
    "        return \"\"\n",
    "    \n",
    "    # Filter valid points and normalize coordinates\n",
    "    contour_label = \"\"\n",
    "    for point in contour_list:\n",
    "        if isinstance(point, list) and len(point) == 2:\n",
    "            x_norm = round(float(point[0]) / float(width), 6)\n",
    "            y_norm = round(float(point[1]) / float(height), 6)\n",
    "            contour_label += f\" {x_norm} {y_norm}\"\n",
    "    \n",
    "    return contour_label\n",
    "\n",
    "\n",
    "def process_single_mask(args):\n",
    "    \"\"\"Process a single mask file - for multiprocessing\"\"\"\n",
    "    mask_path, yolo_output_path, test_output_path, create_test_masks = args\n",
    "    \n",
    "    mask_filename = Path(mask_path).stem\n",
    "    \n",
    "    # Convert mask\n",
    "    label_str, test_mask, error = convert_mask_to_yolo_seg_label(mask_path, create_test_masks)\n",
    "    \n",
    "    if error:\n",
    "        return False, f\"Error processing {mask_filename}: {error}\"\n",
    "    \n",
    "    if not label_str:\n",
    "        return False, f\"No valid contours found in {mask_filename}\"\n",
    "    \n",
    "    # Save YOLO label\n",
    "    label_output_path = os.path.join(yolo_output_path, f\"{mask_filename}.txt\")\n",
    "    with open(label_output_path, 'w') as f:\n",
    "        f.write(label_str)\n",
    "    \n",
    "    # Save test mask if created\n",
    "    if create_test_masks and test_mask is not None:\n",
    "        test_mask_output_path = os.path.join(test_output_path, f\"{mask_filename}_test.png\")\n",
    "        cv2.imwrite(test_mask_output_path, test_mask)\n",
    "    \n",
    "    return True, mask_filename\n",
    "\n",
    "\n",
    "def batch_convert_masks_to_yolo(ANNOTATIONS_BINARY_PNG_PATH, \n",
    "                               YOLO_ANNOTATIONS_OUTPUT_PATH, \n",
    "                               TEST_MASK_OUTPUT_PATH,\n",
    "                               create_test_masks=True,\n",
    "                               num_workers=None,\n",
    "                               create_empty_labels=True):\n",
    "    \"\"\"\n",
    "    Convert all mask files in the input directory to YOLO format\n",
    "    \n",
    "    Args:\n",
    "        ANNOTATIONS_BINARY_PNG_PATH: Input directory with mask files\n",
    "        YOLO_ANNOTATIONS_OUTPUT_PATH: Output directory for YOLO labels\n",
    "        TEST_MASK_OUTPUT_PATH: Output directory for test masks\n",
    "        create_test_masks: Whether to create test masks for verification\n",
    "        num_workers: Number of parallel workers (None = auto-detect)\n",
    "        create_empty_labels: Whether to create empty label files for images without valid contours\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all mask files\n",
    "    mask_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "    mask_files = []\n",
    "    \n",
    "    print(\"Searching for mask files...\")\n",
    "    for extension in mask_extensions:\n",
    "        pattern = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, extension)\n",
    "        mask_files.extend(glob.glob(pattern))\n",
    "    \n",
    "    if not mask_files:\n",
    "        print(f\"No mask files found in {ANNOTATIONS_BINARY_PNG_PATH}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(mask_files)} mask files to process...\")\n",
    "    \n",
    "    # Set up multiprocessing\n",
    "    if num_workers is None:\n",
    "        num_workers = min(multiprocessing.cpu_count(), len(mask_files))\n",
    "    \n",
    "    print(f\"Using {num_workers} workers for parallel processing...\")\n",
    "    \n",
    "    # Prepare arguments for multiprocessing\n",
    "    process_args = [\n",
    "        (mask_path, YOLO_ANNOTATIONS_OUTPUT_PATH, TEST_MASK_OUTPUT_PATH, create_test_masks)\n",
    "        for mask_path in mask_files\n",
    "    ]\n",
    "    \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    errors = []\n",
    "    failed_files = []  # Track files that failed\n",
    "    \n",
    "    # Process files with progress bar\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all jobs at once\n",
    "        futures = {executor.submit(process_single_mask, args): args for args in process_args}\n",
    "        \n",
    "        # Use tqdm for progress tracking with as_completed for real-time updates\n",
    "        with tqdm(total=len(mask_files), desc=\"Converting masks\", unit=\"files\") as pbar:\n",
    "            # Process results as they complete\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    success, message = future.result()\n",
    "                    if success:\n",
    "                        processed_count += 1\n",
    "                        pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        errors.append(message)\n",
    "                        # Extract filename from error message for empty label creation\n",
    "                        if \"No valid contours found in\" in message:\n",
    "                            filename = message.split(\"No valid contours found in \")[-1]\n",
    "                            failed_files.append(filename)\n",
    "                        pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    errors.append(f\"Unexpected error: {str(e)}\")\n",
    "                    pbar.set_postfix({\"Success\": processed_count, \"Errors\": error_count})\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Create empty label files for images without valid contours\n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"\\nCreating empty label files for {len(failed_files)} images without valid contours...\")\n",
    "        empty_labels_created = 0\n",
    "        \n",
    "        for filename in failed_files:\n",
    "            empty_label_path = os.path.join(YOLO_ANNOTATIONS_OUTPUT_PATH, f\"{filename}.txt\")\n",
    "            try:\n",
    "                # Create empty label file\n",
    "                with open(empty_label_path, 'w') as f:\n",
    "                    pass  # Empty file\n",
    "                empty_labels_created += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create empty label for {filename}: {e}\")\n",
    "        \n",
    "        print(f\"Created {empty_labels_created} empty label files\")\n",
    "        processed_count += empty_labels_created  # Update count to include empty labels\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CONVERSION COMPLETED!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Successfully processed: {processed_count} files\")\n",
    "    print(f\"Errors: {error_count - len(failed_files) if create_empty_labels else error_count} files\")\n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"Empty labels created: {len(failed_files)} files (images without annotations)\")\n",
    "    print(f\"Success rate: {processed_count/(len(mask_files))*100:.1f}%\")\n",
    "    print(f\"YOLO labels saved to: {YOLO_ANNOTATIONS_OUTPUT_PATH}\")\n",
    "    if create_test_masks:\n",
    "        print(f\"Test masks saved to: {TEST_MASK_OUTPUT_PATH}\")\n",
    "    \n",
    "    # Show first few errors if any (excluding \"no contours\" if empty labels were created)\n",
    "    remaining_errors = [e for e in errors if not (create_empty_labels and \"No valid contours found in\" in e)]\n",
    "    if remaining_errors:\n",
    "        print(f\"\\nRemaining errors ({len(remaining_errors)}):\")\n",
    "        for error in remaining_errors[:5]:\n",
    "            print(f\"  - {error}\")\n",
    "        if len(remaining_errors) > 5:\n",
    "            print(f\"  ... and {len(remaining_errors) - 5} more errors\")\n",
    "    \n",
    "    if create_empty_labels and failed_files:\n",
    "        print(f\"\\nNote: {len(failed_files)} images had no valid annotations and got empty label files.\")\n",
    "        print(\"This is normal for datasets where some images contain no objects of interest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef68cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_failed_masks(ANNOTATIONS_BINARY_PNG_PATH, failed_filenames, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze why some masks failed to convert to YOLO format.\n",
    "    \n",
    "    Args:\n",
    "        ANNOTATIONS_BINARY_PNG_PATH: Path to mask directory\n",
    "        failed_filenames: List of filenames that failed\n",
    "        sample_size: Number of files to analyze in detail\n",
    "    \"\"\"\n",
    "    if not failed_filenames:\n",
    "        print(\"No failed masks to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nAnalyzing {min(sample_size, len(failed_filenames))} failed masks...\")\n",
    "    \n",
    "    for i, filename in enumerate(failed_filenames[:sample_size]):\n",
    "        mask_path = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, f\"{filename}.png\")\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            # Try other extensions\n",
    "            for ext in ['.jpg', '.jpeg', '.bmp', '.tif', '.tiff']:\n",
    "                alt_path = os.path.join(ANNOTATIONS_BINARY_PNG_PATH, f\"{filename}{ext}\")\n",
    "                if os.path.exists(alt_path):\n",
    "                    mask_path = alt_path\n",
    "                    break\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"  {filename}: File not found\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read and analyze mask\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(f\"  {filename}: Could not read image\")\n",
    "                continue\n",
    "            \n",
    "            height, width = mask.shape\n",
    "            unique_values = np.unique(mask)\n",
    "            foreground_pixels = np.sum(mask > 0)\n",
    "            foreground_percentage = (foreground_pixels / (height * width)) * 100\n",
    "            \n",
    "            print(f\"  {filename}:\")\n",
    "            print(f\"    - Size: {width}x{height}\")\n",
    "            print(f\"    - Unique values: {unique_values}\")\n",
    "            print(f\"    - Foreground pixels: {foreground_pixels} ({foreground_percentage:.2f}%)\")\n",
    "            \n",
    "            if foreground_pixels == 0:\n",
    "                print(\"    - Issue: Completely empty mask (no annotations)\")\n",
    "            elif foreground_pixels < 10:\n",
    "                print(\"    - Issue: Very few foreground pixels (likely noise)\")\n",
    "            else:\n",
    "                # Check contours\n",
    "                _, thresh = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                if contours:\n",
    "                    contour_sizes = [len(c) for c in contours]\n",
    "                    print(f\"    - Contours found: {len(contours)}\")\n",
    "                    print(f\"    - Contour sizes: {contour_sizes}\")\n",
    "                    print(\"    - Issue: Contours too small (< 3 points) or invalid shape\")\n",
    "                else:\n",
    "                    print(\"    - Issue: No contours detected\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  {filename}: Error analyzing - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e49cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting binary masks to YOLO format...\n",
      "Searching for mask files...\n",
      "Found 530 mask files to process...\n",
      "Using 16 workers for parallel processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a8848963e44c699390ae4b7c0277cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting masks:   0%|          | 0/530 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating empty label files for 46 images without valid contours...\n",
      "Created 46 empty label files\n",
      "\n",
      "==================================================\n",
      "CONVERSION COMPLETED!\n",
      "==================================================\n",
      "Successfully processed: 530 files\n",
      "Errors: 0 files\n",
      "Empty labels created: 46 files (images without annotations)\n",
      "Success rate: 100.0%\n",
      "YOLO labels saved to: datasets/supervisely/yolo_processed_20250619_151249/labels\n",
      "Test masks saved to: datasets/supervisely/yolo_processed_20250619_151249/test_masks\n",
      "\n",
      "Note: 46 images had no valid annotations and got empty label files.\n",
      "This is normal for datasets where some images contain no objects of interest.\n"
     ]
    }
   ],
   "source": [
    "if CONVERT_BINARY_MASKS_TO_YOLO_FORMAT:\n",
    "    print(\"Converting binary masks to YOLO format...\")\n",
    "    batch_convert_masks_to_yolo(\n",
    "        ANNOTATIONS_BINARY_PNG_PATH=ANNOTATIONS_BINARY_PNG_PATH,\n",
    "        YOLO_ANNOTATIONS_OUTPUT_PATH=YOLO_ANNOTATIONS_OUTPUT_PATH,\n",
    "        TEST_MASK_OUTPUT_PATH=TEST_MASK_OUTPUT_PATH,\n",
    "        create_test_masks=True,\n",
    "        num_workers=16,\n",
    "        create_empty_labels=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10750b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below if you want to investigate the failed conversions\n",
    "# failed_files = [\n",
    "#     \"24991113_tile_1_3_14c592\", \"25001124_tile_18_16_c9d875\", \n",
    "#     \"24971118_tile_15_17_5212bb\", \"25001121_tile_16_12_6e2b70\", \n",
    "#     \"24921119_tile_4_17_b09eb4\"\n",
    "# ]\n",
    "# analyze_failed_masks(ANNOTATIONS_BINARY_PNG_PATH, failed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc8e0",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8140e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastYOLOAugmentationPipeline:\n",
    "    \"\"\"\n",
    "    Optimized data augmentation pipeline for YOLO segmentation datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, augmentation_pipeline=None, num_augmentations=10):\n",
    "        import albumentations as A\n",
    "        \n",
    "        if augmentation_pipeline is None:\n",
    "            # Optimized pipeline - fewer heavy operations\n",
    "            self.aug_pipeline = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.3),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.4),\n",
    "                # Removed heavy operations like blur for speed\n",
    "            ], additional_targets={'mask': 'mask'})\n",
    "        else:\n",
    "            self.aug_pipeline = augmentation_pipeline\n",
    "            \n",
    "        self.num_augmentations = num_augmentations\n",
    "    \n",
    "    def yolo_label_to_mask_fast(self, label_path, img_width, img_height):\n",
    "        \"\"\"Optimized YOLO label to mask conversion\"\"\"\n",
    "        mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        \n",
    "        if not Path(label_path).exists() or Path(label_path).stat().st_size == 0:\n",
    "            return mask\n",
    "            \n",
    "        try:\n",
    "            with open(label_path, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "            \n",
    "            if not content:\n",
    "                return mask\n",
    "                \n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.split()\n",
    "                if len(parts) < 7:\n",
    "                    continue\n",
    "                \n",
    "                # Vectorized coordinate conversion\n",
    "                coords = np.array([float(x) for x in parts[1:]])\n",
    "                coords = coords.reshape(-1, 2)\n",
    "                \n",
    "                # Convert to pixel coordinates in one go\n",
    "                pixel_coords = coords * np.array([img_width, img_height])\n",
    "                pixel_coords = np.clip(pixel_coords, 0, [img_width-1, img_height-1]).astype(np.int32)\n",
    "                \n",
    "                if len(pixel_coords) >= 3:\n",
    "                    cv2.fillPoly(mask, [pixel_coords], 255)\n",
    "                    \n",
    "        except Exception:\n",
    "            pass  # Return empty mask on error\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def mask_to_yolo_label_fast(self, mask, img_width, img_height, class_id=0):\n",
    "        \"\"\"Optimized mask to YOLO label conversion\"\"\"\n",
    "        if mask.max() == 0:  # Empty mask\n",
    "            return \"\"\n",
    "            \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if not contours:\n",
    "            return \"\"\n",
    "        \n",
    "        label_lines = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Less aggressive simplification for speed\n",
    "            epsilon = 0.002 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            \n",
    "            if len(approx) < 3 or cv2.contourArea(approx) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Vectorized coordinate normalization\n",
    "            points = approx.reshape(-1, 2)\n",
    "            normalized = points / np.array([img_width, img_height])\n",
    "            normalized = np.clip(normalized, 0, 1)\n",
    "            \n",
    "            if len(normalized) >= 3:\n",
    "                coords_str = ' '.join([f\"{coord:.6f}\" for coord in normalized.flatten()])\n",
    "                label_lines.append(f\"{class_id} {coords_str}\")\n",
    "        \n",
    "        return '\\n'.join(label_lines)\n",
    "    \n",
    "    def augment_single_image_batch(self, image_path, label_path, output_images_dir, output_labels_dir):\n",
    "        \"\"\"Process all augmentations for one image in a batch\"\"\"\n",
    "        try:\n",
    "            # Load image once\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                return 0, self.num_augmentations, f\"Could not load image: {image_path}\"\n",
    "            \n",
    "            img_height, img_width = image.shape[:2]\n",
    "            stem = Path(image_path).stem\n",
    "            \n",
    "            # Convert YOLO label to mask once\n",
    "            mask = self.yolo_label_to_mask_fast(label_path, img_width, img_height)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            # Create all augmentations in batch\n",
    "            for aug_idx in range(1, self.num_augmentations + 1):\n",
    "                try:\n",
    "                    # Apply augmentation\n",
    "                    augmented = self.aug_pipeline(image=image, mask=mask)\n",
    "                    aug_image = augmented['image']\n",
    "                    aug_mask = augmented['mask']\n",
    "                    \n",
    "                    # Save files\n",
    "                    aug_image_name = f\"{stem}_aug{aug_idx}.png\"\n",
    "                    aug_label_name = f\"{stem}_aug{aug_idx}.txt\"\n",
    "                    \n",
    "                    aug_image_path = output_images_dir / aug_image_name\n",
    "                    aug_label_path = output_labels_dir / aug_label_name\n",
    "                    \n",
    "                    # Faster image saving\n",
    "                    cv2.imwrite(str(aug_image_path), aug_image, [cv2.IMWRITE_PNG_COMPRESSION, 1])\n",
    "                    \n",
    "                    # Convert and save label\n",
    "                    yolo_label = self.mask_to_yolo_label_fast(aug_mask, img_width, img_height)\n",
    "                    with open(aug_label_path, 'w') as f:\n",
    "                        f.write(yolo_label)\n",
    "                    \n",
    "                    successful += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    failed += 1\n",
    "                    if failed <= 2:  # Limit error messages\n",
    "                        logger.warning(f\"Aug {aug_idx} failed for {stem}: {e}\")\n",
    "            \n",
    "            return successful, failed, f\"Processed {stem}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0, self.num_augmentations, f\"Error processing {Path(image_path).name}: {e}\"\n",
    "    \n",
    "    def augment_dataset_folder_fast(self, images_dir, labels_dir, output_images_dir, output_labels_dir, \n",
    "                                   num_workers=None, use_threads=True):\n",
    "        \"\"\"\n",
    "        Fast augmentation using parallel processing\n",
    "        \n",
    "        Args:\n",
    "            use_threads: If True, use ThreadPoolExecutor (faster for I/O), \n",
    "                        if False, use ProcessPoolExecutor (better for CPU)\n",
    "        \"\"\"\n",
    "        images_dir = Path(images_dir)\n",
    "        labels_dir = Path(labels_dir)\n",
    "        output_images_dir = Path(output_images_dir)\n",
    "        output_labels_dir = Path(output_labels_dir)\n",
    "        \n",
    "        # Find all images\n",
    "        image_files = []\n",
    "        for ext in ['*.png', '*.jpg', '*.jpeg', '*.tif']:\n",
    "            image_files.extend(images_dir.glob(ext))\n",
    "        \n",
    "        if not image_files:\n",
    "            logger.warning(f\"No images found in {images_dir}\")\n",
    "            return 0, 0\n",
    "        \n",
    "        logger.info(f\"Found {len(image_files)} images to augment\")\n",
    "        logger.info(f\"Creating {self.num_augmentations} versions each = {len(image_files) * self.num_augmentations} total\")\n",
    "        \n",
    "        # Set optimal number of workers\n",
    "        if num_workers is None:\n",
    "            num_workers = min(multiprocessing.cpu_count(), len(image_files), 8)\n",
    "        \n",
    "        total_successful = 0\n",
    "        total_failed = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if use_threads and len(image_files) > 1:\n",
    "            # Use ThreadPoolExecutor for I/O-bound operations\n",
    "            logger.info(f\"Using {num_workers} threads for parallel augmentation\")\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                # Submit all tasks\n",
    "                future_to_image = {}\n",
    "                for image_path in image_files:\n",
    "                    label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                    future = executor.submit(\n",
    "                        self.augment_single_image_batch,\n",
    "                        image_path, label_path, output_images_dir, output_labels_dir\n",
    "                    )\n",
    "                    future_to_image[future] = image_path\n",
    "                \n",
    "                # Process results with progress bar\n",
    "                with tqdm(total=len(image_files), desc=\"Augmenting images (threaded)\") as pbar:\n",
    "                    for future in as_completed(future_to_image):\n",
    "                        try:\n",
    "                            successful, failed, message = future.result(timeout=60)\n",
    "                            total_successful += successful\n",
    "                            total_failed += failed\n",
    "                            pbar.update(1)\n",
    "                            pbar.set_postfix({\n",
    "                                \"Success\": total_successful, \n",
    "                                \"Failed\": total_failed,\n",
    "                                \"Rate\": f\"{total_successful/(time.time()-start_time):.1f}/s\"\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            total_failed += self.num_augmentations\n",
    "                            logger.error(f\"Task failed: {e}\")\n",
    "                            pbar.update(1)\n",
    "        \n",
    "        else:\n",
    "            # Fallback to sequential processing\n",
    "            logger.info(\"Using sequential processing\")\n",
    "            \n",
    "            for image_path in tqdm(image_files, desc=\"Augmenting images (sequential)\"):\n",
    "                label_path = labels_dir / f\"{image_path.stem}.txt\"\n",
    "                successful, failed, message = self.augment_single_image_batch(\n",
    "                    image_path, label_path, output_images_dir, output_labels_dir\n",
    "                )\n",
    "                total_successful += successful\n",
    "                total_failed += failed\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        rate = total_successful / duration if duration > 0 else 0\n",
    "        \n",
    "        logger.info(f\"Augmentation completed in {duration:.1f}s\")\n",
    "        logger.info(f\"Rate: {rate:.1f} augmentations/second\")\n",
    "        logger.info(f\"Results: {total_successful} successful, {total_failed} failed\")\n",
    "        \n",
    "        return total_successful, total_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f550d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_list(txt_path):\n",
    "    \"\"\"Read image filenames from txt file.\"\"\"\n",
    "    with open(txt_path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def get_image_name_without_ext(filename):\n",
    "    \"\"\"Get image name without extension.\"\"\"\n",
    "    return Path(filename).stem\n",
    "\n",
    "def create_directory_structure(base_path):\n",
    "    \"\"\"Create train/val/test directory structure with images and labels subdirs.\"\"\"\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for subdir in ['images', 'labels']:\n",
    "            dir_path = Path(base_path) / split / subdir\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def convert_tiff_to_png(tiff_path, png_path, quality=95):\n",
    "    \"\"\"Convert TIFF image to high-quality PNG.\"\"\"\n",
    "    try:\n",
    "        with Image.open(tiff_path) as img:\n",
    "            # Convert to RGB if needed (TIFF might be in different color modes)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save as PNG with high quality\n",
    "            img.save(png_path, 'PNG', optimize=True, compress_level=1)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to convert {tiff_path} to {png_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def copy_label_file(source_labels_dir, target_labels_dir, image_filename):\n",
    "    \"\"\"Copy corresponding label file for an image.\"\"\"\n",
    "    # Get image name without extension\n",
    "    image_name = get_image_name_without_ext(image_filename)\n",
    "    \n",
    "    # YOLO labels have exact same name as images (just .txt extension)\n",
    "    label_filename = f\"{image_name}.txt\"\n",
    "    \n",
    "    source_label = Path(source_labels_dir) / label_filename\n",
    "    target_label = Path(target_labels_dir) / label_filename\n",
    "    \n",
    "    if source_label.exists():\n",
    "        shutil.copy2(source_label, target_label)\n",
    "        return True\n",
    "    else:\n",
    "        logger.warning(f\"Label file not found: {source_label}\")\n",
    "        return False\n",
    "\n",
    "def validate_setup():\n",
    "    \"\"\"Validate that all paths and files exist.\"\"\"\n",
    "    logger.info(\"Validating setup for YOLO dataset creation...\")\n",
    "    \n",
    "    all_good = True\n",
    "    \n",
    "    # Check original dataset path for reference\n",
    "    if not Path(DATASET_PATH).exists():\n",
    "        logger.warning(f\"Original dataset path does not exist: {DATASET_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        logger.success(f\"Original dataset path exists: {DATASET_PATH}\")\n",
    "    \n",
    "    # Check YOLO labels directory (main requirement)\n",
    "    yolo_labels_dir = Path(YOLO_ANNOTATIONS_OUTPUT_PATH)\n",
    "    if not yolo_labels_dir.exists():\n",
    "        logger.error(f\"YOLO labels directory does not exist: {yolo_labels_dir}\")\n",
    "        logger.error(\"Please run the binary mask to YOLO conversion first!\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        label_count = len(list(yolo_labels_dir.glob(\"*.txt\")))\n",
    "        logger.success(f\"YOLO labels directory exists: {yolo_labels_dir} ({label_count} label files)\")\n",
    "    \n",
    "    # Check image path\n",
    "    if not Path(IMG_DATASET_PATH).exists():\n",
    "        logger.warning(f\"Image dataset path does not exist: {IMG_DATASET_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        image_count = len(list(Path(IMG_DATASET_PATH).glob(\"*.tif\")))  # Fixed: only .tif\n",
    "        logger.success(f\"Image dataset path exists: {IMG_DATASET_PATH} ({image_count} image files)\")\n",
    "    \n",
    "    # Check/create processed output path\n",
    "    if not Path(CREATE_DATASET_PROCESSED_PATH).exists():\n",
    "        logger.info(f\"Creating processed dataset directory: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "        Path(CREATE_DATASET_PROCESSED_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        logger.success(f\"Processed dataset path exists: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "    \n",
    "    # Check fold txt files\n",
    "    total_fold_images = 0\n",
    "    for fold_num, txt_path in FOLD_PATHS.items():\n",
    "        if not Path(txt_path).exists():\n",
    "            logger.warning(f\"Fold {fold_num} txt file does not exist: {txt_path}\")\n",
    "            all_good = False\n",
    "        else:\n",
    "            images = read_image_list(txt_path)\n",
    "            total_fold_images += len(images)\n",
    "            logger.success(f\"Fold {fold_num}: {len(images)} images\")\n",
    "    \n",
    "    # Check test file\n",
    "    if not Path(TEST_DATASET_TXT_PATH).exists():\n",
    "        logger.warning(f\"Test dataset txt file does not exist: {TEST_DATASET_TXT_PATH}\")\n",
    "        all_good = False\n",
    "    else:\n",
    "        test_images = read_image_list(TEST_DATASET_TXT_PATH)\n",
    "        logger.success(f\"Test set: {len(test_images)} images\")\n",
    "        logger.info(f\"Total dataset size: {total_fold_images + len(test_images)} images\")\n",
    "    \n",
    "    # Validate that images and labels match (critical check)\n",
    "    if Path(YOLO_ANNOTATIONS_OUTPUT_PATH).exists() and FOLD_PATHS.get(0) and Path(FOLD_PATHS[0]).exists():\n",
    "        logger.info(\"Validating image-label correspondence...\")\n",
    "        \n",
    "        sample_images = read_image_list(FOLD_PATHS[0])[:10]  # Check first 10 images\n",
    "        missing_labels = []\n",
    "        missing_images = []\n",
    "        \n",
    "        for image_filename in sample_images:\n",
    "            image_name = get_image_name_without_ext(image_filename)\n",
    "            \n",
    "            # Check label exists\n",
    "            label_file = Path(YOLO_ANNOTATIONS_OUTPUT_PATH) / f\"{image_name}.txt\"\n",
    "            if not label_file.exists():\n",
    "                missing_labels.append(f\"{image_name}.txt\")\n",
    "            \n",
    "            # Check image exists (only .tif)\n",
    "            tif_file = Path(IMG_DATASET_PATH) / f\"{image_name}.tif\"\n",
    "            if not tif_file.exists():\n",
    "                missing_images.append(f\"{image_name}.tif\")\n",
    "        \n",
    "        if missing_labels:\n",
    "            logger.error(f\"Missing label files: {missing_labels}\")\n",
    "            all_good = False\n",
    "        \n",
    "        if missing_images:\n",
    "            logger.error(f\"Missing image files: {missing_images}\")\n",
    "            all_good = False\n",
    "        \n",
    "        if not missing_labels and not missing_images:\n",
    "            logger.success(\"Image-label correspondence validation passed!\")\n",
    "    \n",
    "    # Summary\n",
    "    if all_good:\n",
    "        logger.success(\"All validations passed! Ready to create cross-validation datasets.\")\n",
    "        logger.info(f\"Output will be saved to: {CREATE_DATASET_PROCESSED_PATH}\")\n",
    "    else:\n",
    "        logger.error(\"Setup validation failed. Please fix the issues above before proceeding.\")\n",
    "    \n",
    "    return all_good\n",
    "\n",
    "def process_image_list(image_list, split_name, target_base_dir):\n",
    "    \"\"\"Process a list of images for a specific split (train/val/test).\"\"\"\n",
    "    # Use YOLO labels directory\n",
    "    source_labels_dir = Path(YOLO_ANNOTATIONS_OUTPUT_PATH)\n",
    "    target_images_dir = Path(target_base_dir) / split_name / \"images\"\n",
    "    target_labels_dir = Path(target_base_dir) / split_name / \"labels\"\n",
    "    \n",
    "    successful_copies = 0\n",
    "    failed_copies = 0\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for image_filename in tqdm(image_list, desc=f\"Processing {split_name}\", leave=False):\n",
    "        image_name = get_image_name_without_ext(image_filename)\n",
    "        \n",
    "        # Source TIF image path (only .tif extension)\n",
    "        source_tif = Path(IMG_DATASET_PATH) / f\"{image_name}.tif\"\n",
    "        \n",
    "        # Target PNG image path\n",
    "        target_png = target_images_dir / f\"{image_name}.png\"\n",
    "        \n",
    "        # Convert TIF to PNG and copy label\n",
    "        if source_tif.exists():\n",
    "            if convert_tiff_to_png(source_tif, target_png):\n",
    "                # Copy corresponding label file\n",
    "                if copy_label_file(source_labels_dir, target_labels_dir, image_filename):\n",
    "                    successful_copies += 1\n",
    "                else:\n",
    "                    failed_copies += 1\n",
    "            else:\n",
    "                failed_copies += 1\n",
    "        else:\n",
    "            logger.warning(f\"Source image not found: {image_name}.tif\")\n",
    "            failed_copies += 1\n",
    "    \n",
    "    logger.info(f\"{split_name}: {successful_copies} successful, {failed_copies} failed\")\n",
    "    return successful_copies, failed_copies\n",
    "\n",
    "def create_single_fold_dataset(val_fold, fold_data, test_data):\n",
    "    \"\"\"Create a single cross-validation dataset.\"\"\"\n",
    "    dataset_name = f\"fold_{val_fold}_dataset\"\n",
    "    # Use the updated CREATE_DATASET_PROCESSED_PATH for output\n",
    "    dataset_path = Path(CREATE_DATASET_PROCESSED_PATH) / dataset_name\n",
    "    \n",
    "    logger.info(f\"Creating {dataset_name}\")\n",
    "    \n",
    "    # Create directory structure\n",
    "    create_directory_structure(dataset_path)\n",
    "    \n",
    "    # Validation data: current fold\n",
    "    val_data = fold_data[val_fold]\n",
    "    \n",
    "    # Training data: all other folds\n",
    "    train_data = []\n",
    "    for fold_num, images in fold_data.items():\n",
    "        if fold_num != val_fold:\n",
    "            train_data.extend(images)\n",
    "    \n",
    "    logger.info(f\"Training: {len(train_data)} images\")\n",
    "    logger.info(f\"Validation: {len(val_data)} images\")\n",
    "    logger.info(f\"Test: {len(test_data)} images\")\n",
    "    \n",
    "    # Process each split\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_success, train_fail = process_image_list(train_data, \"train\", dataset_path)\n",
    "    val_success, val_fail = process_image_list(val_data, \"val\", dataset_path)\n",
    "    test_success, test_fail = process_image_list(test_data, \"test\", dataset_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    total_success = train_success + val_success + test_success\n",
    "    total_fail = train_fail + val_fail + test_fail\n",
    "    \n",
    "    logger.success(f\"{dataset_name} completed in {duration:.1f}s\")\n",
    "    logger.success(f\"Total: {total_success} successful, {total_fail} failed\")\n",
    "    \n",
    "    return total_success, total_fail\n",
    "\n",
    "def create_single_fold_dataset_with_augmentation_fast(val_fold, fold_data, test_data):\n",
    "    \"\"\"\n",
    "    Fast dataset creation with optimized augmentation\n",
    "    \"\"\"\n",
    "    # First create normal dataset\n",
    "    total_success, total_fail = create_single_fold_dataset(val_fold, fold_data, test_data)\n",
    "    \n",
    "    # Then apply augmentation if enabled\n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.info(f\"Applying FAST augmentation to fold {val_fold} training set...\")\n",
    "        \n",
    "        dataset_path = Path(CREATE_DATASET_PROCESSED_PATH) / f\"fold_{val_fold}_dataset\"\n",
    "        train_images_dir = dataset_path / \"train\" / \"images\"\n",
    "        train_labels_dir = dataset_path / \"train\" / \"labels\"\n",
    "        \n",
    "        if train_images_dir.exists() and train_labels_dir.exists():\n",
    "            # Count original images\n",
    "            original_count = len(list(train_images_dir.glob(\"*.png\")))\n",
    "            logger.info(f\"  Original training images: {original_count}\")\n",
    "            \n",
    "            # Initialize fast augmenter\n",
    "            augmenter = FastYOLOAugmentationPipeline(\n",
    "                augmentation_pipeline=AUGMENTATION_PIPELINE,\n",
    "                num_augmentations=NUM_AUGMENTATIONS_PER_IMAGE\n",
    "            )\n",
    "            \n",
    "            # Apply fast augmentation\n",
    "            start_time = time.time()\n",
    "            aug_success, aug_fail = augmenter.augment_dataset_folder_fast(\n",
    "                images_dir=train_images_dir,\n",
    "                labels_dir=train_labels_dir,\n",
    "                output_images_dir=train_images_dir,  # In-place\n",
    "                output_labels_dir=train_labels_dir,  # In-place\n",
    "                num_workers=AUGMENTATION_WORKERS,\n",
    "                use_threads=True  # Set to False for CPU-intensive augmentations\n",
    "            )\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            final_count = len(list(train_images_dir.glob(\"*.png\")))\n",
    "            \n",
    "            logger.success(f\"Fold {val_fold} augmentation completed in {duration:.1f}s:\")\n",
    "            logger.success(f\"  Created: {aug_success} augmented images\")\n",
    "            logger.success(f\"  Failed: {aug_fail} augmentations\")\n",
    "            logger.success(f\"  Final training set: {final_count} images ({original_count} ‚Üí {final_count})\")\n",
    "            \n",
    "            total_success += aug_success\n",
    "            total_fail += aug_fail\n",
    "        else:\n",
    "            logger.warning(f\"Training directories not found for fold {val_fold}\")\n",
    "    \n",
    "    return total_success, total_fail\n",
    "\n",
    "def create_cross_validation_datasets(APPLY_AUGMENTATION):\n",
    "    \"\"\"Create 5 cross-validation datasets with optional augmentation.\"\"\"\n",
    "    \n",
    "    if not SPLIT_DATASET:\n",
    "        logger.warning(\"Dataset creation is disabled. Set SPLIT_DATASET = True to enable.\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Starting cross-validation dataset creation...\")\n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.info(\"Augmentation is ENABLED - will augment training sets\")\n",
    "        logger.info(f\"Augmentations per image: {NUM_AUGMENTATIONS_PER_IMAGE}\")\n",
    "    else:\n",
    "        logger.info(\"Augmentation is DISABLED\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read all fold datasets\n",
    "    fold_data = {}\n",
    "    for fold_num, txt_path in FOLD_PATHS.items():\n",
    "        fold_data[fold_num] = read_image_list(txt_path)\n",
    "        logger.info(f\"Fold {fold_num}: {len(fold_data[fold_num])} images\")\n",
    "    \n",
    "    # Read test dataset\n",
    "    test_data = read_image_list(TEST_DATASET_TXT_PATH)\n",
    "    logger.info(f\"Test set: {len(test_data)} images\")\n",
    "    \n",
    "    # Create 5 cross-validation datasets\n",
    "    total_success = 0\n",
    "    total_fail = 0\n",
    "    \n",
    "    for val_fold in range(5):\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"PROCESSING FOLD {val_fold}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        if APPLY_AUGMENTATION:\n",
    "            logger.info(f\"Creating dataset for fold {val_fold} WITH augmentation...\")\n",
    "            success, fail = create_single_fold_dataset_with_augmentation_fast(val_fold, fold_data, test_data)\n",
    "        else:\n",
    "            logger.info(f\"Creating dataset for fold {val_fold} WITHOUT augmentation...\")\n",
    "            success, fail = create_single_fold_dataset(val_fold, fold_data, test_data)\n",
    "        \n",
    "        total_success += success\n",
    "        total_fail += fail\n",
    "        \n",
    "        logger.info(f\"Fold {val_fold} completed: {success} successful, {fail} failed\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_duration = end_time - start_time\n",
    "    \n",
    "    logger.success(\"\\n\" + \"=\"*60)\n",
    "    logger.success(\"ALL CROSS-VALIDATION DATASETS COMPLETED!\")\n",
    "    logger.success(\"=\"*60)\n",
    "    logger.success(f\"Total time: {total_duration/60:.1f} minutes\")\n",
    "    logger.success(f\"Overall: {total_success} successful, {total_fail} failed\")\n",
    "    \n",
    "    if APPLY_AUGMENTATION:\n",
    "        logger.success(f\"Augmentation applied to all training sets with {NUM_AUGMENTATIONS_PER_IMAGE} versions per image\")\n",
    "    \n",
    "    return total_success, total_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f119ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:12:53.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mValidating setup for YOLO dataset creation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.046\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m61\u001b[0m - \u001b[32m\u001b[1mOriginal dataset path exists: datasets/supervisely/341575_free_space_rooftop_geneva_20250511_yolo\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.048\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m71\u001b[0m - \u001b[32m\u001b[1mYOLO labels directory exists: datasets/supervisely/yolo_processed_20250619_151249/labels (530 label files)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.050\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m79\u001b[0m - \u001b[32m\u001b[1mImage dataset path exists: datasets/supervisely/dataset_processed_20250523-173715/images (530 image files)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.050\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m86\u001b[0m - \u001b[32m\u001b[1mProcessed dataset path exists: datasets/supervisely/yolo_processed_20250619_151249\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.050\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m97\u001b[0m - \u001b[32m\u001b[1mFold 0: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.051\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m97\u001b[0m - \u001b[32m\u001b[1mFold 1: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.051\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m97\u001b[0m - \u001b[32m\u001b[1mFold 2: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.052\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m97\u001b[0m - \u001b[32m\u001b[1mFold 3: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.052\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m97\u001b[0m - \u001b[32m\u001b[1mFold 4: 89 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.052\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m105\u001b[0m - \u001b[32m\u001b[1mTest set: 89 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mTotal dataset size: 530 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mValidating image-label correspondence...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.054\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m138\u001b[0m - \u001b[32m\u001b[1mImage-label correspondence validation passed!\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.054\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m142\u001b[0m - \u001b[32m\u001b[1mAll validations passed! Ready to create cross-validation datasets.\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mvalidate_setup\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mOutput will be saved to: datasets/supervisely/yolo_processed_20250619_151249\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mStarting cross-validation dataset creation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mAugmentation is ENABLED - will augment training sets\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mAugmentations per image: 10\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mFold 0: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mFold 1: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mFold 2: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mFold 3: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mFold 4: 89 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m304\u001b[0m - \u001b[1mTest set: 89 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mPROCESSING FOLD 0\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mCreating dataset for fold 0 WITH augmentation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mCreating fold_0_dataset\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mTraining: 353 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mValidation: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:12:53.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mTest: 89 images\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b5bc9420ea4d52ac29467e3f794456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:14:25.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtrain: 353 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d8194f77ba43ce82160d70bd6103ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:14:49.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mval: 88 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a4cf1ca66c48fb900489334653ae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:15:18.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtest: 89 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.877\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m223\u001b[0m - \u001b[32m\u001b[1mfold_0_dataset completed in 145.8s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.877\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m224\u001b[0m - \u001b[32m\u001b[1mTotal: 530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mApplying FAST augmentation to fold 0 training set...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m  Original training images: 353\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mFound 353 images to augment\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mCreating 10 versions each = 3530 total\u001b[0m\n",
      "\u001b[32m2025-06-19 15:15:18.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mUsing 8 threads for parallel augmentation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a793437a9b845f794562e8fbc139e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting images (threaded):   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:19:05.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mAugmentation completed in 226.9s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mRate: 15.6 augmentations/second\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mResults: 3530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.829\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m268\u001b[0m - \u001b[32m\u001b[1mFold 0 augmentation completed in 226.9s:\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.830\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m269\u001b[0m - \u001b[32m\u001b[1m  Created: 3530 augmented images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.830\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m270\u001b[0m - \u001b[32m\u001b[1m  Failed: 0 augmentations\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.830\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m271\u001b[0m - \u001b[32m\u001b[1m  Final training set: 3883 images (353 ‚Üí 3883)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mFold 0 completed: 4060 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mPROCESSING FOLD 1\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mCreating dataset for fold 1 WITH augmentation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mCreating fold_1_dataset\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mTraining: 353 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mValidation: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:19:05.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mTest: 89 images\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd329bb4c5f1406481740aef8072b4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:20:35.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtrain: 353 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8f5b1ec91d47aa8d563534f44d08c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:21:00.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mval: 88 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f64dd63b9147588cafb2619c1ffa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:21:30.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtest: 89 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.107\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m223\u001b[0m - \u001b[32m\u001b[1mfold_1_dataset completed in 144.3s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.107\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m224\u001b[0m - \u001b[32m\u001b[1mTotal: 530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mApplying FAST augmentation to fold 1 training set...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m  Original training images: 353\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mFound 353 images to augment\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mCreating 10 versions each = 3530 total\u001b[0m\n",
      "\u001b[32m2025-06-19 15:21:30.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mUsing 8 threads for parallel augmentation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ff74922624438dbebf5c48adf18cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting images (threaded):   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:25:21.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mAugmentation completed in 231.5s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mRate: 15.2 augmentations/second\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mResults: 3530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.648\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m268\u001b[0m - \u001b[32m\u001b[1mFold 1 augmentation completed in 231.5s:\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.648\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m269\u001b[0m - \u001b[32m\u001b[1m  Created: 3530 augmented images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.649\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m270\u001b[0m - \u001b[32m\u001b[1m  Failed: 0 augmentations\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.649\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m271\u001b[0m - \u001b[32m\u001b[1m  Final training set: 3883 images (353 ‚Üí 3883)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mFold 1 completed: 4060 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mPROCESSING FOLD 2\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mCreating dataset for fold 2 WITH augmentation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mCreating fold_2_dataset\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mTraining: 353 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mValidation: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:25:21.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mTest: 89 images\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac0d012e8dc43a9909b30951ad475c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:26:55.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtrain: 353 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4146729899384665bfd11cab395d97a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:27:16.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mval: 88 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539108bfc31c43a781c0dfd2ccb4a426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:27:45.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtest: 89 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.810\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m223\u001b[0m - \u001b[32m\u001b[1mfold_2_dataset completed in 144.2s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.811\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m224\u001b[0m - \u001b[32m\u001b[1mTotal: 530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mApplying FAST augmentation to fold 2 training set...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m  Original training images: 353\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mFound 353 images to augment\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mCreating 10 versions each = 3530 total\u001b[0m\n",
      "\u001b[32m2025-06-19 15:27:45.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mUsing 8 threads for parallel augmentation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c466933713984cd5ac37c8e3458c79ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting images (threaded):   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:31:30.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mAugmentation completed in 225.0s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mRate: 15.7 augmentations/second\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mResults: 3530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.828\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m268\u001b[0m - \u001b[32m\u001b[1mFold 2 augmentation completed in 225.0s:\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.828\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m269\u001b[0m - \u001b[32m\u001b[1m  Created: 3530 augmented images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.829\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m270\u001b[0m - \u001b[32m\u001b[1m  Failed: 0 augmentations\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.829\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m271\u001b[0m - \u001b[32m\u001b[1m  Final training set: 3883 images (353 ‚Üí 3883)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mFold 2 completed: 4060 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mPROCESSING FOLD 3\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mCreating dataset for fold 3 WITH augmentation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mCreating fold_3_dataset\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mTraining: 353 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mValidation: 88 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:31:30.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mTest: 89 images\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4e3b1f7e0a486ba9e9b9b107c3d87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:33:01.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtrain: 353 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68978c521527484fbdedeb139101fdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:33:25.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mval: 88 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38ba778397344b4a1ae5791ad0ebdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:33:54.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtest: 89 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:54.999\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m223\u001b[0m - \u001b[32m\u001b[1mfold_3_dataset completed in 144.2s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:54.999\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m224\u001b[0m - \u001b[32m\u001b[1mTotal: 530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:54.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mApplying FAST augmentation to fold 3 training set...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:55.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m  Original training images: 353\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:55.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mFound 353 images to augment\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:55.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mCreating 10 versions each = 3530 total\u001b[0m\n",
      "\u001b[32m2025-06-19 15:33:55.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mUsing 8 threads for parallel augmentation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bf345937d343539029a99b4d3c3d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting images (threaded):   0%|          | 0/353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:37:44.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mAugmentation completed in 229.9s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mRate: 15.4 augmentations/second\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mResults: 3530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.960\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m268\u001b[0m - \u001b[32m\u001b[1mFold 3 augmentation completed in 229.9s:\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.960\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m269\u001b[0m - \u001b[32m\u001b[1m  Created: 3530 augmented images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.961\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m270\u001b[0m - \u001b[32m\u001b[1m  Failed: 0 augmentations\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.961\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m271\u001b[0m - \u001b[32m\u001b[1m  Final training set: 3883 images (353 ‚Üí 3883)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mFold 3 completed: 4060 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mPROCESSING FOLD 4\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mCreating dataset for fold 4 WITH augmentation...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mCreating fold_4_dataset\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mTraining: 352 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1mValidation: 89 images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:37:44.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1mTest: 89 images\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210afc466256441c8571ae56e4dbd33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing train:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:39:18.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtrain: 352 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7728a02b89ae451299f73d09d23f8da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:39:39.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mval: 89 successful, 0 failed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3826f02708f84fc6b283eed424a30c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing test:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:40:08.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_image_list\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mtest: 89 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.933\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m223\u001b[0m - \u001b[32m\u001b[1mfold_4_dataset completed in 144.0s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.933\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset\u001b[0m:\u001b[36m224\u001b[0m - \u001b[32m\u001b[1mTotal: 530 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m237\u001b[0m - \u001b[1mApplying FAST augmentation to fold 4 training set...\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1m  Original training images: 352\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mFound 352 images to augment\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1mCreating 10 versions each = 3520 total\u001b[0m\n",
      "\u001b[32m2025-06-19 15:40:08.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mUsing 8 threads for parallel augmentation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e04dff2d0d4b28a00a6f75cb76bd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting images (threaded):   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-19 15:43:55.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mAugmentation completed in 226.4s\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mRate: 15.5 augmentations/second\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36maugment_dataset_folder_fast\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mResults: 3520 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.337\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m268\u001b[0m - \u001b[32m\u001b[1mFold 4 augmentation completed in 226.4s:\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.338\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m269\u001b[0m - \u001b[32m\u001b[1m  Created: 3520 augmented images\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.338\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m270\u001b[0m - \u001b[32m\u001b[1m  Failed: 0 augmentations\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.338\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_single_fold_dataset_with_augmentation_fast\u001b[0m:\u001b[36m271\u001b[0m - \u001b[32m\u001b[1m  Final training set: 3872 images (352 ‚Üí 3872)\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mFold 4 completed: 4050 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.339\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m330\u001b[0m - \u001b[32m\u001b[1m\n",
      "============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.339\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m331\u001b[0m - \u001b[32m\u001b[1mALL CROSS-VALIDATION DATASETS COMPLETED!\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.340\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m332\u001b[0m - \u001b[32m\u001b[1m============================================================\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.340\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m333\u001b[0m - \u001b[32m\u001b[1mTotal time: 31.0 minutes\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.340\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m334\u001b[0m - \u001b[32m\u001b[1mOverall: 20290 successful, 0 failed\u001b[0m\n",
      "\u001b[32m2025-06-19 15:43:55.341\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_cross_validation_datasets\u001b[0m:\u001b[36m337\u001b[0m - \u001b[32m\u001b[1mAugmentation applied to all training sets with 10 versions per image\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if SPLIT_DATASET:\n",
    "    if validate_setup():\n",
    "        # Create cross-validation datasets\n",
    "        create_cross_validation_datasets(APPLY_AUGMENTATION=APPLY_AUGMENTATION)\n",
    "    else:\n",
    "        logger.error(\"Setup validation failed. Please fix the issues before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0f442",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb8ca57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOSegmentationTrainer:\n",
    "    \"\"\"\n",
    "    Transfer learning pipeline for YOLO segmentation models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dataset_processed_path: str,\n",
    "                 model_name: str = \"yolo11n-seg.pt\",\n",
    "                 project_name: str = \"rooftop_segmentation\",\n",
    "                 output_dir: str = None,\n",
    "                 device: str = \"auto\"):\n",
    "        \"\"\"\n",
    "        Initialize the trainer.\n",
    "        \n",
    "        Args:\n",
    "            dataset_processed_path: Path to processed CV datasets\n",
    "            model_name: Pre-trained model to use (must be segmentation model)\n",
    "            project_name: Project name for saving results\n",
    "            output_dir: Custom directory to save training results (default: current directory)\n",
    "            device: Device to use ('auto', 'cpu', '0', '1', etc.)\n",
    "        \"\"\"\n",
    "        self.dataset_processed_path = Path(dataset_processed_path)\n",
    "        self.model_name = model_name\n",
    "        self.project_name = project_name\n",
    "        self.device = device\n",
    "        \n",
    "        # Set up output directory\n",
    "        if output_dir:\n",
    "            self.output_dir = Path(output_dir)\n",
    "            self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            self.full_project_path = self.output_dir / project_name\n",
    "        else:\n",
    "            self.output_dir = Path(\".\")\n",
    "            self.full_project_path = Path(project_name)\n",
    "        \n",
    "        # Training parameters\n",
    "        self.training_params = {\n",
    "            'epochs': 100,\n",
    "            'imgsz': 640,\n",
    "            'batch': 16,\n",
    "            'lr0': 0.01,\n",
    "            'lrf': 0.1,\n",
    "            'momentum': 0.937,\n",
    "            'weight_decay': 0.0005,\n",
    "            'warmup_epochs': 3,\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,\n",
    "            'patience': 10,\n",
    "            'save_period': 10,\n",
    "            'cache': False,\n",
    "            'workers': 8,\n",
    "            'close_mosaic': 10,\n",
    "        }\n",
    "        \n",
    "        # Results storage\n",
    "        self.results = {}\n",
    "        self.cv_results = []\n",
    "\n",
    "        \n",
    "        logger.info(\"Initialized YOLO Segmentation Trainer\")\n",
    "        logger.info(f\"Model: {model_name}\")\n",
    "        logger.info(f\"Device: {device}\")\n",
    "        logger.info(f\"Dataset path: {dataset_processed_path}\")\n",
    "        logger.info(f\"Output directory: {self.full_project_path}\")\n",
    "        \n",
    "        # Check if dataset path exists\n",
    "        if not self.dataset_processed_path.exists():\n",
    "            logger.error(f\"Dataset path not found: {self.dataset_processed_path}\")\n",
    "        else:\n",
    "            logger.success(f\"Dataset path found: {self.dataset_processed_path}\")\n",
    "    \n",
    "    def _cleanup_project_directory(self):\n",
    "        \"\"\"Clean up project directory to avoid auto-increment naming issues.\"\"\"\n",
    "        if self.full_project_path.exists():\n",
    "            logger.info(f\"Cleaning up existing project directory: {self.full_project_path}\")\n",
    "            shutil.rmtree(self.full_project_path)\n",
    "            logger.info(\"Project directory cleaned up\")\n",
    "    \n",
    "    def create_dataset_yaml(self, fold_path: Path, class_names: list = None):\n",
    "        \"\"\"\n",
    "        Create YOLO dataset configuration file.\n",
    "        \n",
    "        Args:\n",
    "            fold_path: Path to specific fold dataset\n",
    "            class_names: List of class names (default: [\"free_space\"])\n",
    "        \"\"\"\n",
    "        if class_names is None:\n",
    "            class_names = [\"free_space\"]\n",
    "        \n",
    "        dataset_config = {\n",
    "            'path': str(fold_path.absolute()),\n",
    "            'train': 'train/images',\n",
    "            'val': 'val/images', \n",
    "            'test': 'test/images',\n",
    "            'nc': len(class_names),\n",
    "            'names': {i: name for i, name in enumerate(class_names)}\n",
    "        }\n",
    "        \n",
    "        yaml_path = fold_path / 'dataset.yaml'\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "        \n",
    "        logger.info(f\"Created dataset config: {yaml_path}\")\n",
    "        return yaml_path\n",
    "    \n",
    "    def train_single_fold(self, \n",
    "                         fold_num: int, \n",
    "                         class_names: list = None,\n",
    "                         custom_params: dict = None):\n",
    "        \"\"\"\n",
    "        Train on a single cross-validation fold.\n",
    "        \n",
    "        Args:\n",
    "            fold_num: Fold number (0-4)\n",
    "            class_names: List of class names\n",
    "            custom_params: Custom training parameters\n",
    "        \"\"\"\n",
    "        logger.info(f\"Starting training for fold {fold_num}\")\n",
    "        \n",
    "        # Setup paths\n",
    "        fold_path = self.dataset_processed_path / f\"fold_{fold_num}_dataset\"\n",
    "        \n",
    "        if not fold_path.exists():\n",
    "            raise ValueError(f\"Fold dataset not found: {fold_path}\")\n",
    "        \n",
    "        # Use existing dataset.yaml if it exists, otherwise create one\n",
    "        yaml_path = fold_path / 'dataset.yaml'\n",
    "        if not yaml_path.exists():\n",
    "            yaml_path = self.create_dataset_yaml(fold_path, class_names)\n",
    "        else:\n",
    "            logger.info(f\"Using existing dataset config: {yaml_path}\")\n",
    "        \n",
    "        # Load pre-trained model with validation\n",
    "        model = YOLO(self.model_name)\n",
    "        logger.info(f\"Loaded pre-trained model: {self.model_name}\")\n",
    "        \n",
    "        # Merge custom parameters\n",
    "        train_params = self.training_params.copy()\n",
    "        if custom_params:\n",
    "            train_params.update(custom_params)\n",
    "        \n",
    "        # Clean up any existing folder to avoid auto-increment naming\n",
    "        fold_dir = self.full_project_path / f\"fold_{fold_num}\"\n",
    "        if fold_dir.exists():\n",
    "            logger.info(f\"Removing existing fold directory: {fold_dir}\")\n",
    "            shutil.rmtree(fold_dir)\n",
    "        \n",
    "        # Train the model\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = model.train(\n",
    "            data=str(yaml_path),\n",
    "            project=str(self.output_dir),  # Use output directory\n",
    "            name=str(self.full_project_path.name) + f\"/fold_{fold_num}\",  # Include project name in the path\n",
    "            device=self.device,\n",
    "            exist_ok=True,  # Allow overwriting\n",
    "            **train_params\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Validate the model on the best checkpoint\n",
    "        val_results = model.val(data=str(yaml_path))\n",
    "        \n",
    "        # Extract comprehensive results from training (with API compatibility)\n",
    "        try:\n",
    "            # Try to get metrics - handle different YOLO versions\n",
    "            if hasattr(val_results, 'seg'):\n",
    "                # Segmentation metrics\n",
    "                metrics = {\n",
    "                    'mAP50': float(val_results.seg.map50),\n",
    "                    'mAP50-95': float(val_results.seg.map),\n",
    "                    'precision': float(val_results.seg.mp),\n",
    "                    'recall': float(val_results.seg.mr),\n",
    "                }\n",
    "            elif hasattr(val_results, 'box'):\n",
    "                # Detection metrics (fallback)\n",
    "                logger.warning(f\"Using detection metrics for fold {fold_num} - ensure you're using a segmentation model!\")\n",
    "                metrics = {\n",
    "                    'mAP50': float(val_results.box.map50),\n",
    "                    'mAP50-95': float(val_results.box.map),\n",
    "                    'precision': float(val_results.box.mp),\n",
    "                    'recall': float(val_results.box.mr),\n",
    "                }\n",
    "            else:\n",
    "                # Fallback metrics\n",
    "                logger.warning(f\"Could not extract detailed metrics for fold {fold_num}\")\n",
    "                metrics = {\n",
    "                    'mAP50': 0.0,\n",
    "                    'mAP50-95': 0.0,\n",
    "                    'precision': 0.0,\n",
    "                    'recall': 0.0,\n",
    "                }\n",
    "            \n",
    "            # Extract training info with safe attribute access\n",
    "            total_epochs = len(getattr(results, 'results', [])) if hasattr(results, 'results') else getattr(results, 'epochs', 0)\n",
    "            best_epoch = getattr(results, 'best_epoch', total_epochs)\n",
    "            best_fitness = float(getattr(results, 'best_fitness', 0.0))\n",
    "            \n",
    "            # FIXED: Get save directory with proper API compatibility\n",
    "            if hasattr(results, 'save_dir'):\n",
    "                save_dir = str(results.save_dir)\n",
    "            else:\n",
    "                # Fallback: construct expected path\n",
    "                save_dir = str(self.full_project_path / f\"fold_{fold_num}\")\n",
    "            \n",
    "            # Try to get training losses safely\n",
    "            training_metrics = {}\n",
    "            if hasattr(results, 'results') and results.results and len(results.results) > 0:\n",
    "                try:\n",
    "                    last_result = results.results[-1]\n",
    "                    if isinstance(last_result, (list, tuple)) and len(last_result) >= 2:\n",
    "                        training_metrics = {\n",
    "                            'final_train_loss': float(last_result[0]),\n",
    "                            'final_val_loss': float(last_result[1]),\n",
    "                            'convergence_epoch': best_epoch,\n",
    "                        }\n",
    "                except (IndexError, TypeError, ValueError):\n",
    "                    pass\n",
    "            \n",
    "            fold_results = {\n",
    "                'fold': fold_num,\n",
    "                'training_time': training_time,\n",
    "                'total_epochs': total_epochs,\n",
    "                'best_epoch': best_epoch,\n",
    "                'best_fitness': best_fitness,\n",
    "                'final_metrics': metrics,\n",
    "                'training_metrics': training_metrics,\n",
    "                'model_path': str(Path(save_dir) / \"weights\" / \"best.pt\"),\n",
    "                'results_dir': save_dir,\n",
    "                'plots_saved': True if Path(save_dir).exists() else False\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting results for fold {fold_num}: {e}\")\n",
    "            # Import traceback for detailed error info\n",
    "            import traceback\n",
    "            logger.error(f\"Full traceback: {traceback.format_exc()}\")\n",
    "            \n",
    "            # Minimal fallback results\n",
    "            save_dir = str(self.full_project_path / f\"fold_{fold_num}\")\n",
    "            fold_results = {\n",
    "                'fold': fold_num,\n",
    "                'training_time': training_time,\n",
    "                'total_epochs': 0,\n",
    "                'best_epoch': 0,\n",
    "                'best_fitness': 0.0,\n",
    "                'final_metrics': {'mAP50': 0.0, 'mAP50-95': 0.0, 'precision': 0.0, 'recall': 0.0},\n",
    "                'training_metrics': {},\n",
    "                'model_path': str(Path(save_dir) / \"weights\" / \"best.pt\"),\n",
    "                'results_dir': save_dir,\n",
    "                'plots_saved': False\n",
    "            }\n",
    "        \n",
    "        self.cv_results.append(fold_results)\n",
    "        \n",
    "        # Log detailed results\n",
    "        self._log_fold_results(fold_results, results)\n",
    "        \n",
    "        logger.success(f\"Fold {fold_num} completed in {training_time/60:.1f} minutes\")\n",
    "        logger.info(f\"Best mAP50: {fold_results['final_metrics']['mAP50']:.4f}\")\n",
    "        \n",
    "        return fold_results\n",
    "    \n",
    "    def _log_fold_results(self, fold_results, training_results):\n",
    "        \"\"\"Log detailed results from training.\"\"\"\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(f\"FOLD {fold_results['fold']} TRAINING SUMMARY\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(f\"Training time: {fold_results['training_time']/60:.1f} minutes\")\n",
    "        logger.info(f\"Total epochs: {fold_results['total_epochs']}\")\n",
    "        logger.info(f\"Best epoch: {fold_results['best_epoch']}\")\n",
    "        logger.info(f\"Best fitness: {fold_results['best_fitness']:.4f}\")\n",
    "        logger.info(\"Final Metrics:\")\n",
    "        for metric, value in fold_results['final_metrics'].items():\n",
    "            logger.info(f\"  {metric}: {value:.4f}\")\n",
    "        logger.info(f\"Results saved to: {fold_results['results_dir']}\")\n",
    "        logger.info(\"=\" * 60)\n",
    "    \n",
    "    def train_cross_validation(self, \n",
    "                              folds: list = None,\n",
    "                              class_names: list = None,\n",
    "                              custom_params: dict = None):\n",
    "        \"\"\"\n",
    "        Train all cross-validation folds.\n",
    "        \n",
    "        Args:\n",
    "            folds: List of fold numbers to train (default: [0,1,2,3,4])\n",
    "            class_names: List of class names\n",
    "            custom_params: Custom training parameters\n",
    "        \"\"\"\n",
    "        if folds is None:\n",
    "            folds = list(range(5))\n",
    "        \n",
    "        logger.info(f\"Starting cross-validation training for folds: {folds}\")\n",
    "        \n",
    "        # Clean up any existing project directory to avoid naming conflicts\n",
    "        self._cleanup_project_directory()\n",
    "        \n",
    "        for fold_num in folds:\n",
    "            try:\n",
    "                self.train_single_fold(fold_num, class_names, custom_params)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to train fold {fold_num}: {e}\")\n",
    "                import traceback\n",
    "                logger.error(f\"Full traceback: {traceback.format_exc()}\")\n",
    "                continue\n",
    "        \n",
    "        # Analyze results\n",
    "        self.analyze_cv_results()\n",
    "        \n",
    "        logger.success(\"Cross-validation training completed!\")\n",
    "    \n",
    "    def analyze_cv_results(self):\n",
    "        \"\"\"Analyze cross-validation results.\"\"\"\n",
    "        if not self.cv_results:\n",
    "            logger.warning(\"No CV results to analyze\")\n",
    "            return\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(self.cv_results)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        metrics = ['mAP50', 'mAP50-95', 'precision', 'recall']\n",
    "        stats = {}\n",
    "        \n",
    "        for metric in metrics:\n",
    "            values = [r['final_metrics'][metric] for r in self.cv_results]\n",
    "            stats[metric] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values)\n",
    "            }\n",
    "        \n",
    "        # Log summary\n",
    "        logger.info(\"Cross-Validation Results Summary:\")\n",
    "        logger.info(\"-\" * 50)\n",
    "        for metric, stat in stats.items():\n",
    "            logger.info(f\"{metric:12s}: {stat['mean']:.4f} ¬± {stat['std']:.4f} \"\n",
    "                       f\"(min: {stat['min']:.4f}, max: {stat['max']:.4f})\")\n",
    "        \n",
    "        # Create visualization\n",
    "        self.plot_cv_results(df)\n",
    "        \n",
    "        # Save results\n",
    "        self.save_cv_results(df, stats)\n",
    "        \n",
    "        # Plot training curves if available\n",
    "        self.plot_training_curves()\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def plot_training_curves(self):\n",
    "        \"\"\"Plot training curves for all folds with API compatibility.\"\"\"\n",
    "        if not self.cv_results:\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, fold_result in enumerate(self.cv_results):\n",
    "            # Try to load training results\n",
    "            results_dir = Path(fold_result['results_dir'])\n",
    "            results_csv = results_dir / 'results.csv'\n",
    "            \n",
    "            if results_csv.exists():\n",
    "                try:\n",
    "                    df = pd.read_csv(results_csv)\n",
    "                    \n",
    "                    # Plot training curves\n",
    "                    if len(df) > 1:\n",
    "                        color = f'C{i}'\n",
    "                        label = f\"Fold {fold_result['fold']}\"\n",
    "                        \n",
    "                        # Loss curves - handle different column names\n",
    "                        train_loss_cols = ['train/box_loss', 'train/loss', 'train/total_loss']\n",
    "                        val_loss_cols = ['val/box_loss', 'val/loss', 'val/total_loss']\n",
    "                        \n",
    "                        train_loss_col = next((col for col in train_loss_cols if col in df.columns), None)\n",
    "                        val_loss_col = next((col for col in val_loss_cols if col in df.columns), None)\n",
    "                        \n",
    "                        if train_loss_col:\n",
    "                            axes[0].plot(df['epoch'], df[train_loss_col], \n",
    "                                       color=color, label=f\"{label} Train\", alpha=0.7)\n",
    "                        if val_loss_col:\n",
    "                            axes[0].plot(df['epoch'], df[val_loss_col], \n",
    "                                       color=color, linestyle='--', label=f\"{label} Val\", alpha=0.7)\n",
    "                        \n",
    "                        # mAP curves - handle different column names\n",
    "                        map_cols = ['metrics/mAP50(M)', 'metrics/mAP50-95(M)', 'val/mAP50', 'val/mAP50-95']\n",
    "                        map_col = next((col for col in map_cols if col in df.columns), None)\n",
    "                        if map_col:\n",
    "                            axes[1].plot(df['epoch'], df[map_col], \n",
    "                                       color=color, label=label, alpha=0.7)\n",
    "                        \n",
    "                        # Precision curves - handle different column names\n",
    "                        prec_cols = ['metrics/precision(M)', 'val/precision', 'metrics/precision']\n",
    "                        prec_col = next((col for col in prec_cols if col in df.columns), None)\n",
    "                        if prec_col:\n",
    "                            axes[2].plot(df['epoch'], df[prec_col], \n",
    "                                       color=color, label=label, alpha=0.7)\n",
    "                        \n",
    "                        # Recall curves - handle different column names\n",
    "                        rec_cols = ['metrics/recall(M)', 'val/recall', 'metrics/recall']\n",
    "                        rec_col = next((col for col in rec_cols if col in df.columns), None)\n",
    "                        if rec_col:\n",
    "                            axes[3].plot(df['epoch'], df[rec_col], \n",
    "                                       color=color, label=label, alpha=0.7)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not plot training curves for fold {fold_result['fold']}: {e}\")\n",
    "        \n",
    "        # Customize plots\n",
    "        titles = ['Training/Validation Loss', 'mAP50', 'Precision', 'Recall']\n",
    "        for ax, title in zip(axes, titles):\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        curves_path = self.full_project_path / \"training_curves.png\"\n",
    "        plt.savefig(curves_path, dpi=300, bbox_inches='tight')\n",
    "        logger.info(f\"Training curves saved: {curves_path}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_cv_results(self, df):\n",
    "        \"\"\"Create visualizations of CV results.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        metrics = ['mAP50', 'mAP50-95', 'precision', 'recall']\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            ax = axes[i//2, i%2]\n",
    "            values = [r['final_metrics'][metric] for r in self.cv_results]\n",
    "            \n",
    "            # Bar plot\n",
    "            bars = ax.bar(df['fold'], values, alpha=0.7, color=f'C{i}')\n",
    "            ax.set_xlabel('Fold')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.set_title(f'{metric} across folds')\n",
    "            ax.set_ylim(0, 1)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, value in zip(bars, values):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                       f'{value:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            # Add mean line\n",
    "            mean_val = np.mean(values)\n",
    "            ax.axhline(y=mean_val, color='red', linestyle='--', alpha=0.7,\n",
    "                      label=f'Mean: {mean_val:.3f}')\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = self.full_project_path / \"cv_results.png\"\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        logger.info(f\"Results plot saved: {plot_path}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def save_cv_results(self, df, stats):\n",
    "        \"\"\"Save detailed CV results.\"\"\"\n",
    "        results_dir = self.full_project_path / \"cv_analysis\"\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save detailed results\n",
    "        df.to_csv(results_dir / \"detailed_results.csv\", index=False)\n",
    "        \n",
    "        # Save summary statistics\n",
    "        stats_df = pd.DataFrame(stats).T\n",
    "        stats_df.to_csv(results_dir / \"summary_stats.csv\")\n",
    "        \n",
    "        # Save comprehensive results including training metrics\n",
    "        comprehensive_results = []\n",
    "        for result in self.cv_results:\n",
    "            flat_result = {\n",
    "                'fold': result['fold'],\n",
    "                'training_time_minutes': result['training_time'] / 60,\n",
    "                'total_epochs': result.get('total_epochs', 'N/A'),\n",
    "                'best_epoch': result['best_epoch'],\n",
    "                'best_fitness': result['best_fitness'],\n",
    "                'final_mAP50': result['final_metrics']['mAP50'],\n",
    "                'final_mAP50_95': result['final_metrics']['mAP50-95'],\n",
    "                'final_precision': result['final_metrics']['precision'],\n",
    "                'final_recall': result['final_metrics']['recall'],\n",
    "                'model_path': result['model_path'],\n",
    "                'results_directory': result.get('results_dir', 'N/A')\n",
    "            }\n",
    "            \n",
    "            # Add training metrics if available\n",
    "            if 'training_metrics' in result:\n",
    "                flat_result.update({\n",
    "                    'final_train_loss': result['training_metrics'].get('final_train_loss', 'N/A'),\n",
    "                    'final_val_loss': result['training_metrics'].get('final_val_loss', 'N/A'),\n",
    "                    'convergence_epoch': result['training_metrics'].get('convergence_epoch', 'N/A')\n",
    "                })\n",
    "            \n",
    "            comprehensive_results.append(flat_result)\n",
    "        \n",
    "        comprehensive_df = pd.DataFrame(comprehensive_results)\n",
    "        comprehensive_df.to_csv(results_dir / \"comprehensive_results.csv\", index=False)\n",
    "        \n",
    "        # Save configuration\n",
    "        config = {\n",
    "            'model_name': self.model_name,\n",
    "            'training_params': self.training_params,\n",
    "            'dataset_path': str(self.dataset_processed_path),\n",
    "            'project_name': self.project_name,\n",
    "            'total_folds_trained': len(self.cv_results),\n",
    "            'average_training_time_minutes': np.mean([r['training_time']/60 for r in self.cv_results]),\n",
    "            'best_performing_fold': max(self.cv_results, key=lambda x: x['final_metrics']['mAP50'])['fold'] if self.cv_results else 'N/A',\n",
    "        }\n",
    "        \n",
    "        with open(results_dir / \"training_config.yaml\", 'w') as f:\n",
    "            yaml.dump(config, f, default_flow_style=False)\n",
    "        \n",
    "        logger.info(f\"Results saved to: {results_dir}\")\n",
    "        logger.info(f\"Comprehensive results saved: {results_dir / 'comprehensive_results.csv'}\")\n",
    "        \n",
    "        return results_dir\n",
    "    \n",
    "    def predict_on_test_set(self, best_fold: int = None):\n",
    "        \"\"\"\n",
    "        Use the best model to predict on test sets.\n",
    "        \n",
    "        Args:\n",
    "            best_fold: Fold number of best model (auto-select if None)\n",
    "        \"\"\"\n",
    "        if not self.cv_results:\n",
    "            logger.error(\"No trained models available\")\n",
    "            return\n",
    "        \n",
    "        # Select best fold based on mAP50\n",
    "        if best_fold is None:\n",
    "            best_fold = max(self.cv_results, \n",
    "                          key=lambda x: x['final_metrics']['mAP50'])['fold']\n",
    "        \n",
    "        logger.info(f\"Using model from fold {best_fold} for predictions\")\n",
    "        \n",
    "        # Load best model\n",
    "        model_path = self.full_project_path / f\"fold_{best_fold}\" / \"weights\" / \"best.pt\"\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            logger.error(f\"Model not found: {model_path}\")\n",
    "            return\n",
    "        \n",
    "        model = YOLO(str(model_path))\n",
    "        \n",
    "        # Test on all folds\n",
    "        for fold_num in range(5):\n",
    "            fold_path = self.dataset_processed_path / f\"fold_{fold_num}_dataset\"\n",
    "            test_images = fold_path / \"test\" / \"images\"\n",
    "            \n",
    "            if test_images.exists():\n",
    "                logger.info(f\"Predicting on fold {fold_num} test set\")\n",
    "                \n",
    "                try:\n",
    "                    results = model.predict(\n",
    "                        source=str(test_images),\n",
    "                        project=str(self.output_dir),\n",
    "                        name=str(self.full_project_path.name) + f\"/predictions_fold_{fold_num}\",\n",
    "                        save=True,\n",
    "                        save_txt=True,\n",
    "                        save_conf=True,\n",
    "                        conf=0.5,\n",
    "                        iou=0.7\n",
    "                    )\n",
    "                    \n",
    "                    logger.success(f\"Predictions saved for fold {fold_num}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to predict on fold {fold_num}: {e}\")\n",
    "            else:\n",
    "                logger.warning(f\"Test images not found for fold {fold_num}: {test_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1d69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_YOLO:\n",
    "    # Initialize trainer\n",
    "    trainer = YOLOSegmentationTrainer(\n",
    "        dataset_processed_path=DATASET_PROCESSED_PATH,\n",
    "        model_name=MODEL_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        output_dir=OUTPUT_DIR_YOLO,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    # Full cross-validation\n",
    "    logger.info(\"Starting full cross-validation training...\")\n",
    "    trainer.train_cross_validation(\n",
    "        class_names=CLASS_NAMES,\n",
    "        custom_params=CUSTOM_PARAMS\n",
    "    )\n",
    "\n",
    "    # Make predictions on test sets\n",
    "    trainer.predict_on_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73caa2e6",
   "metadata": {},
   "source": [
    "## Evaluate on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e69dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoCVEvaluator:\n",
    "    \"\"\"\n",
    "    Automatically find and evaluate all fold models in training directory\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 training_base_dir: str,\n",
    "                 dataset_base_path: str,\n",
    "                 output_dir: str = \"auto_cv_evaluation_results\",\n",
    "                 conf_threshold: float = 0.5,\n",
    "                 iou_threshold: float = 0.7,\n",
    "                 class_names: list = None):\n",
    "        \"\"\"\n",
    "        Initialize Auto CV evaluator for comprehensive model comparison\n",
    "        \n",
    "        Args:\n",
    "            training_base_dir: Base directory containing yolo_* directories (e.g., \"training_yolo\")\n",
    "            dataset_base_path: Base path to dataset folds\n",
    "            output_dir: Directory to save CV evaluation results\n",
    "            conf_threshold: Confidence threshold for predictions\n",
    "            iou_threshold: IoU threshold for NMS\n",
    "            class_names: List of class names\n",
    "        \"\"\"\n",
    "        self.training_base_dir = Path(training_base_dir)\n",
    "        self.dataset_base_path = Path(dataset_base_path)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.class_names = class_names or [\"free_space\"]\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Results storage\n",
    "        self.all_per_image_results = []  # Master dataframe data\n",
    "        self.fold_summaries = []\n",
    "        self.cv_summary = {}\n",
    "        \n",
    "        print(f\"Initialized Comprehensive Model Evaluator:\")\n",
    "        print(f\"  Training base: {self.training_base_dir}\")\n",
    "        print(f\"  Dataset base: {self.dataset_base_path}\")\n",
    "        print(f\"  Output: {self.output_dir}\")\n",
    "        print(f\"  Will evaluate ALL yolo_* projects with 3+ folds\")\n",
    "    \n",
    "    def find_fold_models(self):\n",
    "        \"\"\"Automatically find all fold models in ALL yolo_* directories and let user choose\"\"\"\n",
    "        fold_models = {}\n",
    "        \n",
    "        print(\"Searching for fold models in ALL yolo_* directories...\")\n",
    "        \n",
    "        # Find all yolo_* project directories\n",
    "        yolo_projects = [item for item in self.training_base_dir.iterdir() \n",
    "                        if item.is_dir() and item.name.startswith('yolo_')]\n",
    "        \n",
    "        if not yolo_projects:\n",
    "            print(\"No yolo_* directories found!\")\n",
    "            return fold_models\n",
    "        \n",
    "        print(f\"Found {len(yolo_projects)} yolo_* project directories:\")\n",
    "        \n",
    "        # Search through ALL yolo_* projects and collect info\n",
    "        project_models = {}\n",
    "        for project_dir in yolo_projects:\n",
    "            print(f\"\\nSearching in project: {project_dir.name}\")\n",
    "            \n",
    "            # Look for fold_X directories within this project\n",
    "            project_folds = {}\n",
    "            for item in project_dir.iterdir():\n",
    "                if item.is_dir() and item.name.startswith('fold_'):\n",
    "                    try:\n",
    "                        # Extract fold number\n",
    "                        fold_num = int(item.name.split('fold_')[1])\n",
    "                        \n",
    "                        # Deep search for best.pt files\n",
    "                        model_path = self.deep_search_best_pt(item)\n",
    "                        \n",
    "                        if model_path:\n",
    "                            project_folds[fold_num] = model_path\n",
    "                            print(f\"  ‚úì Found Fold {fold_num}: {model_path}\")\n",
    "                        else:\n",
    "                            print(f\"  ‚úó Fold {fold_num} directory found but no best.pt: {item}\")\n",
    "                            \n",
    "                    except ValueError:\n",
    "                        # Not a valid fold_X format\n",
    "                        continue\n",
    "            \n",
    "            if project_folds:\n",
    "                project_models[project_dir.name] = {\n",
    "                    'folds': project_folds,\n",
    "                    'count': len(project_folds),\n",
    "                    'path': project_dir\n",
    "                }\n",
    "                print(f\"  ‚Üí Found {len(project_folds)} fold models in {project_dir.name}\")\n",
    "        \n",
    "        if not project_models:\n",
    "            print(\"\\nNo fold models found in any yolo_* directories!\")\n",
    "            return fold_models\n",
    "        \n",
    "        # Display options\n",
    "        print(f\"\\nAvailable projects with models:\")\n",
    "        print(\"-\" * 60)\n",
    "        for proj_name, info in project_models.items():\n",
    "            folds = sorted(info['folds'].keys())\n",
    "            print(f\"{proj_name}: {info['count']} folds {folds}\")\n",
    "        \n",
    "        # Select project based on target_project parameter or auto-select\n",
    "        if self.target_project:\n",
    "            if self.target_project in project_models:\n",
    "                selected_project = self.target_project\n",
    "                selected_models = project_models[self.target_project]['folds']\n",
    "                print(f\"\\nUsing specified project: {selected_project}\")\n",
    "            else:\n",
    "                print(f\"\\nSpecified project '{self.target_project}' not found!\")\n",
    "                print(\"Available projects:\", list(project_models.keys()))\n",
    "                return fold_models\n",
    "        else:\n",
    "            # Auto-select the project with the most folds\n",
    "            best_project = max(project_models.items(), key=lambda x: x[1]['count'])\n",
    "            selected_project = best_project[0]\n",
    "            selected_models = best_project[1]['folds']\n",
    "            print(f\"\\nAuto-selected: {selected_project} ({best_project[1]['count']} folds)\")\n",
    "        \n",
    "        print(\"Final model selection:\")\n",
    "        for fold_num in sorted(selected_models.keys()):\n",
    "            print(f\"  Fold {fold_num}: {selected_models[fold_num]}\")\n",
    "        \n",
    "        return selected_models\n",
    "    \n",
    "    def deep_search_best_pt(self, fold_dir):\n",
    "        \"\"\"Recursively search for best.pt in a fold directory\"\"\"\n",
    "        for root, dirs, files in os.walk(fold_dir):\n",
    "            if \"best.pt\" in files:\n",
    "                return Path(root) / \"best.pt\"\n",
    "        return None\n",
    "    \n",
    "    def find_shared_test_dataset(self):\n",
    "        \"\"\"Find shared test dataset (same for all folds)\"\"\"\n",
    "        # Try different naming conventions for the first available test dataset\n",
    "        possible_dataset_names = [\n",
    "            \"fold_0_dataset\",\n",
    "            \"fold0_dataset\", \n",
    "            \"fold_0\",\n",
    "            \"fold0\"\n",
    "        ]\n",
    "        \n",
    "        for dataset_name in possible_dataset_names:\n",
    "            dataset_path = self.dataset_base_path / dataset_name\n",
    "            test_images_dir = dataset_path / \"test\" / \"images\"\n",
    "            test_labels_dir = dataset_path / \"test\" / \"labels\"\n",
    "            \n",
    "            if test_images_dir.exists() and test_labels_dir.exists():\n",
    "                print(f\"  ‚úì Using shared test dataset: {dataset_path}\")\n",
    "                return test_images_dir, test_labels_dir\n",
    "        \n",
    "        # If specific fold datasets not found, try direct test directory\n",
    "        direct_test_images = self.dataset_base_path / \"test\" / \"images\"\n",
    "        direct_test_labels = self.dataset_base_path / \"test\" / \"labels\"\n",
    "        \n",
    "        if direct_test_images.exists() and direct_test_labels.exists():\n",
    "            print(f\"  ‚úì Using direct test dataset: {self.dataset_base_path / 'test'}\")\n",
    "            return direct_test_images, direct_test_labels\n",
    "        \n",
    "        print(f\"  ‚úó Could not find shared test dataset in {self.dataset_base_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    def evaluate_single_fold_simple(self, fold_num, model_path, shared_test_images_dir, shared_test_labels_dir, project_name=None):\n",
    "        \"\"\"\n",
    "        Simplified evaluation function that doesn't require the external script\n",
    "        Uses shared test dataset for all folds\n",
    "        \"\"\"\n",
    "        print(f\"\\nEvaluating {project_name} - Fold {fold_num}...\")\n",
    "        print(f\"  Model: {model_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Import YOLO\n",
    "            from ultralytics import YOLO\n",
    "            import cv2\n",
    "            \n",
    "            # Load model\n",
    "            model = YOLO(str(model_path))\n",
    "            print(f\"  ‚úì Loaded model successfully\")\n",
    "            \n",
    "            # Get test images\n",
    "            image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']\n",
    "            image_files = []\n",
    "            \n",
    "            for ext in image_extensions:\n",
    "                image_files.extend(shared_test_images_dir.glob(ext))\n",
    "            \n",
    "            image_files.sort()\n",
    "            print(f\"  Found {len(image_files)} test images\")\n",
    "            \n",
    "            if not image_files:\n",
    "                print(f\"  ‚úó No test images found in {shared_test_images_dir}\")\n",
    "                return None\n",
    "            \n",
    "            # Evaluate each image\n",
    "            fold_results = []\n",
    "            all_tp, all_tn, all_fp, all_fn = 0, 0, 0, 0\n",
    "            \n",
    "            for image_file in tqdm(image_files, desc=f\"  Processing {project_name} fold {fold_num}\", leave=False):\n",
    "                try:\n",
    "                    result = self.evaluate_single_image_simple(\n",
    "                        image_file, shared_test_labels_dir, model, fold_num, project_name\n",
    "                    )\n",
    "                    \n",
    "                    if result:\n",
    "                        fold_results.append(result)\n",
    "                        # Accumulate confusion matrix\n",
    "                        all_tp += result['true_positives']\n",
    "                        all_tn += result['true_negatives'] \n",
    "                        all_fp += result['false_positives']\n",
    "                        all_fn += result['false_negatives']\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error processing {image_file.name}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if not fold_results:\n",
    "                print(f\"  ‚úó No valid results for {project_name} fold {fold_num}\")\n",
    "                return None\n",
    "            \n",
    "            # Calculate fold summary metrics\n",
    "            fold_df = pd.DataFrame(fold_results)\n",
    "            \n",
    "            # Overall metrics\n",
    "            epsilon = 1e-7\n",
    "            overall_precision = all_tp / (all_tp + all_fp + epsilon)\n",
    "            overall_recall = all_tp / (all_tp + all_fn + epsilon)\n",
    "            overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall + epsilon)\n",
    "            overall_iou = all_tp / (all_tp + all_fp + all_fn + epsilon)\n",
    "            overall_accuracy = (all_tp + all_tn) / (all_tp + all_tn + all_fp + all_fn + epsilon)\n",
    "            \n",
    "            fold_summary = {\n",
    "                'project': project_name,\n",
    "                'fold': fold_num,\n",
    "                'model_path': str(model_path),\n",
    "                'total_images': len(fold_results),\n",
    "                'overall_iou': overall_iou,\n",
    "                'overall_f1_score': overall_f1,\n",
    "                'overall_precision': overall_precision,\n",
    "                'overall_recall': overall_recall,\n",
    "                'overall_accuracy': overall_accuracy,\n",
    "                'mean_iou': fold_df['iou'].mean(),\n",
    "                'mean_f1_score': fold_df['f1_score'].mean(),\n",
    "                'mean_precision': fold_df['precision'].mean(),\n",
    "                'mean_recall': fold_df['recall'].mean(),\n",
    "                'std_iou': fold_df['iou'].std(),\n",
    "                'std_f1_score': fold_df['f1_score'].std(),\n",
    "                'total_tp': int(all_tp),\n",
    "                'total_tn': int(all_tn),\n",
    "                'total_fp': int(all_fp),\n",
    "                'total_fn': int(all_fn)\n",
    "            }\n",
    "            \n",
    "            # Add to master results\n",
    "            self.all_per_image_results.extend(fold_results)\n",
    "            self.fold_summaries.append(fold_summary)\n",
    "            \n",
    "            print(f\"  ‚úì {project_name} fold {fold_num} completed: {len(fold_results)} images, IoU={overall_iou:.4f}\")\n",
    "            \n",
    "            return fold_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error evaluating {project_name} fold {fold_num}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_single_image_simple(self, image_file, test_labels_dir, model, fold_num, project_name=None):\n",
    "        \"\"\"Simplified single image evaluation\"\"\"\n",
    "        try:\n",
    "            import cv2\n",
    "            \n",
    "            # Load ground truth\n",
    "            gt_mask = self.load_ground_truth_mask_simple(image_file, test_labels_dir)\n",
    "            if gt_mask is None:\n",
    "                return None\n",
    "            \n",
    "            # Get prediction\n",
    "            pred_mask = self.get_prediction_mask_simple(image_file, model)\n",
    "            if pred_mask is None:\n",
    "                return None\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self.calculate_metrics_simple(pred_mask, gt_mask)\n",
    "            \n",
    "            # Add metadata\n",
    "            metrics.update({\n",
    "                'project': project_name,\n",
    "                'fold': fold_num,\n",
    "                'image_name': image_file.name,\n",
    "                'image_path': str(image_file)\n",
    "            })\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {image_file.name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_ground_truth_mask_simple(self, image_file, test_labels_dir):\n",
    "        \"\"\"Load ground truth mask from YOLO label\"\"\"\n",
    "        try:\n",
    "            import cv2\n",
    "            \n",
    "            # Load image to get dimensions\n",
    "            img = cv2.imread(str(image_file))\n",
    "            if img is None:\n",
    "                return None\n",
    "            \n",
    "            img_height, img_width = img.shape[:2]\n",
    "            \n",
    "            # Load label file\n",
    "            image_name = image_file.stem\n",
    "            label_file = test_labels_dir / f\"{image_name}.txt\"\n",
    "            \n",
    "            # Initialize empty mask\n",
    "            gt_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "            \n",
    "            if label_file.exists() and label_file.stat().st_size > 0:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    parts = line.split()\n",
    "                    if len(parts) < 7:  # class + at least 3 points\n",
    "                        continue\n",
    "                    \n",
    "                    coords = [float(x) for x in parts[1:]]\n",
    "                    \n",
    "                    # Convert normalized coords to pixels\n",
    "                    points = []\n",
    "                    for i in range(0, len(coords), 2):\n",
    "                        x = int(coords[i] * img_width)\n",
    "                        y = int(coords[i + 1] * img_height)\n",
    "                        points.append([x, y])\n",
    "                    \n",
    "                    if len(points) >= 3:\n",
    "                        points = np.array(points, dtype=np.int32)\n",
    "                        cv2.fillPoly(gt_mask, [points], 255)\n",
    "            \n",
    "            return gt_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading GT for {image_file.name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_prediction_mask_simple(self, image_file, model):\n",
    "        \"\"\"Get prediction mask from model\"\"\"\n",
    "        try:\n",
    "            import cv2\n",
    "            \n",
    "            # Run inference\n",
    "            results = model.predict(\n",
    "                source=str(image_file),\n",
    "                conf=self.conf_threshold,\n",
    "                iou=self.iou_threshold,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            if not results:\n",
    "                img = cv2.imread(str(image_file))\n",
    "                img_height, img_width = img.shape[:2]\n",
    "                return np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "            \n",
    "            result = results[0]\n",
    "            img_height, img_width = result.orig_shape\n",
    "            \n",
    "            # Initialize prediction mask\n",
    "            pred_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "            \n",
    "            # Process masks\n",
    "            if hasattr(result, 'masks') and result.masks is not None:\n",
    "                masks = result.masks.data.cpu().numpy()\n",
    "                \n",
    "                for mask in masks:\n",
    "                    mask_resized = cv2.resize(mask, (img_width, img_height))\n",
    "                    mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255\n",
    "                    pred_mask = cv2.bitwise_or(pred_mask, mask_binary)\n",
    "            \n",
    "            return pred_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting prediction for {image_file.name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_metrics_simple(self, pred_mask, gt_mask):\n",
    "        \"\"\"Calculate segmentation metrics\"\"\"\n",
    "        # Convert to binary\n",
    "        pred_binary = (pred_mask > 127).astype(np.uint8)\n",
    "        gt_binary = (gt_mask > 127).astype(np.uint8)\n",
    "        \n",
    "        # Flatten\n",
    "        pred_flat = pred_binary.flatten()\n",
    "        gt_flat = gt_binary.flatten()\n",
    "        \n",
    "        # Confusion matrix\n",
    "        tp = np.sum((pred_flat == 1) & (gt_flat == 1))\n",
    "        tn = np.sum((pred_flat == 0) & (gt_flat == 0))\n",
    "        fp = np.sum((pred_flat == 1) & (gt_flat == 0))\n",
    "        fn = np.sum((pred_flat == 0) & (gt_flat == 1))\n",
    "        \n",
    "        # Metrics\n",
    "        epsilon = 1e-7\n",
    "        precision = tp / (tp + fp + epsilon)\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "        iou = tp / (tp + fp + fn + epsilon)\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn + epsilon)\n",
    "        dice = 2 * tp / (2 * tp + fp + fn + epsilon)\n",
    "        \n",
    "        return {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'iou': iou,\n",
    "            'accuracy': accuracy,\n",
    "            'dice_coefficient': dice,\n",
    "            'true_positives': int(tp),\n",
    "            'true_negatives': int(tn),\n",
    "            'false_positives': int(fp),\n",
    "            'false_negatives': int(fn)\n",
    "        }\n",
    "    \n",
    "    def evaluate_all_folds(self):\n",
    "        \"\"\"Evaluate ALL projects and all folds - comprehensive comparison\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING COMPREHENSIVE MODEL EVALUATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Find shared test dataset (same for all folds)\n",
    "        print(\"\\nFinding shared test dataset...\")\n",
    "        shared_test_images_dir, shared_test_labels_dir = self.find_shared_test_dataset()\n",
    "        \n",
    "        if shared_test_images_dir is None or shared_test_labels_dir is None:\n",
    "            print(\"‚ùå Could not find shared test dataset. Exiting.\")\n",
    "            return None, None\n",
    "        \n",
    "        # Find all projects with models\n",
    "        all_project_models = self.find_all_project_models()\n",
    "        \n",
    "        if not all_project_models:\n",
    "            print(\"‚ùå No project models found. Exiting.\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"\\nWill evaluate {len(all_project_models)} projects against the same test dataset\")\n",
    "        \n",
    "        # Evaluate each project\n",
    "        total_evaluations = 0\n",
    "        successful_evaluations = 0\n",
    "        \n",
    "        for project_name, fold_models in all_project_models.items():\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"EVALUATING PROJECT: {project_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            for fold_num in sorted(fold_models.keys()):\n",
    "                model_path = fold_models[fold_num]\n",
    "                total_evaluations += 1\n",
    "                \n",
    "                result = self.evaluate_single_fold_simple(\n",
    "                    fold_num, model_path, shared_test_images_dir, shared_test_labels_dir,\n",
    "                    project_name=project_name\n",
    "                )\n",
    "                if result:\n",
    "                    successful_evaluations += 1\n",
    "        \n",
    "        if successful_evaluations == 0:\n",
    "            print(\"‚ùå No evaluations were successful.\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"\\n‚úÖ Successfully completed {successful_evaluations}/{total_evaluations} evaluations\")\n",
    "        \n",
    "        # Create comprehensive dataframes\n",
    "        master_df = pd.DataFrame(self.all_per_image_results)\n",
    "        fold_summary_df = pd.DataFrame(self.fold_summaries)\n",
    "        \n",
    "        # Analyze results across all projects\n",
    "        self.analyze_comprehensive_results(master_df, fold_summary_df)\n",
    "        \n",
    "        # Save results\n",
    "        self.save_comprehensive_results(master_df, fold_summary_df)\n",
    "        \n",
    "        return master_df, fold_summary_df\n",
    "    \n",
    "    def find_all_project_models(self):\n",
    "        \"\"\"Find models for ALL projects that have complete fold sets\"\"\"\n",
    "        print(\"Searching for fold models in ALL yolo_* directories...\")\n",
    "        \n",
    "        # Find all yolo_* project directories\n",
    "        yolo_projects = [item for item in self.training_base_dir.iterdir() \n",
    "                        if item.is_dir() and item.name.startswith('yolo_')]\n",
    "        \n",
    "        if not yolo_projects:\n",
    "            print(\"No yolo_* directories found!\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"Found {len(yolo_projects)} yolo_* project directories:\")\n",
    "        \n",
    "        # Search through ALL yolo_* projects and collect info\n",
    "        all_project_models = {}\n",
    "        \n",
    "        for project_dir in yolo_projects:\n",
    "            print(f\"\\nSearching in project: {project_dir.name}\")\n",
    "            \n",
    "            # Look for fold_X directories within this project\n",
    "            project_folds = {}\n",
    "            for item in project_dir.iterdir():\n",
    "                if item.is_dir() and item.name.startswith('fold_'):\n",
    "                    try:\n",
    "                        # Extract fold number\n",
    "                        fold_num = int(item.name.split('fold_')[1])\n",
    "                        \n",
    "                        # Deep search for best.pt files\n",
    "                        model_path = self.deep_search_best_pt(item)\n",
    "                        \n",
    "                        if model_path:\n",
    "                            project_folds[fold_num] = model_path\n",
    "                            print(f\"  ‚úì Found Fold {fold_num}: {model_path}\")\n",
    "                        else:\n",
    "                            print(f\"  ‚úó Fold {fold_num} directory found but no best.pt: {item}\")\n",
    "                            \n",
    "                    except ValueError:\n",
    "                        # Not a valid fold_X format\n",
    "                        continue\n",
    "            \n",
    "            if project_folds:\n",
    "                # Only include projects with at least 3 folds (configurable)\n",
    "                min_folds = 3\n",
    "                if len(project_folds) >= min_folds:\n",
    "                    all_project_models[project_dir.name] = project_folds\n",
    "                    print(f\"  ‚Üí Will evaluate {len(project_folds)} folds from {project_dir.name}\")\n",
    "                else:\n",
    "                    print(f\"  ‚Üí Skipping {project_dir.name} (only {len(project_folds)} folds, need {min_folds}+)\")\n",
    "        \n",
    "        if not all_project_models:\n",
    "            print(\"\\nNo projects with sufficient folds found!\")\n",
    "            return {}\n",
    "        \n",
    "        # Display what will be evaluated\n",
    "        print(f\"\\nFinal evaluation plan:\")\n",
    "        print(\"-\" * 60)\n",
    "        total_folds = 0\n",
    "        for proj_name, folds in all_project_models.items():\n",
    "            fold_list = sorted(folds.keys())\n",
    "            print(f\"{proj_name}: {len(fold_list)} folds {fold_list}\")\n",
    "            total_folds += len(fold_list)\n",
    "        \n",
    "        print(f\"\\nTotal evaluations to perform: {total_folds}\")\n",
    "        \n",
    "        return all_project_models\n",
    "    \n",
    "    def analyze_comprehensive_results(self, master_df, fold_summary_df):\n",
    "        \"\"\"Analyze results across all projects and folds\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"COMPREHENSIVE ANALYSIS ACROSS ALL MODELS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if fold_summary_df.empty:\n",
    "            print(\"No results to analyze\")\n",
    "            return\n",
    "        \n",
    "        # Group by project\n",
    "        project_stats = {}\n",
    "        \n",
    "        print(\"Results by Project:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for project in fold_summary_df['project'].unique():\n",
    "            project_data = fold_summary_df[fold_summary_df['project'] == project]\n",
    "            \n",
    "            metrics_to_analyze = ['overall_iou', 'overall_f1_score', 'overall_precision', \n",
    "                                 'overall_recall', 'overall_accuracy']\n",
    "            \n",
    "            project_metrics = {}\n",
    "            for metric in metrics_to_analyze:\n",
    "                if metric in project_data.columns:\n",
    "                    project_metrics[metric] = {\n",
    "                        'mean': project_data[metric].mean(),\n",
    "                        'std': project_data[metric].std(),\n",
    "                        'min': project_data[metric].min(),\n",
    "                        'max': project_data[metric].max()\n",
    "                    }\n",
    "            \n",
    "            project_stats[project] = {\n",
    "                'folds_evaluated': len(project_data),\n",
    "                'total_images': project_data['total_images'].sum(),\n",
    "                'metrics': project_metrics\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{project}:\")\n",
    "            print(f\"  Folds: {len(project_data)} | Images: {project_data['total_images'].sum()}\")\n",
    "            for metric, stats in project_metrics.items():\n",
    "                metric_name = metric.replace('overall_', '').replace('_', ' ').title()\n",
    "                print(f\"  {metric_name:12s}: {stats['mean']:.4f} ¬± {stats['std']:.4f}\")\n",
    "        \n",
    "        # Find best performing models\n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(\"BEST PERFORMING MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        best_iou = fold_summary_df.loc[fold_summary_df['overall_iou'].idxmax()]\n",
    "        best_f1 = fold_summary_df.loc[fold_summary_df['overall_f1_score'].idxmax()]\n",
    "        \n",
    "        print(f\"Best IoU: {best_iou['project']} (Fold {best_iou['fold']}) - IoU: {best_iou['overall_iou']:.4f}\")\n",
    "        print(f\"Best F1:  {best_f1['project']} (Fold {best_f1['fold']}) - F1: {best_f1['overall_f1_score']:.4f}\")\n",
    "        \n",
    "        # Project rankings\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        print(\"PROJECT RANKINGS (by mean IoU)\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        project_rankings = []\n",
    "        for project in fold_summary_df['project'].unique():\n",
    "            project_data = fold_summary_df[fold_summary_df['project'] == project]\n",
    "            mean_iou = project_data['overall_iou'].mean()\n",
    "            mean_f1 = project_data['overall_f1_score'].mean()\n",
    "            project_rankings.append({\n",
    "                'project': project,\n",
    "                'mean_iou': mean_iou,\n",
    "                'mean_f1': mean_f1,\n",
    "                'folds': len(project_data)\n",
    "            })\n",
    "        \n",
    "        project_rankings.sort(key=lambda x: x['mean_iou'], reverse=True)\n",
    "        \n",
    "        for i, proj in enumerate(project_rankings, 1):\n",
    "            print(f\"{i}. {proj['project']}\")\n",
    "            print(f\"   Mean IoU: {proj['mean_iou']:.4f} | Mean F1: {proj['mean_f1']:.4f} | Folds: {proj['folds']}\")\n",
    "        \n",
    "        # Store comprehensive summary\n",
    "        self.cv_summary = {\n",
    "            'total_projects': len(fold_summary_df['project'].unique()),\n",
    "            'total_evaluations': len(fold_summary_df),\n",
    "            'total_images': master_df.shape[0] if not master_df.empty else 0,\n",
    "            'project_statistics': project_stats,\n",
    "            'project_rankings': project_rankings,\n",
    "            'best_models': {\n",
    "                'best_iou': {\n",
    "                    'project': best_iou['project'],\n",
    "                    'fold': best_iou['fold'],\n",
    "                    'value': best_iou['overall_iou']\n",
    "                },\n",
    "                'best_f1': {\n",
    "                    'project': best_f1['project'],\n",
    "                    'fold': best_f1['fold'],\n",
    "                    'value': best_f1['overall_f1_score']\n",
    "                }\n",
    "            },\n",
    "            'evaluation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    \n",
    "    def save_comprehensive_results(self, master_df, fold_summary_df):\n",
    "        \"\"\"Save all results with timestamp\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save master dataframe (all per-image results)\n",
    "        master_path = self.output_dir / f\"all_per_image_results_{timestamp}.csv\"\n",
    "        master_df.to_csv(master_path, index=False)\n",
    "        print(f\"\\n‚úì Master results saved: {master_path}\")\n",
    "        print(f\"  Shape: {master_df.shape}\")\n",
    "        \n",
    "        # Save fold summary\n",
    "        summary_path = self.output_dir / f\"fold_summary_{timestamp}.csv\"\n",
    "        fold_summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"‚úì Fold summary saved: {summary_path}\")\n",
    "        \n",
    "        # Save CV analysis\n",
    "        cv_path = self.output_dir / f\"cv_analysis_{timestamp}.json\"\n",
    "        with open(cv_path, 'w') as f:\n",
    "            json.dump(self.cv_summary, f, indent=2, default=str)\n",
    "        print(f\"‚úì CV analysis saved: {cv_path}\")\n",
    "        \n",
    "        # Create plots\n",
    "        self.create_summary_plots(master_df, fold_summary_df, timestamp)\n",
    "        \n",
    "        print(f\"\\nüéâ All results saved to: {self.output_dir}\")\n",
    "    \n",
    "    def create_summary_plots(self, master_df, fold_summary_df, timestamp):\n",
    "        \"\"\"Create comprehensive visualization plots for multiple projects\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Set style\n",
    "            plt.style.use('default')\n",
    "            \n",
    "            # Plot 1: Project comparison by metrics\n",
    "            if 'project' in fold_summary_df.columns:\n",
    "                fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "                axes = axes.flatten()\n",
    "                \n",
    "                metrics_to_plot = ['overall_iou', 'overall_f1_score', 'overall_precision',\n",
    "                                  'overall_recall', 'overall_accuracy', 'mean_iou']\n",
    "                \n",
    "                projects = fold_summary_df['project'].unique()\n",
    "                colors = plt.cm.Set3(np.linspace(0, 1, len(projects)))\n",
    "                \n",
    "                for i, metric in enumerate(metrics_to_plot):\n",
    "                    if metric in fold_summary_df.columns:\n",
    "                        ax = axes[i]\n",
    "                        \n",
    "                        # Create grouped bar plot\n",
    "                        x_pos = 0\n",
    "                        width = 0.15\n",
    "                        \n",
    "                        for j, project in enumerate(projects):\n",
    "                            project_data = fold_summary_df[fold_summary_df['project'] == project]\n",
    "                            folds = project_data['fold'].values\n",
    "                            values = project_data[metric].values\n",
    "                            \n",
    "                            x_positions = [x_pos + k * (width * len(projects) + 0.1) for k in range(len(folds))]\n",
    "                            bars = ax.bar([x + j * width for x in x_positions], values, \n",
    "                                         width, label=project.replace('yolo_', ''), \n",
    "                                         color=colors[j], alpha=0.8)\n",
    "                            \n",
    "                            # Add value labels on bars\n",
    "                            for bar, value in zip(bars, values):\n",
    "                                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                                       f'{value:.3f}', ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "                        \n",
    "                        ax.set_xlabel('Fold')\n",
    "                        ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "                        ax.set_title(f'{metric.replace(\"_\", \" \").title()} by Project and Fold')\n",
    "                        ax.set_ylim(0, 1)\n",
    "                        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Set x-tick labels to fold numbers\n",
    "                        n_folds = len(fold_summary_df['fold'].unique())\n",
    "                        ax.set_xticks([k * (width * len(projects) + 0.1) + width * (len(projects) - 1) / 2 \n",
    "                                      for k in range(n_folds)])\n",
    "                        ax.set_xticklabels([f'F{k}' for k in sorted(fold_summary_df['fold'].unique())])\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.output_dir / f\"project_fold_comparison_{timestamp}.png\", \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                # Plot 2: Project performance comparison (box plots)\n",
    "                fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "                axes = axes.flatten()\n",
    "                \n",
    "                for i, metric in enumerate(metrics_to_plot):\n",
    "                    if metric in fold_summary_df.columns:\n",
    "                        ax = axes[i]\n",
    "                        \n",
    "                        # Create box plot\n",
    "                        data_for_box = []\n",
    "                        labels = []\n",
    "                        for project in projects:\n",
    "                            project_data = fold_summary_df[fold_summary_df['project'] == project]\n",
    "                            data_for_box.append(project_data[metric].values)\n",
    "                            labels.append(project.replace('yolo_', ''))\n",
    "                        \n",
    "                        bp = ax.boxplot(data_for_box, labels=labels, patch_artist=True)\n",
    "                        \n",
    "                        # Color the boxes\n",
    "                        for patch, color in zip(bp['boxes'], colors):\n",
    "                            patch.set_facecolor(color)\n",
    "                            patch.set_alpha(0.7)\n",
    "                        \n",
    "                        ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "                        ax.set_title(f'{metric.replace(\"_\", \" \").title()} Distribution by Project')\n",
    "                        ax.tick_params(axis='x', rotation=45)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.output_dir / f\"project_performance_boxplot_{timestamp}.png\", \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "            # Plot 3: Per-image metrics distribution (if we have per-image data)\n",
    "            if not master_df.empty and 'project' in master_df.columns:\n",
    "                fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "                axes = axes.flatten()\n",
    "                \n",
    "                image_metrics = ['iou', 'f1_score', 'precision', 'recall', 'accuracy', 'dice_coefficient']\n",
    "                \n",
    "                for i, metric in enumerate(image_metrics):\n",
    "                    if metric in master_df.columns:\n",
    "                        ax = axes[i]\n",
    "                        \n",
    "                        # Create histogram for each project\n",
    "                        for j, project in enumerate(projects):\n",
    "                            project_data = master_df[master_df['project'] == project]\n",
    "                            ax.hist(project_data[metric], bins=30, alpha=0.6, \n",
    "                                   label=project.replace('yolo_', ''), color=colors[j])\n",
    "                        \n",
    "                        ax.set_xlabel(metric.replace('_', ' ').title())\n",
    "                        ax.set_ylabel('Frequency')\n",
    "                        ax.set_title(f'{metric.replace(\"_\", \" \").title()} Distribution')\n",
    "                        ax.legend()\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.output_dir / f\"per_image_distributions_{timestamp}.png\", \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            print(f\"‚úì Comprehensive plots saved\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not create plots: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8841d6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s‚Äôest bloqu√© lors de l‚Äôex√©cution du code dans une cellule active ou une cellule pr√©c√©dente. \n",
      "\u001b[1;31mVeuillez v√©rifier le code dans la ou les cellules pour identifier une cause possible de l‚Äô√©chec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d‚Äôinformations. \n",
      "\u001b[1;31mPour plus d‚Äôinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "if EVALUATE_YOLO:\n",
    "    # =============================================================================\n",
    "    # RUN EVALUATION\n",
    "    # =============================================================================\n",
    "\n",
    "    evaluator = AutoCVEvaluator(\n",
    "        training_base_dir=OUTPUT_DIR_YOLO,\n",
    "        dataset_base_path=DATASET_PROCESSED_PATH,\n",
    "        output_dir=OUTPUT_EVALUATE_TEST_DIR,\n",
    "        conf_threshold=CONF_THRESHOLD,\n",
    "        iou_threshold=IOU_THRESHOLD,\n",
    "        class_names=CLASS_NAMES,\n",
    "    )\n",
    "    # Run evaluation and get dataframes\n",
    "    master_df, fold_summary_df = evaluator.evaluate_all_folds()\n",
    "\n",
    "    if master_df is not None:\n",
    "        print(\"\\nüìä COMPREHENSIVE EVALUATION RESULTS:\")\n",
    "        print(f\"   üìã Per-Image DataFrame shape: {master_df.shape}\")\n",
    "        print(f\"      Columns: {list(master_df.columns)}\")\n",
    "        print(f\"   üìà Per-Fold DataFrame shape: {fold_summary_df.shape}\")\n",
    "        print(f\"      Columns: {list(fold_summary_df.columns)}\")\n",
    "        \n",
    "        # Show unique projects evaluated\n",
    "        if 'project' in master_df.columns:\n",
    "            unique_projects = master_df['project'].unique()\n",
    "            print(f\"   üöÄ Projects evaluated: {len(unique_projects)}\")\n",
    "            for proj in unique_projects:\n",
    "                count = len(master_df[master_df['project'] == proj])\n",
    "                print(f\"      - {proj}: {count} evaluations\")\n",
    "        \n",
    "        # Display sample results\n",
    "        print(\"\\nüìã Sample per-image results:\")\n",
    "        display_cols = ['project', 'fold', 'image_name', 'iou', 'f1_score', 'precision', 'recall']\n",
    "        available_cols = [col for col in display_cols if col in master_df.columns]\n",
    "        print(master_df[available_cols].head(10))\n",
    "        \n",
    "        print(\"\\nüìä Per-fold summary:\")\n",
    "        summary_cols = ['project', 'fold', 'total_images', 'overall_iou', 'overall_f1_score', 'mean_iou']\n",
    "        available_summary_cols = [col for col in summary_cols if col in fold_summary_df.columns]\n",
    "        print(fold_summary_df[available_summary_cols].round(4))\n",
    "        \n",
    "        print(\"\\nüíæ Files saved:\")\n",
    "        print(\"   - all_per_image_results_*.csv (Per-Image DataFrame)\")\n",
    "        print(\"   - fold_summary_*.csv (Per-Fold DataFrame)\")\n",
    "        print(\"   - cv_analysis_*.json (Comprehensive analysis)\")\n",
    "        print(\"   - fold_comparison_*.png (Visualization plots)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
