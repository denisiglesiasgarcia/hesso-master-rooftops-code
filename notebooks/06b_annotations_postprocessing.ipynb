{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tempfile\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.windows import from_bounds, Window\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "DATASET_ANNOTATED_BRUT_PATH = \"datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask\"\n",
    "DATASET_TILES_INFORMATION_CSV_PATH = \"data/notebook_06/dataset_20250405-193125/PNG_dataset_roboflow_20250405-193143/sampled_tiles.csv\"\n",
    "CORRECT_CRS = CRS.from_epsg(2056)\n",
    "EPSG_SUISSE = \"EPSG:2056\"\n",
    "\n",
    "CAD_BATIMENT_HORSOL_TOIT_MERGE_PARQUET_PATH = \"data/notebook_04/parquet/04_02_merged_rooftops_poly.parquet\"\n",
    "\n",
    "# Parquet files\n",
    "VERIFICATION_OUTPUT_PARQUET_PATH = \"data/notebook_06/parquet/06b_01_verification.parquet\"\n",
    "DATASET_OUTPUT_PARQUET_PATH = \"data/notebook_06/parquet/06b_02_dataset_processed.parquet\"\n",
    "DATASET_FINAL_OUTPUT_PARQUET_PATH = \"data/notebook_06/parquet/06b_03_dataset_final.parquet\"\n",
    "\n",
    "# dataset processed\n",
    "DATASET_PROCESSED_NAME = \"dataset_processed_\" + str(todays_date)\n",
    "DATASET_PROCESSED_PATH = \"datasets/supervisely/\" + DATASET_PROCESSED_NAME\n",
    "DATASET_OUTPUT_IMG_PATH = DATASET_PROCESSED_PATH + \"/images\"\n",
    "DATASET_OUTPUT_MASKS_PATH = DATASET_PROCESSED_PATH + \"/masks\"\n",
    "DATASET_OUTPUT_CHECKS_PATH = DATASET_PROCESSED_PATH + \"/check_dataset\"\n",
    "\n",
    "# buffer pour les chevauchements\n",
    "BUFFER_DISTANCE = 0 # en mètre\n",
    "OVERLAP_POSITIONS=['top', 'right', 'top-left', 'top-right']\n",
    "\n",
    "os.makedirs(DATASET_PROCESSED_PATH)\n",
    "os.makedirs(DATASET_OUTPUT_IMG_PATH)\n",
    "os.makedirs(DATASET_OUTPUT_MASKS_PATH)\n",
    "os.makedirs(DATASET_OUTPUT_CHECKS_PATH)\n",
    "\n",
    "#! Régénérer les tuiles dans tile_1024_split depuis les geotiff de 1.4Gb de SITG. Environ 1h\n",
    "#! Utiles si jamais les tuiles de 1024 sont corrompues ou effacées par erreur\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG = False\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_PROCESSES = 2\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_THREADS = 2\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG_COMBINED_METADATA_PARQUET = \"data/notebook_04/geotiff/tile_1024_split_old_20250519-120028/combined_metadata.parquet\"\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TILE_1024 = \"data/notebook_04/geotiff/tile_1024_split\"\n",
    "REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TEMP_1280 = 'data/notebook_04/geotiff/tile_1280_split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régénérer tile_1024_split si problème\n",
    "\n",
    "optionnel, c'est dans le cas ou le tile_1024_split a été modifié par erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single tile\n",
    "def process_tile(row, output_dir, debug_dir):\n",
    "    try:\n",
    "        bounds_str = row['buffered_bounds']\n",
    "        if isinstance(bounds_str, str):\n",
    "            bounds_str = bounds_str.replace(' ', '')\n",
    "            bounds = tuple(float(x) for x in bounds_str.strip('()').split(','))\n",
    "        else:\n",
    "            bounds = bounds_str\n",
    "        min_x, min_y, max_x, max_y = bounds\n",
    "\n",
    "        tile_path = row['tile_path']\n",
    "        output_filename = os.path.basename(tile_path)\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        with rasterio.open(row['geotiff_path']) as src:\n",
    "            window = from_bounds(min_x, min_y, max_x, max_y, src.transform)\n",
    "            window = rasterio.windows.Window(\n",
    "                col_off=int(round(window.col_off)),\n",
    "                row_off=int(round(window.row_off)),\n",
    "                width=int(round(window.width)),\n",
    "                height=int(round(window.height))\n",
    "            )\n",
    "            # Ensure window is within image bounds\n",
    "            if (window.col_off < 0 or window.row_off < 0 or \n",
    "                window.col_off + window.width > src.width or \n",
    "                window.row_off + window.height > src.height):\n",
    "                window = window.intersection(\n",
    "                    rasterio.windows.Window(0, 0, src.width, src.height)\n",
    "                )\n",
    "            data = src.read(window=window)\n",
    "            window_transform = rasterio.windows.transform(window, src.transform)\n",
    "            profile = src.profile.copy()\n",
    "            profile.update({\n",
    "                'height': window.height,\n",
    "                'width': window.width,\n",
    "                'transform': window_transform,\n",
    "                'crs': CORRECT_CRS,\n",
    "                'driver': 'GTiff',\n",
    "                'compress': None,\n",
    "                'predictor': 1,\n",
    "                'tiled': False,\n",
    "                'interleave': 'band',\n",
    "                'bigtiff': True,\n",
    "                'dtype': src.dtypes[0],\n",
    "            })\n",
    "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                dst.write(data)\n",
    "        return (row.name, True, None)\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return (row.name, False, f\"Error: {str(e)}\\n{tb}\")\n",
    "\n",
    "# Copy a single file\n",
    "def copy_file(args):\n",
    "    src_file, dst_file = args\n",
    "    try:\n",
    "        shutil.copy2(src_file, dst_file)\n",
    "        return (True, src_file)\n",
    "    except Exception as e:\n",
    "        return (False, f\"Error copying {src_file} to {dst_file}: {str(e)}\")\n",
    "\n",
    "# Process a group of tiles\n",
    "def process_geotiffs(chunk_df, output_dir, debug_dir):\n",
    "    results = []\n",
    "    for idx, row in chunk_df.iterrows():\n",
    "        result = process_tile(row, output_dir, debug_dir)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "if REGENERATE_TILE_1024_SPLIT_FROM_SITG:\n",
    "    warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    df = pd.read_parquet(REGENERATE_TILE_1024_SPLIT_FROM_SITG_COMBINED_METADATA_PARQUET)\n",
    "    os.makedirs(REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TEMP_1280, exist_ok=True)\n",
    "    debug_dir = os.path.join(REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TEMP_1280, 'debug')\n",
    "    os.makedirs(debug_dir, exist_ok=True)\n",
    "\n",
    "    # Group by source file\n",
    "    grouped = df.groupby('geotiff_path')\n",
    "    group_dfs = [group for _, group in grouped]\n",
    "\n",
    "    print(f\"Processing {len(df)} tiles from {len(group_dfs)} source GeoTIFFs using {REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_PROCESSES} processes\")\n",
    "\n",
    "    # Parallel processing\n",
    "    with ProcessPoolExecutor(max_workers=REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_PROCESSES) as executor:\n",
    "        futures = [executor.submit(process_geotiffs, group_df, REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TEMP_1280, debug_dir) \n",
    "                  for group_df in group_dfs]\n",
    "        all_results = []\n",
    "        for future in tqdm(futures, total=len(futures), desc=\"Processing GeoTIFF groups\"):\n",
    "            results = future.result()\n",
    "            all_results.extend(results)\n",
    "\n",
    "    # Log results\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    for idx, success, error_msg in all_results:\n",
    "        if success:\n",
    "            success_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "            error_info_path = os.path.join(debug_dir, f\"error_row_{idx}.txt\")\n",
    "            with open(error_info_path, 'w') as f:\n",
    "                f.write(error_msg)\n",
    "    print(f\"Tile processing complete: {success_count} successful, {error_count} errors\")\n",
    "\n",
    "    src_dir = REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TILE_1024\n",
    "    dst_dir = REGENERATE_TILE_1024_SPLIT_FROM_SITG_OUTPUT_DIR_TEMP_1280\n",
    "\n",
    "    processed_tif_files = set(os.path.basename(row['tile_path']) for _, row in df.iterrows())\n",
    "\n",
    "    files_to_copy = []\n",
    "    print(\"\\nScanning directory structure...\")\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        rel_path = os.path.relpath(root, src_dir)\n",
    "        if rel_path != '.':\n",
    "            dst_root = os.path.join(dst_dir, rel_path)\n",
    "            os.makedirs(dst_root, exist_ok=True)\n",
    "            print(f\"Created directory: {rel_path}\")\n",
    "        for file in files:\n",
    "            if rel_path == '.' and file.endswith('.tif') and file in processed_tif_files:\n",
    "                continue\n",
    "            src_file = os.path.join(root, file)\n",
    "            dst_file = os.path.join(dst_dir, rel_path, file) if rel_path != '.' else os.path.join(dst_dir, file)\n",
    "            files_to_copy.append((src_file, dst_file))\n",
    "\n",
    "    # Parallel file copy\n",
    "    print(f\"\\nCopying {len(files_to_copy)} additional files using {REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_THREADS} threads...\")\n",
    "    with ThreadPoolExecutor(max_workers=REGENERATE_TILE_1024_SPLIT_FROM_SITG_NUM_THREADS) as executor:\n",
    "        results = list(tqdm(executor.map(copy_file, files_to_copy), total=len(files_to_copy), desc=\"Copying files\"))\n",
    "\n",
    "    # Check copy errors\n",
    "    copy_errors = [result for result in results if not result[0]]\n",
    "    if copy_errors:\n",
    "        print(f\"Warning: {len(copy_errors)} files failed to copy:\")\n",
    "        for _, error in copy_errors[:10]:\n",
    "            print(f\"  {error}\")\n",
    "        if len(copy_errors) > 10:\n",
    "            print(f\"  ... and {len(copy_errors) - 10} more errors\")\n",
    "\n",
    "    # File count verification\n",
    "    def count_files(directory):\n",
    "        count = 0\n",
    "        for root, _, files in os.walk(directory):\n",
    "            count += len(files)\n",
    "        return count\n",
    "\n",
    "    old_count = count_files(src_dir)\n",
    "    new_count = count_files(dst_dir)\n",
    "\n",
    "    print(f\"\\nTotal files in old directory (including subdirectories): {old_count}\")\n",
    "    print(f\"Total files in new directory (including subdirectories): {new_count}\")\n",
    "\n",
    "    expected_diff = len(processed_tif_files)\n",
    "    actual_diff = new_count - old_count + expected_diff\n",
    "\n",
    "    print(f\"Expected difference (replaced TIF files): {expected_diff}\")\n",
    "    print(f\"Actual difference: {actual_diff}\")\n",
    "\n",
    "    if actual_diff != 0:\n",
    "        print(\"WARNING: File count doesn't match expectations!\")\n",
    "        proceed = input(\"Do you want to proceed with the renaming? (y/n): \")\n",
    "        if proceed.lower() != 'y':\n",
    "            print(\"Operation aborted\")\n",
    "            exit()\n",
    "\n",
    "    # Rename old and new folders\n",
    "    todaysdate = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    old_folder_new_name = \"data/notebook_04/geotiff/tile_1024_split_old_\" + str(todaysdate)\n",
    "    print(f\"\\nRenaming old folder '{src_dir}' to '{old_folder_new_name}'\")\n",
    "    os.rename(src_dir, old_folder_new_name)\n",
    "    print(f\"Renaming new folder '{dst_dir}' to '{src_dir}'\")\n",
    "    os.rename(dst_dir, src_dir)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset avant annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dataset = gpd.read_file(DATASET_TILES_INFORMATION_CSV_PATH)\n",
    "if \"geometry\" in gdf_dataset.columns:\n",
    "    gdf_dataset = gdf_dataset.drop(columns=[\"geometry\"])\n",
    "if \"geometry_x\" in gdf_dataset.columns:\n",
    "    gdf_dataset = gdf_dataset.drop(columns=[\"geometry_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "globalid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sia_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "altitude_min",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "altitude_max",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_leve",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tile_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tile_bounds",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SHAPE__Area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dominant_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "area_bin",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b0dd9284-1c24-45a8-ac04-40dfe7f5a16c",
       "rows": [
        [
         "0",
         "10_12_8d26a8",
         "['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE74ACC-AAE5-4961-9D58-5BE9FE4C9FE8', '807677B7-4C11-4DA0-9B8E-B55BE8086FE3', 'A1EB1C87-F247-4AB7-9FEE-EC189701624C', '099977CB-3896-4165-9471-07C803BBD4E2', '101F4AEA-BC90-45F9-8B1D-966872C25E42', 'BE1BAF3B-524C-4EC5-BBAA-DEA640D8B21D', '88AF053A-88D8-46E9-B848-F9380DF10B56', 'CBAA1C7C-5F51-4447-B1B5-1620F557F3E9', 'D873B97C-7160-43FF-932D-EDC28CB5AACE', '567FE7D7-49FB-4E3C-86AB-A431405D73BD', '6ADBB429-7D27-4471-9D9C-6B64B9C1F1A7', 'F28223BA-6007-4390-9488-5163B9CCF6D4', '10EB7F7C-B869-49AE-A2B1-2D0AA18BD081', 'B772E54A-CDF5-408A-A8D7-3FCFC1010266', '574A3217-6D6A-49C8-A8DC-7DDE33B3D397', '51ED77F9-4492-4599-9CD6-9B5D24413666', '3F373343-4083-4DA1-BF05-6CF6B4DD0CC4', '25ED7F1D-8087-4240-9855-7190919E216A', '266B9FF3-7018-431A-9F4C-8EA72091F3A5', '2E0285AC-F117-47CB-B2CC-5EBAD3C1BB83', 'F25EE555-2929-400E-9572-714EA08A030F', '98FDD560-3974-48F1-812D-31925B183D80', '2C10A45E-EDF1-4D25-8D7E-4FCDF0A25E3D', '89EE94BF-2108-4005-96DD-A1562FFA0812', '2290CE78-E68D-4DDB-BDD5-6B96C4B052D8', 'E05B0BB1-6714-47A8-BA0C-DEA7A4C597B3', '3415A63F-3D24-433E-A214-4FCE93B60CEE', '511D83F3-B580-4084-8BB4-776839C3D354', '8651415D-4757-4F19-B87E-2505E2A42739', '457CF140-3A2E-4F1E-AE45-5B86335ED0E0', '89A6F8B4-686E-42F5-85DA-158C63FDDB3D', '798FB3A2-1809-4158-BA3A-F8242EA0A926', 'A779921A-812B-4541-9458-A0A7FBA16073', 'F6F6E635-8183-48A7-9252-C8850961DEE2', '3471849E-E979-45AB-ABFB-512D3398AC4A', '97B5BC83-0319-48E6-8138-F34B87AC5284', 'F58D35C8-18EC-4E10-87E9-C226FB7A01ED', 'C4B16477-05B9-48F0-88D9-3867756358DE']",
         "['I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif']",
         "489.9533333333333",
         "490.24435897435893",
         "2009-06-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25031119_tile_10_12_8d26a8.tif",
         "(2503614.4, 1119436.8, 2503665.6, 1119488.0)",
         "199.54863144098917",
         "I habitat collectif",
         "0-200"
        ],
        [
         "1",
         "0_6_9201e5",
         "['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14DFD8-8F0A-48FC-BB7D-38B9996C9E57']",
         "['I habitat collectif', 'IX industrie']",
         "400.53",
         "400.53",
         "2019-06-08 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25051123_tile_0_6_9201e5.tif",
         "(2505307.2, 1123948.8, 2505358.4, 1124000.0)",
         "179.86172888887035",
         "I habitat collectif",
         "0-200"
        ],
        [
         "2",
         "18_4_b35ef3",
         "['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF365229-7BD4-42BA-9DAD-DDF74BCBA3B2', 'FC536C31-B8FE-4D0B-9624-7B86B9899C96']",
         "['I habitat collectif', 'I habitat collectif', 'I habitat collectif']",
         "449.93333333333334",
         "451.15000000000003",
         "2005-08-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25081121_tile_18_4_b35ef3.tif",
         "(2508204.8, 1121027.2, 2508256.0, 1121078.4)",
         "53.2306893459604",
         "I habitat collectif",
         "0-200"
        ],
        [
         "3",
         "1_3_14c592",
         "['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67ACD29-3572-4541-B352-7E858774F167', 'B98AD647-0F92-4B84-90BE-F872D383302E', '0CD45588-2EEB-48ED-AE34-7D5C40A4122A']",
         "['I habitat collectif', 'II habitat individuel', 'I habitat collectif', 'II habitat individuel']",
         "428.7775",
         "429.1725",
         "2016-03-01 01:00:00",
         "data/notebook_04/geotiff/tile_1024_split/24991113_tile_1_3_14c592.tif",
         "(2499153.6, 1113897.6, 2499204.8, 1113948.8)",
         "123.19650865057967",
         "I habitat collectif",
         "0-200"
        ],
        [
         "4",
         "15_17_5212bb",
         "['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']",
         "['I habitat collectif']",
         "441.73",
         "441.73",
         "2005-08-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/24971118_tile_15_17_5212bb.tif",
         "(2497870.4, 1118180.8, 2497921.6, 1118232.0)",
         "149.40822829361062",
         "I habitat collectif",
         "0-200"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>globalid</th>\n",
       "      <th>sia_cat</th>\n",
       "      <th>altitude_min</th>\n",
       "      <th>altitude_max</th>\n",
       "      <th>date_leve</th>\n",
       "      <th>tile_path</th>\n",
       "      <th>tile_bounds</th>\n",
       "      <th>SHAPE__Area</th>\n",
       "      <th>dominant_class</th>\n",
       "      <th>area_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_12_8d26a8</td>\n",
       "      <td>['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>489.9533333333333</td>\n",
       "      <td>490.24435897435893</td>\n",
       "      <td>2009-06-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25031...</td>\n",
       "      <td>(2503614.4, 1119436.8, 2503665.6, 1119488.0)</td>\n",
       "      <td>199.54863144098917</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_6_9201e5</td>\n",
       "      <td>['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...</td>\n",
       "      <td>['I habitat collectif', 'IX industrie']</td>\n",
       "      <td>400.53</td>\n",
       "      <td>400.53</td>\n",
       "      <td>2019-06-08 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25051...</td>\n",
       "      <td>(2505307.2, 1123948.8, 2505358.4, 1124000.0)</td>\n",
       "      <td>179.86172888887035</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_4_b35ef3</td>\n",
       "      <td>['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>449.93333333333334</td>\n",
       "      <td>451.15000000000003</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25081...</td>\n",
       "      <td>(2508204.8, 1121027.2, 2508256.0, 1121078.4)</td>\n",
       "      <td>53.2306893459604</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3_14c592</td>\n",
       "      <td>['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...</td>\n",
       "      <td>['I habitat collectif', 'II habitat individuel...</td>\n",
       "      <td>428.7775</td>\n",
       "      <td>429.1725</td>\n",
       "      <td>2016-03-01 01:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24991...</td>\n",
       "      <td>(2499153.6, 1113897.6, 2499204.8, 1113948.8)</td>\n",
       "      <td>123.19650865057967</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_17_5212bb</td>\n",
       "      <td>['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']</td>\n",
       "      <td>['I habitat collectif']</td>\n",
       "      <td>441.73</td>\n",
       "      <td>441.73</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24971...</td>\n",
       "      <td>(2497870.4, 1118180.8, 2497921.6, 1118232.0)</td>\n",
       "      <td>149.40822829361062</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id                                           globalid  \\\n",
       "0  10_12_8d26a8  ['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...   \n",
       "1    0_6_9201e5  ['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...   \n",
       "2   18_4_b35ef3  ['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...   \n",
       "3    1_3_14c592  ['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...   \n",
       "4  15_17_5212bb           ['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']   \n",
       "\n",
       "                                             sia_cat        altitude_min  \\\n",
       "0  ['I habitat collectif', 'I habitat collectif',...   489.9533333333333   \n",
       "1            ['I habitat collectif', 'IX industrie']              400.53   \n",
       "2  ['I habitat collectif', 'I habitat collectif',...  449.93333333333334   \n",
       "3  ['I habitat collectif', 'II habitat individuel...            428.7775   \n",
       "4                            ['I habitat collectif']              441.73   \n",
       "\n",
       "         altitude_max            date_leve  \\\n",
       "0  490.24435897435893  2009-06-01 02:00:00   \n",
       "1              400.53  2019-06-08 02:00:00   \n",
       "2  451.15000000000003  2005-08-01 02:00:00   \n",
       "3            429.1725  2016-03-01 01:00:00   \n",
       "4              441.73  2005-08-01 02:00:00   \n",
       "\n",
       "                                           tile_path  \\\n",
       "0  data/notebook_04/geotiff/tile_1024_split/25031...   \n",
       "1  data/notebook_04/geotiff/tile_1024_split/25051...   \n",
       "2  data/notebook_04/geotiff/tile_1024_split/25081...   \n",
       "3  data/notebook_04/geotiff/tile_1024_split/24991...   \n",
       "4  data/notebook_04/geotiff/tile_1024_split/24971...   \n",
       "\n",
       "                                    tile_bounds         SHAPE__Area  \\\n",
       "0  (2503614.4, 1119436.8, 2503665.6, 1119488.0)  199.54863144098917   \n",
       "1  (2505307.2, 1123948.8, 2505358.4, 1124000.0)  179.86172888887035   \n",
       "2  (2508204.8, 1121027.2, 2508256.0, 1121078.4)    53.2306893459604   \n",
       "3  (2499153.6, 1113897.6, 2499204.8, 1113948.8)  123.19650865057967   \n",
       "4  (2497870.4, 1118180.8, 2497921.6, 1118232.0)  149.40822829361062   \n",
       "\n",
       "        dominant_class area_bin  \n",
       "0  I habitat collectif    0-200  \n",
       "1  I habitat collectif    0-200  \n",
       "2  I habitat collectif    0-200  \n",
       "3  I habitat collectif    0-200  \n",
       "4  I habitat collectif    0-200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(gdf_dataset))\n",
    "gdf_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no duplicate in gdf_dataset[\"tile_id\"]\n",
    "assert(len(gdf_dataset[gdf_dataset.duplicated(subset=[\"tile_id\"])]) == 0), f\"gdf_dataset has duplicates in tile_id: {gdf_dataset[gdf_dataset.duplicated(subset=['tile_id'])]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset annoté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_masks_path: datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img\n",
      "Number of files: 539\n",
      "dataset_masks_path: datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine\n",
      "Number of files: 539\n"
     ]
    }
   ],
   "source": [
    "# img\n",
    "dataset_img_path = os.path.join(DATASET_ANNOTATED_BRUT_PATH, [f for f in os.listdir(DATASET_ANNOTATED_BRUT_PATH) if f.startswith(\"dataset\")][0], \"img\")\n",
    "assert(os.path.exists(dataset_img_path)), f\"Path does not exist: {dataset_img_path}\"\n",
    "print(f\"dataset_masks_path: {dataset_img_path}\")\n",
    "print(f\"Number of files: {len(os.listdir(dataset_img_path))}\")\n",
    "\n",
    "\n",
    "# masks\n",
    "dataset_masks_path = os.path.join(DATASET_ANNOTATED_BRUT_PATH, [f for f in os.listdir(DATASET_ANNOTATED_BRUT_PATH) if f.startswith(\"dataset\")][0], \"masks_machine\")\n",
    "assert(os.path.exists(dataset_masks_path)), f\"Path does not exist: {dataset_masks_path}\"\n",
    "print(f\"dataset_masks_path: {dataset_masks_path}\")\n",
    "print(f\"Number of files: {len(os.listdir(dataset_masks_path))}\")\n",
    "\n",
    "# verif\n",
    "assert(len(os.listdir(dataset_img_path)) == len(os.listdir(dataset_masks_path))), f\"Number of files in {dataset_masks_path} is not equal to number of files in {dataset_masks_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_mask_path_png",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_img_path_png",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "aaa41539-922c-4a56-aed1-21411d7d3a01",
       "rows": [
        [
         "0",
         "3_10_d297df",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24861111_tile_3_10_d297df.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24861111_tile_3_10_d297df.png"
        ],
        [
         "1",
         "19_8_067ade",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24861112_tile_19_8_067ade.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24861112_tile_19_8_067ade.png"
        ],
        [
         "2",
         "4_9_e48187",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24871112_tile_4_9_e48187.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24871112_tile_4_9_e48187.png"
        ],
        [
         "3",
         "5_9_4ffdcf",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24871112_tile_5_9_4ffdcf.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24871112_tile_5_9_4ffdcf.png"
        ],
        [
         "4",
         "10_6_eecedc",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24881112_tile_10_6_eecedc.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24881112_tile_10_6_eecedc.png"
        ],
        [
         "5",
         "0_11_3c4488",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24881116_tile_0_11_3c4488.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24881116_tile_0_11_3c4488.png"
        ],
        [
         "6",
         "8_6_13be2f",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24881118_tile_8_6_13be2f.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24881118_tile_8_6_13be2f.png"
        ],
        [
         "7",
         "15_10_cc2aa7",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891111_tile_15_10_cc2aa7.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891111_tile_15_10_cc2aa7.png"
        ],
        [
         "8",
         "10_2_fc2625",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891112_tile_10_2_fc2625.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891112_tile_10_2_fc2625.png"
        ],
        [
         "9",
         "9_4_7894d0",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891112_tile_9_4_7894d0.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891112_tile_9_4_7894d0.png"
        ],
        [
         "10",
         "3_1_8d3072",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891113_tile_3_1_8d3072.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891113_tile_3_1_8d3072.png"
        ],
        [
         "11",
         "3_4_ba1938",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891114_tile_3_4_ba1938.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891114_tile_3_4_ba1938.png"
        ],
        [
         "12",
         "16_2_2d7981",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891118_tile_16_2_2d7981.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891118_tile_16_2_2d7981.png"
        ],
        [
         "13",
         "17_3_95b4ae",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24891118_tile_17_3_95b4ae.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24891118_tile_17_3_95b4ae.png"
        ],
        [
         "14",
         "7_6_e34429",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24901114_tile_7_6_e34429.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24901114_tile_7_6_e34429.png"
        ],
        [
         "15",
         "6_4_ce9259",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24901116_tile_6_4_ce9259.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24901116_tile_6_4_ce9259.png"
        ],
        [
         "16",
         "2_2_42645e",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24901118_tile_2_2_42645e.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24901118_tile_2_2_42645e.png"
        ],
        [
         "17",
         "0_19_c476a4",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911110_tile_0_19_c476a4.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911110_tile_0_19_c476a4.png"
        ],
        [
         "18",
         "15_17_94ec0c",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911111_tile_15_17_94ec0c.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911111_tile_15_17_94ec0c.png"
        ],
        [
         "19",
         "15_18_51d0db",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911111_tile_15_18_51d0db.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911111_tile_15_18_51d0db.png"
        ],
        [
         "20",
         "16_19_c8b263",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911111_tile_16_19_c8b263.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911111_tile_16_19_c8b263.png"
        ],
        [
         "21",
         "3_8_c81f3f",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911116_tile_3_8_c81f3f.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911116_tile_3_8_c81f3f.png"
        ],
        [
         "22",
         "2_17_d313cf",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911117_tile_2_17_d313cf.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911117_tile_2_17_d313cf.png"
        ],
        [
         "23",
         "0_10_ee394a",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24911118_tile_0_10_ee394a.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24911118_tile_0_10_ee394a.png"
        ],
        [
         "24",
         "12_6_265345",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24921113_tile_12_6_265345.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24921113_tile_12_6_265345.png"
        ],
        [
         "25",
         "15_11_d7f4ea",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24921115_tile_15_11_d7f4ea.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24921115_tile_15_11_d7f4ea.png"
        ],
        [
         "26",
         "18_0_dea25e",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24921119_tile_18_0_dea25e.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24921119_tile_18_0_dea25e.png"
        ],
        [
         "27",
         "4_17_b09eb4",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24921119_tile_4_17_b09eb4.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24921119_tile_4_17_b09eb4.png"
        ],
        [
         "28",
         "1_16_b88c9b",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24921120_tile_1_16_b88c9b.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24921120_tile_1_16_b88c9b.png"
        ],
        [
         "29",
         "3_1_d28ae1",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931112_tile_3_1_d28ae1.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931112_tile_3_1_d28ae1.png"
        ],
        [
         "30",
         "3_4_2c6dbf",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931112_tile_3_4_2c6dbf.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931112_tile_3_4_2c6dbf.png"
        ],
        [
         "31",
         "10_6_8c6070",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931113_tile_10_6_8c6070.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931113_tile_10_6_8c6070.png"
        ],
        [
         "32",
         "13_18_a66e08",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931113_tile_13_18_a66e08.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931113_tile_13_18_a66e08.png"
        ],
        [
         "33",
         "15_13_77013c",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931113_tile_15_13_77013c.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931113_tile_15_13_77013c.png"
        ],
        [
         "34",
         "19_19_52ccbb",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931113_tile_19_19_52ccbb.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931113_tile_19_19_52ccbb.png"
        ],
        [
         "35",
         "0_13_b41956",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931115_tile_0_13_b41956.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931115_tile_0_13_b41956.png"
        ],
        [
         "36",
         "15_11_88568b",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931117_tile_15_11_88568b.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931117_tile_15_11_88568b.png"
        ],
        [
         "37",
         "16_12_db0d21",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931117_tile_16_12_db0d21.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931117_tile_16_12_db0d21.png"
        ],
        [
         "38",
         "18_5_f475a0",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931117_tile_18_5_f475a0.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931117_tile_18_5_f475a0.png"
        ],
        [
         "39",
         "19_5_22e308",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931117_tile_19_5_22e308.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931117_tile_19_5_22e308.png"
        ],
        [
         "40",
         "10_16_dc45c0",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_10_16_dc45c0.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_10_16_dc45c0.png"
        ],
        [
         "41",
         "13_14_47b1f2",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_13_14_47b1f2.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_13_14_47b1f2.png"
        ],
        [
         "42",
         "13_15_c8052d",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_13_15_c8052d.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_13_15_c8052d.png"
        ],
        [
         "43",
         "13_17_fc1418",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_13_17_fc1418.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_13_17_fc1418.png"
        ],
        [
         "44",
         "17_0_027bcc",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_17_0_027bcc.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_17_0_027bcc.png"
        ],
        [
         "45",
         "2_2_5dfcfa",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_2_2_5dfcfa.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_2_2_5dfcfa.png"
        ],
        [
         "46",
         "6_17_256755",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_6_17_256755.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_6_17_256755.png"
        ],
        [
         "47",
         "7_8_cf7375",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_7_8_cf7375.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_7_8_cf7375.png"
        ],
        [
         "48",
         "9_16_637cf7",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931119_tile_9_16_637cf7.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931119_tile_9_16_637cf7.png"
        ],
        [
         "49",
         "10_16_604952",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24931120_tile_10_16_604952.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24931120_tile_10_16_604952.png"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 539
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>original_mask_path_png</th>\n",
       "      <th>original_img_path_png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_10_d297df</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19_8_067ade</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_9_e48187</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_9_4ffdcf</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_6_eecedc</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>10_1_e9591b</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>11_18_ac7623</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>16_8_46ad78</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>10_13_55bd29</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0_11_a3fb96</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tile_id                             original_mask_path_png  \\\n",
       "0     3_10_d297df  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1     19_8_067ade  datasets/supervisely/341575_free_space_rooftop...   \n",
       "2      4_9_e48187  datasets/supervisely/341575_free_space_rooftop...   \n",
       "3      5_9_4ffdcf  datasets/supervisely/341575_free_space_rooftop...   \n",
       "4     10_6_eecedc  datasets/supervisely/341575_free_space_rooftop...   \n",
       "..            ...                                                ...   \n",
       "534   10_1_e9591b  datasets/supervisely/341575_free_space_rooftop...   \n",
       "535  11_18_ac7623  datasets/supervisely/341575_free_space_rooftop...   \n",
       "536   16_8_46ad78  datasets/supervisely/341575_free_space_rooftop...   \n",
       "537  10_13_55bd29  datasets/supervisely/341575_free_space_rooftop...   \n",
       "538   0_11_a3fb96  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                                 original_img_path_png  \n",
       "0    datasets/supervisely/341575_free_space_rooftop...  \n",
       "1    datasets/supervisely/341575_free_space_rooftop...  \n",
       "2    datasets/supervisely/341575_free_space_rooftop...  \n",
       "3    datasets/supervisely/341575_free_space_rooftop...  \n",
       "4    datasets/supervisely/341575_free_space_rooftop...  \n",
       "..                                                 ...  \n",
       "534  datasets/supervisely/341575_free_space_rooftop...  \n",
       "535  datasets/supervisely/341575_free_space_rooftop...  \n",
       "536  datasets/supervisely/341575_free_space_rooftop...  \n",
       "537  datasets/supervisely/341575_free_space_rooftop...  \n",
       "538  datasets/supervisely/341575_free_space_rooftop...  \n",
       "\n",
       "[539 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build lists of mask and image file paths\n",
    "dataset_original_masks_path_list = [os.path.join(dataset_masks_path, f) for f in os.listdir(dataset_masks_path)]\n",
    "dataset_original_img_path_list = [os.path.join(dataset_img_path, f) for f in os.listdir(dataset_img_path)]\n",
    "\n",
    "# Create annotation dataframe\n",
    "df_annotations = pd.DataFrame(\n",
    "    {\n",
    "        \"tile_id\": [os.path.basename(f).split(\".\")[0] for f in dataset_original_masks_path_list],\n",
    "        \"original_mask_path_png\": dataset_original_masks_path_list,\n",
    "        \"original_img_path_png\": dataset_original_img_path_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Extract tile_id suffix after second underscore\n",
    "df_annotations[\"tile_id\"] = df_annotations[\"tile_id\"].apply(lambda x: \"_\".join(x.split(\"_\")[2:]))\n",
    "\n",
    "# Check for duplicates\n",
    "assert(len(df_annotations[df_annotations.duplicated(subset=[\"tile_id\"])]) == 0), f\"gdf_dataset has duplicates in tile_id: {df_annotations[df_annotations.duplicated(subset=['tile_id'])]}\"\n",
    "assert(len(df_annotations[df_annotations.duplicated(subset=[\"original_mask_path_png\"])]) == 0), f\"gdf_dataset has duplicates in original_mask_path_png: {df_annotations[df_annotations.duplicated(subset=['original_mask_path_png'])]}\"\n",
    "assert(len(df_annotations[df_annotations.duplicated(subset=[\"original_img_path_png\"])]) == 0), f\"gdf_dataset has duplicates in original_img_path_png: {df_annotations[df_annotations.duplicated(subset=['original_img_path_png'])]}\"\n",
    "\n",
    "# Check for missing values\n",
    "assert(df_annotations[\"tile_id\"].notnull().all()), f\"df_annotations has null values in tile_id: {df_annotations[df_annotations['tile_id'].isnull()]}\"\n",
    "assert(df_annotations[\"original_mask_path_png\"].notnull().all()), f\"df_annotations has null values in original_mask_path_png: {df_annotations[df_annotations['original_mask_path_png'].isnull()]}\"\n",
    "assert(df_annotations[\"original_img_path_png\"].notnull().all()), f\"df_annotations has null values in original_img_path_png: {df_annotations[df_annotations['original_img_path_png'].isnull()]}\"\n",
    "\n",
    "# Check row count consistency\n",
    "assert(len(df_annotations[\"tile_id\"]) == len(gdf_dataset[\"tile_id\"])), f\"len(df_annotations['tile_id']) is not equal to len(gdf_dataset['tile_id']): {len(df_annotations['tile_id'])} != {len(gdf_dataset['tile_id'])}\"\n",
    "\n",
    "display(df_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dataset = gdf_dataset.merge(\n",
    "    df_annotations,\n",
    "    how=\"left\",\n",
    "    left_on=\"tile_id\",\n",
    "    right_on=\"tile_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "assert(len(gdf_dataset[gdf_dataset.duplicated(subset=[\"tile_id\"])]) == 0), f\"gdf_dataset has duplicates in tile_id: {gdf_dataset[gdf_dataset.duplicated(subset=['tile_id'])]}\"\n",
    "assert(len(gdf_dataset[gdf_dataset.duplicated(subset=[\"original_img_path_png\"])]) == 0), f\"gdf_dataset has duplicates in img_path: {gdf_dataset[gdf_dataset.duplicated(subset=['original_img_path_png'])]}\"\n",
    "assert(len(gdf_dataset[gdf_dataset.duplicated(subset=[\"original_mask_path_png\"])]) == 0), f\"gdf_dataset has duplicates in original_mask_path_png: {gdf_dataset[gdf_dataset.duplicated(subset=['original_mask_path_png'])]}\"\n",
    "\n",
    "# Check for missing values\n",
    "assert(gdf_dataset[\"tile_id\"].notnull().all()), f\"gdf_dataset has null values in tile_id: {gdf_dataset[gdf_dataset['tile_id'].isnull()]}\"\n",
    "assert(gdf_dataset[\"original_img_path_png\"].notnull().all()), f\"gdf_dataset has null values in original_img_path_png: {gdf_dataset[gdf_dataset['original_img_path_png'].isnull()]}\"\n",
    "assert(gdf_dataset[\"original_mask_path_png\"].notnull().all()), f\"gdf_dataset has null values in original_mask_path_png: {gdf_dataset[gdf_dataset['original_mask_path_png'].isnull()]}\"\n",
    "\n",
    "# Check row count consistency\n",
    "assert(len(gdf_dataset[\"tile_id\"]) == len(df_annotations[\"tile_id\"])), f\"len(gdf_dataset['tile_id']) is not equal to len(df_annotations['tile_id']): {len(gdf_dataset['tile_id'])} != {len(df_annotations['tile_id'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "globalid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sia_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "altitude_min",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "altitude_max",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_leve",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tile_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tile_bounds",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SHAPE__Area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dominant_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "area_bin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_mask_path_png",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_img_path_png",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "18c4b402-21f7-490b-a8a7-f70a4c7f2431",
       "rows": [
        [
         "0",
         "10_12_8d26a8",
         "['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE74ACC-AAE5-4961-9D58-5BE9FE4C9FE8', '807677B7-4C11-4DA0-9B8E-B55BE8086FE3', 'A1EB1C87-F247-4AB7-9FEE-EC189701624C', '099977CB-3896-4165-9471-07C803BBD4E2', '101F4AEA-BC90-45F9-8B1D-966872C25E42', 'BE1BAF3B-524C-4EC5-BBAA-DEA640D8B21D', '88AF053A-88D8-46E9-B848-F9380DF10B56', 'CBAA1C7C-5F51-4447-B1B5-1620F557F3E9', 'D873B97C-7160-43FF-932D-EDC28CB5AACE', '567FE7D7-49FB-4E3C-86AB-A431405D73BD', '6ADBB429-7D27-4471-9D9C-6B64B9C1F1A7', 'F28223BA-6007-4390-9488-5163B9CCF6D4', '10EB7F7C-B869-49AE-A2B1-2D0AA18BD081', 'B772E54A-CDF5-408A-A8D7-3FCFC1010266', '574A3217-6D6A-49C8-A8DC-7DDE33B3D397', '51ED77F9-4492-4599-9CD6-9B5D24413666', '3F373343-4083-4DA1-BF05-6CF6B4DD0CC4', '25ED7F1D-8087-4240-9855-7190919E216A', '266B9FF3-7018-431A-9F4C-8EA72091F3A5', '2E0285AC-F117-47CB-B2CC-5EBAD3C1BB83', 'F25EE555-2929-400E-9572-714EA08A030F', '98FDD560-3974-48F1-812D-31925B183D80', '2C10A45E-EDF1-4D25-8D7E-4FCDF0A25E3D', '89EE94BF-2108-4005-96DD-A1562FFA0812', '2290CE78-E68D-4DDB-BDD5-6B96C4B052D8', 'E05B0BB1-6714-47A8-BA0C-DEA7A4C597B3', '3415A63F-3D24-433E-A214-4FCE93B60CEE', '511D83F3-B580-4084-8BB4-776839C3D354', '8651415D-4757-4F19-B87E-2505E2A42739', '457CF140-3A2E-4F1E-AE45-5B86335ED0E0', '89A6F8B4-686E-42F5-85DA-158C63FDDB3D', '798FB3A2-1809-4158-BA3A-F8242EA0A926', 'A779921A-812B-4541-9458-A0A7FBA16073', 'F6F6E635-8183-48A7-9252-C8850961DEE2', '3471849E-E979-45AB-ABFB-512D3398AC4A', '97B5BC83-0319-48E6-8138-F34B87AC5284', 'F58D35C8-18EC-4E10-87E9-C226FB7A01ED', 'C4B16477-05B9-48F0-88D9-3867756358DE']",
         "['I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif', 'I habitat collectif']",
         "489.9533333333333",
         "490.24435897435893",
         "2009-06-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25031119_tile_10_12_8d26a8.tif",
         "(2503614.4, 1119436.8, 2503665.6, 1119488.0)",
         "199.54863144098917",
         "I habitat collectif",
         "0-200",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/25031119_tile_10_12_8d26a8.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/25031119_tile_10_12_8d26a8.png"
        ],
        [
         "1",
         "0_6_9201e5",
         "['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14DFD8-8F0A-48FC-BB7D-38B9996C9E57']",
         "['I habitat collectif', 'IX industrie']",
         "400.53",
         "400.53",
         "2019-06-08 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25051123_tile_0_6_9201e5.tif",
         "(2505307.2, 1123948.8, 2505358.4, 1124000.0)",
         "179.86172888887035",
         "I habitat collectif",
         "0-200",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/25051123_tile_0_6_9201e5.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/25051123_tile_0_6_9201e5.png"
        ],
        [
         "2",
         "18_4_b35ef3",
         "['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF365229-7BD4-42BA-9DAD-DDF74BCBA3B2', 'FC536C31-B8FE-4D0B-9624-7B86B9899C96']",
         "['I habitat collectif', 'I habitat collectif', 'I habitat collectif']",
         "449.93333333333334",
         "451.15000000000003",
         "2005-08-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/25081121_tile_18_4_b35ef3.tif",
         "(2508204.8, 1121027.2, 2508256.0, 1121078.4)",
         "53.2306893459604",
         "I habitat collectif",
         "0-200",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/25081121_tile_18_4_b35ef3.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/25081121_tile_18_4_b35ef3.png"
        ],
        [
         "3",
         "1_3_14c592",
         "['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67ACD29-3572-4541-B352-7E858774F167', 'B98AD647-0F92-4B84-90BE-F872D383302E', '0CD45588-2EEB-48ED-AE34-7D5C40A4122A']",
         "['I habitat collectif', 'II habitat individuel', 'I habitat collectif', 'II habitat individuel']",
         "428.7775",
         "429.1725",
         "2016-03-01 01:00:00",
         "data/notebook_04/geotiff/tile_1024_split/24991113_tile_1_3_14c592.tif",
         "(2499153.6, 1113897.6, 2499204.8, 1113948.8)",
         "123.19650865057967",
         "I habitat collectif",
         "0-200",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24991113_tile_1_3_14c592.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24991113_tile_1_3_14c592.png"
        ],
        [
         "4",
         "15_17_5212bb",
         "['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']",
         "['I habitat collectif']",
         "441.73",
         "441.73",
         "2005-08-01 02:00:00",
         "data/notebook_04/geotiff/tile_1024_split/24971118_tile_15_17_5212bb.tif",
         "(2497870.4, 1118180.8, 2497921.6, 1118232.0)",
         "149.40822829361062",
         "I habitat collectif",
         "0-200",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/masks_machine/24971118_tile_15_17_5212bb.png",
         "datasets/supervisely/341575_free_space_rooftop_geneva_20250511_binary_mask/dataset 2025-04-07 17-26-34/img/24971118_tile_15_17_5212bb.png"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>globalid</th>\n",
       "      <th>sia_cat</th>\n",
       "      <th>altitude_min</th>\n",
       "      <th>altitude_max</th>\n",
       "      <th>date_leve</th>\n",
       "      <th>tile_path</th>\n",
       "      <th>tile_bounds</th>\n",
       "      <th>SHAPE__Area</th>\n",
       "      <th>dominant_class</th>\n",
       "      <th>area_bin</th>\n",
       "      <th>original_mask_path_png</th>\n",
       "      <th>original_img_path_png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_12_8d26a8</td>\n",
       "      <td>['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>489.9533333333333</td>\n",
       "      <td>490.24435897435893</td>\n",
       "      <td>2009-06-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25031...</td>\n",
       "      <td>(2503614.4, 1119436.8, 2503665.6, 1119488.0)</td>\n",
       "      <td>199.54863144098917</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_6_9201e5</td>\n",
       "      <td>['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...</td>\n",
       "      <td>['I habitat collectif', 'IX industrie']</td>\n",
       "      <td>400.53</td>\n",
       "      <td>400.53</td>\n",
       "      <td>2019-06-08 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25051...</td>\n",
       "      <td>(2505307.2, 1123948.8, 2505358.4, 1124000.0)</td>\n",
       "      <td>179.86172888887035</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_4_b35ef3</td>\n",
       "      <td>['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>449.93333333333334</td>\n",
       "      <td>451.15000000000003</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25081...</td>\n",
       "      <td>(2508204.8, 1121027.2, 2508256.0, 1121078.4)</td>\n",
       "      <td>53.2306893459604</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3_14c592</td>\n",
       "      <td>['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...</td>\n",
       "      <td>['I habitat collectif', 'II habitat individuel...</td>\n",
       "      <td>428.7775</td>\n",
       "      <td>429.1725</td>\n",
       "      <td>2016-03-01 01:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24991...</td>\n",
       "      <td>(2499153.6, 1113897.6, 2499204.8, 1113948.8)</td>\n",
       "      <td>123.19650865057967</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_17_5212bb</td>\n",
       "      <td>['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']</td>\n",
       "      <td>['I habitat collectif']</td>\n",
       "      <td>441.73</td>\n",
       "      <td>441.73</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24971...</td>\n",
       "      <td>(2497870.4, 1118180.8, 2497921.6, 1118232.0)</td>\n",
       "      <td>149.40822829361062</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id                                           globalid  \\\n",
       "0  10_12_8d26a8  ['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...   \n",
       "1    0_6_9201e5  ['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...   \n",
       "2   18_4_b35ef3  ['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...   \n",
       "3    1_3_14c592  ['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...   \n",
       "4  15_17_5212bb           ['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']   \n",
       "\n",
       "                                             sia_cat        altitude_min  \\\n",
       "0  ['I habitat collectif', 'I habitat collectif',...   489.9533333333333   \n",
       "1            ['I habitat collectif', 'IX industrie']              400.53   \n",
       "2  ['I habitat collectif', 'I habitat collectif',...  449.93333333333334   \n",
       "3  ['I habitat collectif', 'II habitat individuel...            428.7775   \n",
       "4                            ['I habitat collectif']              441.73   \n",
       "\n",
       "         altitude_max            date_leve  \\\n",
       "0  490.24435897435893  2009-06-01 02:00:00   \n",
       "1              400.53  2019-06-08 02:00:00   \n",
       "2  451.15000000000003  2005-08-01 02:00:00   \n",
       "3            429.1725  2016-03-01 01:00:00   \n",
       "4              441.73  2005-08-01 02:00:00   \n",
       "\n",
       "                                           tile_path  \\\n",
       "0  data/notebook_04/geotiff/tile_1024_split/25031...   \n",
       "1  data/notebook_04/geotiff/tile_1024_split/25051...   \n",
       "2  data/notebook_04/geotiff/tile_1024_split/25081...   \n",
       "3  data/notebook_04/geotiff/tile_1024_split/24991...   \n",
       "4  data/notebook_04/geotiff/tile_1024_split/24971...   \n",
       "\n",
       "                                    tile_bounds         SHAPE__Area  \\\n",
       "0  (2503614.4, 1119436.8, 2503665.6, 1119488.0)  199.54863144098917   \n",
       "1  (2505307.2, 1123948.8, 2505358.4, 1124000.0)  179.86172888887035   \n",
       "2  (2508204.8, 1121027.2, 2508256.0, 1121078.4)    53.2306893459604   \n",
       "3  (2499153.6, 1113897.6, 2499204.8, 1113948.8)  123.19650865057967   \n",
       "4  (2497870.4, 1118180.8, 2497921.6, 1118232.0)  149.40822829361062   \n",
       "\n",
       "        dominant_class area_bin  \\\n",
       "0  I habitat collectif    0-200   \n",
       "1  I habitat collectif    0-200   \n",
       "2  I habitat collectif    0-200   \n",
       "3  I habitat collectif    0-200   \n",
       "4  I habitat collectif    0-200   \n",
       "\n",
       "                              original_mask_path_png  \\\n",
       "0  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1  datasets/supervisely/341575_free_space_rooftop...   \n",
       "2  datasets/supervisely/341575_free_space_rooftop...   \n",
       "3  datasets/supervisely/341575_free_space_rooftop...   \n",
       "4  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                               original_img_path_png  \n",
       "0  datasets/supervisely/341575_free_space_rooftop...  \n",
       "1  datasets/supervisely/341575_free_space_rooftop...  \n",
       "2  datasets/supervisely/341575_free_space_rooftop...  \n",
       "3  datasets/supervisely/341575_free_space_rooftop...  \n",
       "4  datasets/supervisely/341575_free_space_rooftop...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAD_BATIMENT_HORSOL_TOIT_MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>objectid</th>\n",
       "      <th>egid</th>\n",
       "      <th>altitude_min</th>\n",
       "      <th>altitude_max</th>\n",
       "      <th>date_leve</th>\n",
       "      <th>SHAPE__Length</th>\n",
       "      <th>SHAPE__Area</th>\n",
       "      <th>globalid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((2486492.692 1110581.039, 2486492.687...</td>\n",
       "      <td>48192</td>\n",
       "      <td>295076435.0</td>\n",
       "      <td>381.94</td>\n",
       "      <td>382.34</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>51.65274923353816</td>\n",
       "      <td>124.87250692348236</td>\n",
       "      <td>{C22AB52C-0F0B-4FAA-9E75-4243A665B461}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((2486457.102 1110749.186, 2486460.004...</td>\n",
       "      <td>48235</td>\n",
       "      <td>295091310.0</td>\n",
       "      <td>368.07</td>\n",
       "      <td>368.56</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>31.015893027041194</td>\n",
       "      <td>54.70481326736387</td>\n",
       "      <td>{61AB5825-8EDB-4F5C-92E3-A8F3CB3B3637}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((2486286.792 1110867.393, 2486290.749...</td>\n",
       "      <td>48204</td>\n",
       "      <td>295077439.0</td>\n",
       "      <td>339.15</td>\n",
       "      <td>339.15</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>14.954717776916645</td>\n",
       "      <td>13.691946764255684</td>\n",
       "      <td>{FF2FD4B9-EE43-4622-8B1E-F18E65820C6F}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((2486627.502 1110880.096, 2486627.462...</td>\n",
       "      <td>48225 | 48224 | 48223 | 48226 | 48129 | 48142 ...</td>\n",
       "      <td>295077673.0 | 1004238.0</td>\n",
       "      <td>360.04 | 367.89 | 367.37 | 364.7 | 367.36 | 36...</td>\n",
       "      <td>361.58 | 370.86 | 368.07 | 368.06</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>16.51163203622832 | 16.65983583426023 | 16.657...</td>\n",
       "      <td>11.7960687648941 | 11.800539859749684 | 11.793...</td>\n",
       "      <td>{4925DA6C-D32C-4D40-A376-8715F1678EED} | {81C7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((2486688.491 1111040.638, 2486700.898...</td>\n",
       "      <td>48233</td>\n",
       "      <td>295091089.0</td>\n",
       "      <td>348.75</td>\n",
       "      <td>348.75</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>38.97868110167111</td>\n",
       "      <td>87.73404090611139</td>\n",
       "      <td>{7EEE17BC-9A10-4AE7-906A-8F2021CEFB07}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  \\\n",
       "0  POLYGON ((2486492.692 1110581.039, 2486492.687...   \n",
       "1  POLYGON ((2486457.102 1110749.186, 2486460.004...   \n",
       "2  POLYGON ((2486286.792 1110867.393, 2486290.749...   \n",
       "3  POLYGON ((2486627.502 1110880.096, 2486627.462...   \n",
       "4  POLYGON ((2486688.491 1111040.638, 2486700.898...   \n",
       "\n",
       "                                            objectid                     egid  \\\n",
       "0                                              48192              295076435.0   \n",
       "1                                              48235              295091310.0   \n",
       "2                                              48204              295077439.0   \n",
       "3  48225 | 48224 | 48223 | 48226 | 48129 | 48142 ...  295077673.0 | 1004238.0   \n",
       "4                                              48233              295091089.0   \n",
       "\n",
       "                                        altitude_min  \\\n",
       "0                                             381.94   \n",
       "1                                             368.07   \n",
       "2                                             339.15   \n",
       "3  360.04 | 367.89 | 367.37 | 364.7 | 367.36 | 36...   \n",
       "4                                             348.75   \n",
       "\n",
       "                        altitude_max            date_leve  \\\n",
       "0                             382.34  2005-08-01 02:00:00   \n",
       "1                             368.56  2005-08-01 02:00:00   \n",
       "2                             339.15  2005-08-01 02:00:00   \n",
       "3  361.58 | 370.86 | 368.07 | 368.06  2005-08-01 02:00:00   \n",
       "4                             348.75  2005-08-01 02:00:00   \n",
       "\n",
       "                                       SHAPE__Length  \\\n",
       "0                                  51.65274923353816   \n",
       "1                                 31.015893027041194   \n",
       "2                                 14.954717776916645   \n",
       "3  16.51163203622832 | 16.65983583426023 | 16.657...   \n",
       "4                                  38.97868110167111   \n",
       "\n",
       "                                         SHAPE__Area  \\\n",
       "0                                 124.87250692348236   \n",
       "1                                  54.70481326736387   \n",
       "2                                 13.691946764255684   \n",
       "3  11.7960687648941 | 11.800539859749684 | 11.793...   \n",
       "4                                  87.73404090611139   \n",
       "\n",
       "                                            globalid  \n",
       "0             {C22AB52C-0F0B-4FAA-9E75-4243A665B461}  \n",
       "1             {61AB5825-8EDB-4F5C-92E3-A8F3CB3B3637}  \n",
       "2             {FF2FD4B9-EE43-4622-8B1E-F18E65820C6F}  \n",
       "3  {4925DA6C-D32C-4D40-A376-8715F1678EED} | {81C7...  \n",
       "4             {7EEE17BC-9A10-4AE7-906A-8F2021CEFB07}  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_cad_batiment_horsol = gpd.read_parquet(CAD_BATIMENT_HORSOL_TOIT_MERGE_PARQUET_PATH)\n",
    "print(type(gdf_cad_batiment_horsol))\n",
    "gdf_cad_batiment_horsol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compléter données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GeoTIFF files...\n",
      "Successfully processed 539 out of 539 files\n"
     ]
    }
   ],
   "source": [
    "# Extract polygon geometry from a GeoTIFF file\n",
    "def get_geometry_from_tiff(tiff_path, crs=CORRECT_CRS):\n",
    "    try:\n",
    "        with rasterio.open(tiff_path) as src:\n",
    "            transform = src.transform\n",
    "            height, width = src.shape\n",
    "            crs_src = src.crs\n",
    "\n",
    "            if crs_src != crs:\n",
    "                print(f\"Warning: CRS mismatch in {tiff_path}. Found {crs_src}, expected {crs}\")\n",
    "\n",
    "            minx = transform[2]\n",
    "            maxy = transform[5]\n",
    "            miny = maxy + height * transform[4]\n",
    "            maxx = minx + width * transform[0]\n",
    "\n",
    "            polygon = Polygon([\n",
    "                (minx, miny), (maxx, miny), (maxx, maxy), (minx, maxy), (minx, miny)\n",
    "            ])\n",
    "\n",
    "            if not polygon.is_valid:\n",
    "                print(f\"Warning: Invalid polygon from {tiff_path}\")\n",
    "                polygon = polygon.buffer(0)\n",
    "\n",
    "            if polygon.area <= 0:\n",
    "                print(f\"Warning: Zero-area polygon from {tiff_path}\")\n",
    "                return None\n",
    "\n",
    "            return polygon\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tiff_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get image width and height\n",
    "def get_image_dimensions(image_path):\n",
    "    try:\n",
    "        if os.path.exists(image_path):\n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                return width, height\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {image_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def create_geodataframe_from_tiffs(df):\n",
    "    \"\"\"\n",
    "    Create a GeoDataFrame from a DataFrame of GeoTIFF paths.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'tile_path' column\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame with geometry column\n",
    "    \"\"\"\n",
    "    geometries = []\n",
    "    indices = []\n",
    "    total_files = len(df)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        tiff_path = row['tile_path']\n",
    "        if os.path.exists(tiff_path):\n",
    "            geometry = get_geometry_from_tiff(tiff_path)\n",
    "            if geometry is not None:\n",
    "                geometries.append(geometry)\n",
    "                indices.append(idx)\n",
    "        else:\n",
    "            print(f\"File not found: {tiff_path}\")\n",
    "\n",
    "    print(f\"Processed {len(geometries)} of {total_files} files\")\n",
    "\n",
    "    df_processed = df.loc[indices].copy()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df_processed,\n",
    "        geometry=geometries,\n",
    "        crs=EPSG_SUISSE\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "gdf_dataset = create_geodataframe_from_tiffs(gdf_dataset)\n",
    "\n",
    "# Add image dimensions columns\n",
    "image_dimensions = gdf_dataset['tile_path'].apply(get_image_dimensions)\n",
    "gdf_dataset['image_width'], gdf_dataset['image_height'] = zip(*image_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>globalid</th>\n",
       "      <th>sia_cat</th>\n",
       "      <th>altitude_min</th>\n",
       "      <th>altitude_max</th>\n",
       "      <th>date_leve</th>\n",
       "      <th>tile_path</th>\n",
       "      <th>tile_bounds</th>\n",
       "      <th>SHAPE__Area</th>\n",
       "      <th>dominant_class</th>\n",
       "      <th>area_bin</th>\n",
       "      <th>original_mask_path_png</th>\n",
       "      <th>original_img_path_png</th>\n",
       "      <th>geometry</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_12_8d26a8</td>\n",
       "      <td>['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>489.9533333333333</td>\n",
       "      <td>490.24435897435893</td>\n",
       "      <td>2009-06-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25031...</td>\n",
       "      <td>(2503614.4, 1119436.8, 2503665.6, 1119488.0)</td>\n",
       "      <td>199.54863144098917</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2503608 1119430.4, 2503672 1119430.4...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_6_9201e5</td>\n",
       "      <td>['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...</td>\n",
       "      <td>['I habitat collectif', 'IX industrie']</td>\n",
       "      <td>400.53</td>\n",
       "      <td>400.53</td>\n",
       "      <td>2019-06-08 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25051...</td>\n",
       "      <td>(2505307.2, 1123948.8, 2505358.4, 1124000.0)</td>\n",
       "      <td>179.86172888887035</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2505300.8 1123936, 2505364.8 1123936...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_4_b35ef3</td>\n",
       "      <td>['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>449.93333333333334</td>\n",
       "      <td>451.15000000000003</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25081...</td>\n",
       "      <td>(2508204.8, 1121027.2, 2508256.0, 1121078.4)</td>\n",
       "      <td>53.2306893459604</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2508198.4 1121020.8, 2508262.4 11210...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3_14c592</td>\n",
       "      <td>['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...</td>\n",
       "      <td>['I habitat collectif', 'II habitat individuel...</td>\n",
       "      <td>428.7775</td>\n",
       "      <td>429.1725</td>\n",
       "      <td>2016-03-01 01:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24991...</td>\n",
       "      <td>(2499153.6, 1113897.6, 2499204.8, 1113948.8)</td>\n",
       "      <td>123.19650865057967</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2499147.2 1113891.2, 2499211.2 11138...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_17_5212bb</td>\n",
       "      <td>['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']</td>\n",
       "      <td>['I habitat collectif']</td>\n",
       "      <td>441.73</td>\n",
       "      <td>441.73</td>\n",
       "      <td>2005-08-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/24971...</td>\n",
       "      <td>(2497870.4, 1118180.8, 2497921.6, 1118232.0)</td>\n",
       "      <td>149.40822829361062</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2497864 1118174.4, 2497928 1118174.4...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id                                           globalid  \\\n",
       "0  10_12_8d26a8  ['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...   \n",
       "1    0_6_9201e5  ['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...   \n",
       "2   18_4_b35ef3  ['D2047155-7D5C-4CC1-844B-3B672C640CD4', 'CF36...   \n",
       "3    1_3_14c592  ['79D87CAC-FD37-4E23-8E22-A2C21CFF9CB8', 'B67A...   \n",
       "4  15_17_5212bb           ['8C0ECDB2-A52C-4264-B8F0-B6A0CF4265EC']   \n",
       "\n",
       "                                             sia_cat        altitude_min  \\\n",
       "0  ['I habitat collectif', 'I habitat collectif',...   489.9533333333333   \n",
       "1            ['I habitat collectif', 'IX industrie']              400.53   \n",
       "2  ['I habitat collectif', 'I habitat collectif',...  449.93333333333334   \n",
       "3  ['I habitat collectif', 'II habitat individuel...            428.7775   \n",
       "4                            ['I habitat collectif']              441.73   \n",
       "\n",
       "         altitude_max            date_leve  \\\n",
       "0  490.24435897435893  2009-06-01 02:00:00   \n",
       "1              400.53  2019-06-08 02:00:00   \n",
       "2  451.15000000000003  2005-08-01 02:00:00   \n",
       "3            429.1725  2016-03-01 01:00:00   \n",
       "4              441.73  2005-08-01 02:00:00   \n",
       "\n",
       "                                           tile_path  \\\n",
       "0  data/notebook_04/geotiff/tile_1024_split/25031...   \n",
       "1  data/notebook_04/geotiff/tile_1024_split/25051...   \n",
       "2  data/notebook_04/geotiff/tile_1024_split/25081...   \n",
       "3  data/notebook_04/geotiff/tile_1024_split/24991...   \n",
       "4  data/notebook_04/geotiff/tile_1024_split/24971...   \n",
       "\n",
       "                                    tile_bounds         SHAPE__Area  \\\n",
       "0  (2503614.4, 1119436.8, 2503665.6, 1119488.0)  199.54863144098917   \n",
       "1  (2505307.2, 1123948.8, 2505358.4, 1124000.0)  179.86172888887035   \n",
       "2  (2508204.8, 1121027.2, 2508256.0, 1121078.4)    53.2306893459604   \n",
       "3  (2499153.6, 1113897.6, 2499204.8, 1113948.8)  123.19650865057967   \n",
       "4  (2497870.4, 1118180.8, 2497921.6, 1118232.0)  149.40822829361062   \n",
       "\n",
       "        dominant_class area_bin  \\\n",
       "0  I habitat collectif    0-200   \n",
       "1  I habitat collectif    0-200   \n",
       "2  I habitat collectif    0-200   \n",
       "3  I habitat collectif    0-200   \n",
       "4  I habitat collectif    0-200   \n",
       "\n",
       "                              original_mask_path_png  \\\n",
       "0  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1  datasets/supervisely/341575_free_space_rooftop...   \n",
       "2  datasets/supervisely/341575_free_space_rooftop...   \n",
       "3  datasets/supervisely/341575_free_space_rooftop...   \n",
       "4  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                               original_img_path_png  \\\n",
       "0  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1  datasets/supervisely/341575_free_space_rooftop...   \n",
       "2  datasets/supervisely/341575_free_space_rooftop...   \n",
       "3  datasets/supervisely/341575_free_space_rooftop...   \n",
       "4  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                                            geometry  image_width  \\\n",
       "0  POLYGON ((2503608 1119430.4, 2503672 1119430.4...         1280   \n",
       "1  POLYGON ((2505300.8 1123936, 2505364.8 1123936...         1280   \n",
       "2  POLYGON ((2508198.4 1121020.8, 2508262.4 11210...         1280   \n",
       "3  POLYGON ((2499147.2 1113891.2, 2499211.2 11138...         1280   \n",
       "4  POLYGON ((2497864 1118174.4, 2497928 1118174.4...         1280   \n",
       "\n",
       "   image_height  \n",
       "0          1280  \n",
       "1          1280  \n",
       "2          1280  \n",
       "3          1280  \n",
       "4          1280  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert there is no nan or null in gdf_dataset[\"image_width\"], gdf_dataset[\"image_height\"]\n",
    "assert(gdf_dataset[\"image_width\"].notnull().all()), f\"gdf_dataset has null values in image_width: {gdf_dataset[gdf_dataset['image_width'].isnull()]}\"\n",
    "assert(gdf_dataset[\"image_height\"].notnull().all()), f\"gdf_dataset has null values in image_height: {gdf_dataset[gdf_dataset['image_height'].isnull()]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>globalid</th>\n",
       "      <th>sia_cat</th>\n",
       "      <th>altitude_min</th>\n",
       "      <th>altitude_max</th>\n",
       "      <th>date_leve</th>\n",
       "      <th>tile_path</th>\n",
       "      <th>tile_bounds</th>\n",
       "      <th>SHAPE__Area</th>\n",
       "      <th>dominant_class</th>\n",
       "      <th>area_bin</th>\n",
       "      <th>original_mask_path_png</th>\n",
       "      <th>original_img_path_png</th>\n",
       "      <th>geometry</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_12_8d26a8</td>\n",
       "      <td>['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...</td>\n",
       "      <td>['I habitat collectif', 'I habitat collectif',...</td>\n",
       "      <td>489.9533333333333</td>\n",
       "      <td>490.24435897435893</td>\n",
       "      <td>2009-06-01 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25031...</td>\n",
       "      <td>(2503614.4, 1119436.8, 2503665.6, 1119488.0)</td>\n",
       "      <td>199.54863144098917</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2503608 1119430.4, 2503672 1119430.4...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_6_9201e5</td>\n",
       "      <td>['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...</td>\n",
       "      <td>['I habitat collectif', 'IX industrie']</td>\n",
       "      <td>400.53</td>\n",
       "      <td>400.53</td>\n",
       "      <td>2019-06-08 02:00:00</td>\n",
       "      <td>data/notebook_04/geotiff/tile_1024_split/25051...</td>\n",
       "      <td>(2505307.2, 1123948.8, 2505358.4, 1124000.0)</td>\n",
       "      <td>179.86172888887035</td>\n",
       "      <td>I habitat collectif</td>\n",
       "      <td>0-200</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>datasets/supervisely/341575_free_space_rooftop...</td>\n",
       "      <td>POLYGON ((2505300.8 1123936, 2505364.8 1123936...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id                                           globalid  \\\n",
       "0  10_12_8d26a8  ['72BC0BCB-C609-49C3-9EBB-DAEE02CBEDDD', 'FFE7...   \n",
       "1    0_6_9201e5  ['F24DC253-B282-4519-A142-07A8FFB9BE07', '4B14...   \n",
       "\n",
       "                                             sia_cat       altitude_min  \\\n",
       "0  ['I habitat collectif', 'I habitat collectif',...  489.9533333333333   \n",
       "1            ['I habitat collectif', 'IX industrie']             400.53   \n",
       "\n",
       "         altitude_max            date_leve  \\\n",
       "0  490.24435897435893  2009-06-01 02:00:00   \n",
       "1              400.53  2019-06-08 02:00:00   \n",
       "\n",
       "                                           tile_path  \\\n",
       "0  data/notebook_04/geotiff/tile_1024_split/25031...   \n",
       "1  data/notebook_04/geotiff/tile_1024_split/25051...   \n",
       "\n",
       "                                    tile_bounds         SHAPE__Area  \\\n",
       "0  (2503614.4, 1119436.8, 2503665.6, 1119488.0)  199.54863144098917   \n",
       "1  (2505307.2, 1123948.8, 2505358.4, 1124000.0)  179.86172888887035   \n",
       "\n",
       "        dominant_class area_bin  \\\n",
       "0  I habitat collectif    0-200   \n",
       "1  I habitat collectif    0-200   \n",
       "\n",
       "                              original_mask_path_png  \\\n",
       "0  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                               original_img_path_png  \\\n",
       "0  datasets/supervisely/341575_free_space_rooftop...   \n",
       "1  datasets/supervisely/341575_free_space_rooftop...   \n",
       "\n",
       "                                            geometry  image_width  \\\n",
       "0  POLYGON ((2503608 1119430.4, 2503672 1119430.4...         1280   \n",
       "1  POLYGON ((2505300.8 1123936, 2505364.8 1123936...         1280   \n",
       "\n",
       "   image_height  \n",
       "0          1280  \n",
       "1          1280  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(gdf_dataset))\n",
    "gdf_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing images dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clip geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a1d58d2d1b442f9c09cae0e7a8655a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clipping files:   0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing 539 files:\n",
      "- Successfully processed 538 GeoTIFFs\n",
      "- Successfully processed 538 masks\n",
      "- Converted 538 PNG masks to GeoTIFF format\n",
      "- Encountered 0 errors\n",
      "- Successfully processed tiles: 538\n",
      "- Skipped tiles: 1\n",
      "\n",
      "Dimension mismatch summary:\n",
      "  - Total files with dimension mismatches: 0\n",
      "Processed tile_ids: 538\n",
      "Skipped tile_ids: 1\n"
     ]
    }
   ],
   "source": [
    "def clip_geotiff_and_png_masks(gdf_dataset, gdf_buildings, output_img_dir, output_mask_dir, convert_masks_to_geotiff=True):\n",
    "    \"\"\"\n",
    "    Clips GeoTIFFs and corresponding PNG masks using building polygons.\n",
    "    Optionally converts PNG masks to GeoTIFF.\n",
    "    \n",
    "    Args:\n",
    "        gdf_dataset: GeoDataFrame with 'tile_path', 'original_mask_path_png', and 'tile_id'\n",
    "        gdf_buildings: GeoDataFrame with building polygons\n",
    "        output_img_dir: Output directory for clipped GeoTIFFs\n",
    "        output_mask_dir: Output directory for clipped masks\n",
    "        convert_masks_to_geotiff: Convert PNG masks to GeoTIFF if True\n",
    "        \n",
    "    Returns:\n",
    "        list: Processed tile_ids\n",
    "        dict: Skipped tile_ids with reasons\n",
    "    \"\"\"\n",
    "    successful_img_count = 0\n",
    "    successful_mask_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    processed_tile_ids = []\n",
    "    skipped_tile_ids = []\n",
    "    skipped_reasons = {}\n",
    "\n",
    "    for idx, row in tqdm(gdf_dataset.iterrows(), total=len(gdf_dataset), desc=\"Clipping files\"):\n",
    "        tiff_path = row['tile_path']\n",
    "        mask_path = row.get('original_mask_path_png')\n",
    "        tile_id = row['tile_id']\n",
    "\n",
    "        if pd.isna(tiff_path):\n",
    "            skipped_tile_ids.append(tile_id)\n",
    "            skipped_reasons[tile_id] = \"Missing tiff_path\"\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(tiff_path):\n",
    "            skipped_tile_ids.append(tile_id)\n",
    "            skipped_reasons[tile_id] = f\"TIFF file not found: {tiff_path}\"\n",
    "            continue\n",
    "\n",
    "        output_img_path = os.path.join(output_img_dir, os.path.basename(tiff_path))\n",
    "\n",
    "        if pd.isna(mask_path) or not os.path.exists(mask_path):\n",
    "            mask_path = None\n",
    "            output_mask_path = None\n",
    "            skipped_reasons[tile_id] = \"Missing or invalid mask_path\"\n",
    "        else:\n",
    "            if convert_masks_to_geotiff:\n",
    "                mask_basename = os.path.splitext(os.path.basename(mask_path))[0] + '.tif'\n",
    "                output_mask_path = os.path.join(output_mask_dir, mask_basename)\n",
    "            else:\n",
    "                output_mask_path = os.path.join(output_mask_dir, os.path.basename(mask_path))\n",
    "\n",
    "        try:\n",
    "            tile_geom = row.geometry\n",
    "            if tile_geom is None:\n",
    "                skipped_tile_ids.append(tile_id)\n",
    "                skipped_reasons[tile_id] = \"Missing geometry\"\n",
    "                continue\n",
    "\n",
    "            buildings_in_tile = gdf_buildings[gdf_buildings.intersects(tile_geom)]\n",
    "            if len(buildings_in_tile) == 0:\n",
    "                skipped_tile_ids.append(tile_id)\n",
    "                skipped_reasons[tile_id] = \"No intersecting buildings found\"\n",
    "                continue\n",
    "\n",
    "            with rasterio.open(tiff_path) as src:\n",
    "                src_meta = src.meta.copy()\n",
    "                original_height, original_width = src.height, src.width\n",
    "                shapes = [mapping(geom) for geom in buildings_in_tile.geometry]\n",
    "\n",
    "                masked_data, mask_transform = rasterio.mask.mask(\n",
    "                    src, \n",
    "                    shapes, \n",
    "                    crop=False, \n",
    "                    all_touched=True,\n",
    "                    invert=True,\n",
    "                    filled=True,\n",
    "                    nodata=0\n",
    "                )\n",
    "\n",
    "                binary_mask = (masked_data[0] == 0).astype(np.uint8)\n",
    "                original_img = src.read()\n",
    "                masked_img = original_img.copy()\n",
    "\n",
    "                for i in range(masked_img.shape[0]):\n",
    "                    masked_img[i][binary_mask == 0] = 0\n",
    "\n",
    "                out_meta = src_meta.copy()\n",
    "                with rasterio.open(output_img_path, 'w', **out_meta) as dest:\n",
    "                    dest.write(masked_img)\n",
    "\n",
    "                successful_img_count += 1\n",
    "\n",
    "                if mask_path is not None:\n",
    "                    try:\n",
    "                        with Image.open(mask_path) as mask_img:\n",
    "                            mask_array = np.array(mask_img)\n",
    "                            if mask_array.shape[:2] != (original_height, original_width):\n",
    "                                tiff_dims = f\"{original_width}x{original_height}\"\n",
    "                                mask_dims = f\"{mask_array.shape[1]}x{mask_array.shape[0]}\"\n",
    "                                print(f\"Warning: Mask dimensions don't match GeoTIFF for {os.path.basename(tiff_path)}\")\n",
    "                                print(f\"  - GeoTIFF dimensions: {tiff_dims}\")\n",
    "                                print(f\"  - Mask dimensions: {mask_dims}\")\n",
    "                                skipped_reasons[tile_id] = f\"Mask dimensions don't match GeoTIFF: GeoTIFF={tiff_dims}, Mask={mask_dims}\"\n",
    "                                continue\n",
    "\n",
    "                            if len(mask_array.shape) == 3:\n",
    "                                for i in range(mask_array.shape[2]):\n",
    "                                    mask_array[:, :, i] = mask_array[:, :, i] * binary_mask\n",
    "                            else:\n",
    "                                mask_array = mask_array * binary_mask\n",
    "\n",
    "                            if convert_masks_to_geotiff:\n",
    "                                mask_meta = src_meta.copy()\n",
    "                                if len(mask_array.shape) == 3:\n",
    "                                    mask_meta.update(\n",
    "                                        dtype=mask_array.dtype,\n",
    "                                        count=mask_array.shape[2],\n",
    "                                        nodata=0,\n",
    "                                    )\n",
    "                                else:\n",
    "                                    mask_meta.update(\n",
    "                                        dtype=mask_array.dtype,\n",
    "                                        count=1,\n",
    "                                        nodata=0,\n",
    "                                    )\n",
    "                                with rasterio.open(output_mask_path, 'w', **mask_meta) as dest:\n",
    "                                    if len(mask_array.shape) == 3:\n",
    "                                        for i in range(mask_array.shape[2]):\n",
    "                                            dest.write(mask_array[:, :, i], i+1)\n",
    "                                    else:\n",
    "                                        dest.write(mask_array, 1)\n",
    "                            else:\n",
    "                                Image.fromarray(mask_array).save(output_mask_path)\n",
    "\n",
    "                            successful_mask_count += 1\n",
    "                            processed_tile_ids.append(tile_id)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        error_count += 1\n",
    "                        skipped_tile_ids.append(tile_id)\n",
    "                        skipped_reasons[tile_id] = f\"Error processing mask: {str(e)}\"\n",
    "                        print(f\"Error processing mask {mask_path}: {e}\")\n",
    "                else:\n",
    "                    processed_tile_ids.append(tile_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            skipped_tile_ids.append(tile_id)\n",
    "            skipped_reasons[tile_id] = f\"Error: {str(e)}\"\n",
    "            print(f\"Error processing {tiff_path}: {e}\")\n",
    "\n",
    "    processed_tile_ids = list(set(processed_tile_ids))\n",
    "    skipped_tile_ids = list(set(skipped_tile_ids))\n",
    "    overlap = set(processed_tile_ids) & set(skipped_tile_ids)\n",
    "\n",
    "    print(f\"Processed {len(gdf_dataset)} files\")\n",
    "    print(f\"- {successful_img_count} GeoTIFFs\")\n",
    "    print(f\"- {successful_mask_count} masks\")\n",
    "    if convert_masks_to_geotiff:\n",
    "        print(f\"- {successful_mask_count} PNG masks converted to GeoTIFF\")\n",
    "    print(f\"- {error_count} errors\")\n",
    "    print(f\"- {len(processed_tile_ids)} tiles processed\")\n",
    "    print(f\"- {len(skipped_tile_ids)} tiles skipped\")\n",
    "\n",
    "    if overlap:\n",
    "        print(f\"Warning: {len(overlap)} tile_ids in both processed and skipped lists.\")\n",
    "\n",
    "    if skipped_tile_ids:\n",
    "        dimension_mismatches = [reason for tile_id, reason in skipped_reasons.items() \n",
    "                            if \"Mask dimensions don't match\" in reason]\n",
    "\n",
    "        print(\"\\nDimension mismatch summary:\")\n",
    "        print(f\"  - {len(dimension_mismatches)} files with dimension mismatches\")\n",
    "\n",
    "        if dimension_mismatches:\n",
    "            import re\n",
    "            geotiff_dims = []\n",
    "            mask_dims = []\n",
    "            pattern = r\"GeoTIFF=(\\d+x\\d+), Mask=(\\d+x\\d+)\"\n",
    "\n",
    "            for reason in dimension_mismatches:\n",
    "                match = re.search(pattern, reason)\n",
    "                if match:\n",
    "                    geotiff_dims.append(match.group(1))\n",
    "                    mask_dims.append(match.group(2))\n",
    "\n",
    "            from collections import Counter\n",
    "            geotiff_counter = Counter(geotiff_dims)\n",
    "            mask_counter = Counter(mask_dims)\n",
    "\n",
    "            print(\"\\nMost common GeoTIFF dimensions:\")\n",
    "            for dims, count in geotiff_counter.most_common(3):\n",
    "                print(f\"  - {dims}: {count} files\")\n",
    "\n",
    "            print(\"\\nMost common mask dimensions:\")\n",
    "            for dims, count in mask_counter.most_common(3):\n",
    "                print(f\"  - {dims}: {count} files\")\n",
    "\n",
    "        skipped_tiles = {tile_id: skipped_reasons[tile_id] for tile_id in skipped_tile_ids}\n",
    "        return processed_tile_ids, skipped_tiles\n",
    "\n",
    "processed_tile_ids, skipped_tiles = clip_geotiff_and_png_masks(\n",
    "    gdf_dataset, gdf_cad_batiment_horsol, DATASET_OUTPUT_IMG_PATH, DATASET_OUTPUT_MASKS_PATH, convert_masks_to_geotiff=True\n",
    ")\n",
    "\n",
    "print(f\"Processed tile_ids: {len(processed_tile_ids)}\")\n",
    "print(f\"Skipped tile_ids: {len(skipped_tiles)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter path au gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of files inside the paths\n",
    "dataset_processed_masks_path_list = [os.path.join(DATASET_OUTPUT_MASKS_PATH, f) for f in os.listdir(DATASET_OUTPUT_MASKS_PATH)]\n",
    "dataset_processed_img_path_list = [os.path.join(DATASET_OUTPUT_IMG_PATH, f) for f in os.listdir(DATASET_OUTPUT_IMG_PATH)]\n",
    "\n",
    "df_processed = pd.DataFrame(\n",
    "    {\n",
    "        \"tile_id\": [os.path.basename(f).split(\".\")[0] for f in dataset_processed_masks_path_list],\n",
    "        \"processed_mask_path_tif\": dataset_processed_masks_path_list,\n",
    "        \"processed_img_path_tif\": dataset_processed_img_path_list,\n",
    "    }\n",
    ")\n",
    "# split tile_id after the second underscore keep the right part\n",
    "df_processed[\"tile_id\"] = df_processed[\"tile_id\"].apply(lambda x: \"_\".join(x.split(\"_\")[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "processed_mask_path_tif",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "processed_img_path_tif",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "830bb97f-544f-418d-9830-6d2449fa3342",
       "rows": [
        [
         "0",
         "10_12_8d26a8",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/25031119_tile_10_12_8d26a8.tif",
         "datasets/supervisely/dataset_processed_20250523-173715/images/25031119_tile_10_12_8d26a8.tif"
        ],
        [
         "1",
         "0_6_9201e5",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/25051123_tile_0_6_9201e5.tif",
         "datasets/supervisely/dataset_processed_20250523-173715/images/25051123_tile_0_6_9201e5.tif"
        ],
        [
         "2",
         "18_4_b35ef3",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/25081121_tile_18_4_b35ef3.tif",
         "datasets/supervisely/dataset_processed_20250523-173715/images/25081121_tile_18_4_b35ef3.tif"
        ],
        [
         "3",
         "1_3_14c592",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24991113_tile_1_3_14c592.tif",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24991113_tile_1_3_14c592.tif"
        ],
        [
         "4",
         "15_17_5212bb",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24971118_tile_15_17_5212bb.tif",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24971118_tile_15_17_5212bb.tif"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>processed_mask_path_tif</th>\n",
       "      <th>processed_img_path_tif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_12_8d26a8</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_6_9201e5</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_4_b35ef3</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3_14c592</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_17_5212bb</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id                            processed_mask_path_tif  \\\n",
       "0  10_12_8d26a8  datasets/supervisely/dataset_processed_2025052...   \n",
       "1    0_6_9201e5  datasets/supervisely/dataset_processed_2025052...   \n",
       "2   18_4_b35ef3  datasets/supervisely/dataset_processed_2025052...   \n",
       "3    1_3_14c592  datasets/supervisely/dataset_processed_2025052...   \n",
       "4  15_17_5212bb  datasets/supervisely/dataset_processed_2025052...   \n",
       "\n",
       "                              processed_img_path_tif  \n",
       "0  datasets/supervisely/dataset_processed_2025052...  \n",
       "1  datasets/supervisely/dataset_processed_2025052...  \n",
       "2  datasets/supervisely/dataset_processed_2025052...  \n",
       "3  datasets/supervisely/dataset_processed_2025052...  \n",
       "4  datasets/supervisely/dataset_processed_2025052...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# no duplicate in df_annotations[\"tile_id\"], no duplicate in df_annotations[\"tile_id\"], no duplicate in df_annotations[\"tile_id\"]\n",
    "assert(len(df_processed[df_processed.duplicated(subset=[\"tile_id\"])]) == 0), f\"df_processed has duplicates in tile_id: {df_processed[df_processed.duplicated(subset=['tile_id'])]}\"\n",
    "assert(len(df_processed[df_processed.duplicated(subset=[\"processed_img_path_tif\"])]) == 0), f\"df_processed has duplicates in processed_img_path_tif: {df_processed[df_processed.duplicated(subset=['processed_img_path_tif'])]}\"\n",
    "assert(len(df_processed[df_processed.duplicated(subset=[\"processed_mask_path_tif\"])]) == 0), f\"df_processed has duplicates in processed_mask_path_tif: {df_processed[df_processed.duplicated(subset=['processed_mask_path_tif'])]}\"\n",
    "\n",
    "# no nan or null in df_processed[\"tile_id\"], no nan or null in df_processed[\"processed_img_path_tif\"], no nan or null in df_processed[\"processed_mask_path_tif\"]\n",
    "assert(df_processed[\"tile_id\"].isnull().sum() == 0), f\"df_processed has null in tile_id: {df_processed[df_processed['tile_id'].isnull()]}\"\n",
    "assert(df_processed[\"processed_img_path_tif\"].isnull().sum() == 0), f\"df_processed has null in processed_img_path_tif: {df_processed[df_processed['processed_img_path_tif'].isnull()]}\"\n",
    "assert(df_processed[\"processed_mask_path_tif\"].isnull().sum() == 0), f\"df_processed has null in processed_mask_path_tif: {df_processed[df_processed['processed_mask_path_tif'].isnull()]}\"\n",
    "\n",
    "display(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dataset = gdf_dataset.merge(\n",
    "    df_processed,\n",
    "    how=\"left\",\n",
    "    left_on=\"tile_id\",\n",
    "    right_on=\"tile_id\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gérér les chevauchement entre tuiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Déterminer coin chevaucehement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating spatial index...\n",
      "Checking overlaps among 539 geometries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7936df83f9c4e038a8a2a2abfa5c915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checking overlaps:   0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 overlapping pairs\n",
      "\n",
      "Overlap positions before filtering:\n",
      "  right: 34\n",
      "  left: 34\n",
      "  top: 28\n",
      "  bottom: 28\n",
      "  top-right: 19\n",
      "  bottom-left: 19\n",
      "  top-left: 16\n",
      "  bottom-right: 16\n",
      "\n",
      "Overlaps using buffered geometries: 0 (0.0%)\n",
      "\n",
      "Unique position types found:\n",
      "  bottom\n",
      "  bottom-left\n",
      "  bottom-right\n",
      "  left\n",
      "  right\n",
      "  top\n",
      "  top-left\n",
      "  top-right\n"
     ]
    }
   ],
   "source": [
    "def determine_relative_position(geom1, geom2, tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Returns the relative position of geom1 to geom2.\n",
    "    Assumes Y increases northward.\n",
    "    \"\"\"\n",
    "    minx1, miny1, maxx1, maxy1 = geom1.bounds\n",
    "    minx2, miny2, maxx2, maxy2 = geom2.bounds\n",
    "\n",
    "    center_x1 = (minx1 + maxx1) / 2\n",
    "    center_y1 = (miny1 + maxy1) / 2\n",
    "    center_x2 = (minx2 + maxx2) / 2\n",
    "    center_y2 = (miny2 + maxy2) / 2\n",
    "\n",
    "    avg_width = ((maxx1 - minx1) + (maxx2 - minx2)) / 2\n",
    "    avg_height = ((maxy1 - miny1) + (maxy2 - miny2)) / 2\n",
    "\n",
    "    x_tolerance = tolerance * avg_width\n",
    "    y_tolerance = tolerance * avg_height\n",
    "\n",
    "    intersection = geom1.intersection(geom2)\n",
    "    intersection_area = intersection.area\n",
    "\n",
    "    vertical_position = None\n",
    "    horizontal_position = None\n",
    "\n",
    "    # Y increases northward\n",
    "    vertical_diff = center_y1 - center_y2\n",
    "    if abs(vertical_diff) <= y_tolerance:\n",
    "        vertical_position = None\n",
    "    elif vertical_diff > 0:\n",
    "        vertical_position = \"bottom\"\n",
    "    else:\n",
    "        vertical_position = \"top\"\n",
    "\n",
    "    # X increases eastward\n",
    "    horizontal_diff = center_x1 - center_x2\n",
    "    if abs(horizontal_diff) <= x_tolerance:\n",
    "        horizontal_position = None\n",
    "    elif horizontal_diff > 0:\n",
    "        horizontal_position = \"left\"\n",
    "    else:\n",
    "        horizontal_position = \"right\"\n",
    "\n",
    "    smaller_area = min(geom1.area, geom2.area)\n",
    "    overlap_percentage = (intersection_area / smaller_area) * 100 if smaller_area > 0 else 0\n",
    "\n",
    "    if vertical_position and horizontal_position:\n",
    "        position = f\"{vertical_position}-{horizontal_position}\"\n",
    "    elif vertical_position:\n",
    "        position = vertical_position\n",
    "    elif horizontal_position:\n",
    "        position = horizontal_position\n",
    "    else:\n",
    "        position = \"substantial-overlap\" if overlap_percentage > 90 else \"center\"\n",
    "\n",
    "    return position\n",
    "\n",
    "def get_opposite_position(position):\n",
    "    \"\"\"Returns the opposite relative position.\"\"\"\n",
    "    position_map = {\n",
    "        'top': 'bottom',\n",
    "        'bottom': 'top',\n",
    "        'left': 'right',\n",
    "        'right': 'left',\n",
    "        'top-left': 'bottom-right',\n",
    "        'top-right': 'bottom-left',\n",
    "        'bottom-left': 'top-right',\n",
    "        'bottom-right': 'top-left',\n",
    "        'center': 'center',\n",
    "        'substantial-overlap': 'substantial-overlap'\n",
    "    }\n",
    "    return position_map.get(position, position)\n",
    "\n",
    "def check_geotiffs_overlap(geom1, geom2, min_overlap_area=0.0):\n",
    "    \"\"\"Returns overlap info between two geometries.\"\"\"\n",
    "    result = {\n",
    "        'overlaps': False,\n",
    "        'overlap_area': 0.0,\n",
    "        'relative_position': None,\n",
    "        'overlap_percentage_1': 0.0,\n",
    "        'overlap_percentage_2': 0.0\n",
    "    }\n",
    "\n",
    "    if geom1.intersects(geom2):\n",
    "        intersection = geom1.intersection(geom2)\n",
    "        overlap_area = intersection.area\n",
    "\n",
    "        if overlap_area > min_overlap_area:\n",
    "            result['overlaps'] = True\n",
    "            result['overlap_area'] = overlap_area\n",
    "            result['relative_position'] = determine_relative_position(geom1, geom2)\n",
    "            result['overlap_percentage_1'] = (overlap_area / geom1.area) * 100\n",
    "            result['overlap_percentage_2'] = (overlap_area / geom2.area) * 100\n",
    "\n",
    "    return result\n",
    "\n",
    "def check_overlaps_in_dataframe(gdf, min_overlap_area=1.0, include_symmetric=False, buffer_distance=0.01):\n",
    "    \"\"\"\n",
    "    Checks for overlapping geometries in a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    overlap_results = []\n",
    "    n = len(gdf)\n",
    "\n",
    "    try:\n",
    "        if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "            raise TypeError(\"Input must be a GeoDataFrame\")\n",
    "\n",
    "        if n == 0:\n",
    "            raise ValueError(\"GeoDataFrame is empty\")\n",
    "\n",
    "        print(\"Creating spatial index...\")\n",
    "        sindex = gdf.sindex\n",
    "\n",
    "        print(f\"Checking overlaps among {n} geometries...\")\n",
    "        with tqdm(total=n, desc=\"Checking overlaps\") as pbar:\n",
    "            for i in range(n):\n",
    "                geom1 = gdf.iloc[i]['geometry']\n",
    "                tile_id1 = gdf.iloc[i]['tile_id']\n",
    "\n",
    "                if geom1 is None or not geom1.is_valid:\n",
    "                    print(f\"Warning: Skipping invalid geometry for {tile_id1}\")\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                bbox = geom1.bounds\n",
    "                potential_matches_idx = list(sindex.intersection(bbox))\n",
    "\n",
    "                if i in potential_matches_idx:\n",
    "                    potential_matches_idx.remove(i)\n",
    "\n",
    "                potential_matches_idx = [j for j in potential_matches_idx if j > i]\n",
    "\n",
    "                for j in potential_matches_idx:\n",
    "                    geom2 = gdf.iloc[j]['geometry']\n",
    "                    tile_id2 = gdf.iloc[j]['tile_id']\n",
    "\n",
    "                    if geom2 is None or not geom2.is_valid:\n",
    "                        print(f\"Warning: Skipping invalid geometry for {tile_id2}\")\n",
    "                        continue\n",
    "\n",
    "                    if buffer_distance > 0:\n",
    "                        buffered_geom1 = geom1.buffer(buffer_distance)\n",
    "                        buffered_geom2 = geom2.buffer(buffer_distance)\n",
    "                    else:\n",
    "                        buffered_geom1 = geom1\n",
    "                        buffered_geom2 = geom2\n",
    "\n",
    "                    if buffered_geom1.intersects(buffered_geom2):\n",
    "                        intersection = buffered_geom1.intersection(buffered_geom2)\n",
    "\n",
    "                        if not intersection.is_empty and intersection.area > min_overlap_area:\n",
    "                            result = check_geotiffs_overlap(buffered_geom1, buffered_geom2, min_overlap_area)\n",
    "\n",
    "                            if result['overlaps']:\n",
    "                                overlap_results.append({\n",
    "                                    'tile_id1': tile_id1,\n",
    "                                    'tile_id2': tile_id2,\n",
    "                                    'index1': i,\n",
    "                                    'index2': j,\n",
    "                                    'overlap_area': result['overlap_area'],\n",
    "                                    'relative_position': result['relative_position'],\n",
    "                                    'overlap_percentage_1': result['overlap_percentage_1'],\n",
    "                                    'overlap_percentage_2': result['overlap_percentage_2'],\n",
    "                                    'buffered': buffer_distance > 0\n",
    "                                })\n",
    "\n",
    "                                if include_symmetric:\n",
    "                                    opposite_position = get_opposite_position(result['relative_position'])\n",
    "\n",
    "                                    overlap_results.append({\n",
    "                                        'tile_id1': tile_id2,\n",
    "                                        'tile_id2': tile_id1,\n",
    "                                        'index1': j,\n",
    "                                        'index2': i,\n",
    "                                        'overlap_area': result['overlap_area'],\n",
    "                                        'relative_position': opposite_position,\n",
    "                                        'overlap_percentage_1': result['overlap_percentage_2'],\n",
    "                                        'overlap_percentage_2': result['overlap_percentage_1'],\n",
    "                                        'buffered': buffer_distance > 0\n",
    "                                    })\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during overlap check: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    if overlap_results:\n",
    "        overlap_df = pd.DataFrame(overlap_results)\n",
    "        print(f\"Found {len(overlap_df)} overlapping pairs\")\n",
    "\n",
    "        position_counts = overlap_df['relative_position'].value_counts()\n",
    "        print(\"\\nOverlap positions before filtering:\")\n",
    "        for pos, count in position_counts.items():\n",
    "            print(f\"  {pos}: {count}\")\n",
    "\n",
    "        if 'buffered' in overlap_df.columns:\n",
    "            buffered_count = overlap_df['buffered'].sum()\n",
    "            print(f\"\\nOverlaps using buffered geometries: {buffered_count} ({(buffered_count/len(overlap_df))*100:.1f}%)\")\n",
    "\n",
    "        return overlap_df\n",
    "    else:\n",
    "        print(\"No overlapping pairs found\")\n",
    "        return pd.DataFrame(columns=['tile_id1', 'tile_id2', 'index1', 'index2',\n",
    "                                    'overlap_area', 'relative_position',\n",
    "                                    'overlap_percentage_1', 'overlap_percentage_2',\n",
    "                                    'buffered'])\n",
    "\n",
    "\n",
    "# Run overlap check\n",
    "overlap_df = check_overlaps_in_dataframe(gdf_dataset, min_overlap_area=1.0, include_symmetric=True, buffer_distance=BUFFER_DISTANCE)\n",
    "\n",
    "# Show unique positions\n",
    "print(\"\\nUnique position types found:\")\n",
    "for pos in sorted(overlap_df['relative_position'].unique()):\n",
    "    print(f\"  {pos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mettre en background si chevauchement haut ou à droite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 113 out of 194 overlaps that match position criteria\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e96d5da3814a7597ffd676db611747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing overlaps:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 226 files\n",
      "\n",
      "Summary of processed files:\n",
      "Total modified files: 226\n",
      "\n",
      "Files by type:\n",
      "file_type\n",
      "image    113\n",
      "mask     113\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of processed files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "overlap_with",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "overlap_area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "modified_pixels",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5eecf8f7-353e-46cd-a5ce-c4f62d4e24ea",
       "rows": [
        [
         "0",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24971117_tile_14_6_cc7d0d.tif",
         "image",
         "top",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24971117_tile_15_6_7a6487.tif",
         "819.1999999880791",
         "327680",
         "14_6_cc7d0d"
        ],
        [
         "1",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24971117_tile_14_6_cc7d0d.tif",
         "mask",
         "top",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24971117_tile_15_6_7a6487.tif",
         "819.1999999880791",
         "327680",
         "14_6_cc7d0d"
        ],
        [
         "2",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24971117_tile_15_6_7a6487.tif",
         "image",
         "top-right",
         "datasets/supervisely/dataset_processed_20250523-173715/images/24971117_tile_14_7_b86707.tif",
         "163.83999999523164",
         "65536",
         "15_6_7a6487"
        ],
        [
         "3",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24971117_tile_15_6_7a6487.tif",
         "mask",
         "top-right",
         "datasets/supervisely/dataset_processed_20250523-173715/masks/24971117_tile_14_7_b86707.tif",
         "163.83999999523164",
         "65536",
         "15_6_7a6487"
        ],
        [
         "4",
         "datasets/supervisely/dataset_processed_20250523-173715/images/25001115_tile_17_6_8a7785.tif",
         "image",
         "top-right",
         "datasets/supervisely/dataset_processed_20250523-173715/images/25001115_tile_16_7_68c3da.tif",
         "163.83999999821185",
         "65536",
         "17_6_8a7785"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_type</th>\n",
       "      <th>position</th>\n",
       "      <th>overlap_with</th>\n",
       "      <th>overlap_area</th>\n",
       "      <th>modified_pixels</th>\n",
       "      <th>tile_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>image</td>\n",
       "      <td>top</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>819.20</td>\n",
       "      <td>327680</td>\n",
       "      <td>14_6_cc7d0d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>mask</td>\n",
       "      <td>top</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>819.20</td>\n",
       "      <td>327680</td>\n",
       "      <td>14_6_cc7d0d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>image</td>\n",
       "      <td>top-right</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>163.84</td>\n",
       "      <td>65536</td>\n",
       "      <td>15_6_7a6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>mask</td>\n",
       "      <td>top-right</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>163.84</td>\n",
       "      <td>65536</td>\n",
       "      <td>15_6_7a6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>image</td>\n",
       "      <td>top-right</td>\n",
       "      <td>datasets/supervisely/dataset_processed_2025052...</td>\n",
       "      <td>163.84</td>\n",
       "      <td>65536</td>\n",
       "      <td>17_6_8a7785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path file_type   position  \\\n",
       "0  datasets/supervisely/dataset_processed_2025052...     image        top   \n",
       "1  datasets/supervisely/dataset_processed_2025052...      mask        top   \n",
       "2  datasets/supervisely/dataset_processed_2025052...     image  top-right   \n",
       "3  datasets/supervisely/dataset_processed_2025052...      mask  top-right   \n",
       "4  datasets/supervisely/dataset_processed_2025052...     image  top-right   \n",
       "\n",
       "                                        overlap_with  overlap_area  \\\n",
       "0  datasets/supervisely/dataset_processed_2025052...        819.20   \n",
       "1  datasets/supervisely/dataset_processed_2025052...        819.20   \n",
       "2  datasets/supervisely/dataset_processed_2025052...        163.84   \n",
       "3  datasets/supervisely/dataset_processed_2025052...        163.84   \n",
       "4  datasets/supervisely/dataset_processed_2025052...        163.84   \n",
       "\n",
       "   modified_pixels      tile_id  \n",
       "0           327680  14_6_cc7d0d  \n",
       "1           327680  14_6_cc7d0d  \n",
       "2            65536  15_6_7a6487  \n",
       "3            65536  15_6_7a6487  \n",
       "4            65536  17_6_8a7785  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_overlap_in_geotiffs(overlap_df, gdf_dataset, overlap_positions=None, overwrite=True, buffer_distance=0.01):\n",
    "    \"\"\"\n",
    "    Removes overlapping regions in GeoTIFF files by setting pixel values to 0 in the specified overlap areas.\n",
    "    Handles both image and mask files. Overlap regions are determined by spatial intersection and relative position.\n",
    "\n",
    "    Args:\n",
    "        overlap_df: DataFrame with overlap information between tiles.\n",
    "        gdf_dataset: GeoDataFrame containing GeoTIFF paths and geometries.\n",
    "        overlap_positions: List of relative positions to process (default: ['right', 'top', 'top-right', 'bottom-right']).\n",
    "        overwrite: If True, modifies files in place. If False, writes to new files.\n",
    "        buffer_distance: Buffer distance for geometry intersection (should match overlap detection).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with details about processed files.\n",
    "    \"\"\"\n",
    "    # Set default positions if not provided\n",
    "    if overlap_positions is None:\n",
    "        overlap_positions = ['right', 'top', 'top-right', 'bottom-right']\n",
    "\n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "\n",
    "    # Exit if there are no overlaps to process\n",
    "    if len(overlap_df) == 0:\n",
    "        print(\"No overlaps to process\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Filter overlaps by specified positions\n",
    "    filtered_df = overlap_df.copy()\n",
    "    if overlap_positions:\n",
    "        position_filter = filtered_df['relative_position'].apply(\n",
    "            lambda pos: any(p in pos for p in overlap_positions)\n",
    "        )\n",
    "        filtered_df = filtered_df[position_filter]\n",
    "        print(f\"Processing {len(filtered_df)} out of {len(overlap_df)} overlaps that match position criteria\")\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        print(\"No overlaps match the specified positions\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Process each overlap entry\n",
    "    with tqdm(total=len(filtered_df), desc=\"Processing overlaps\") as pbar:\n",
    "        for idx, row in filtered_df.iterrows():\n",
    "            index1 = row['index1']\n",
    "            index2 = row['index2']\n",
    "            position = row['relative_position']\n",
    "\n",
    "            # Get file paths for images and masks\n",
    "            tiff_path1 = gdf_dataset.iloc[index1]['processed_img_path_tif']\n",
    "            tiff_path2 = gdf_dataset.iloc[index2]['processed_img_path_tif']\n",
    "            mask_path1 = gdf_dataset.iloc[index1]['processed_mask_path_tif']\n",
    "            mask_path2 = gdf_dataset.iloc[index2]['processed_mask_path_tif']\n",
    "\n",
    "            # Get geometries for both tiles\n",
    "            geom1 = gdf_dataset.iloc[index1]['geometry']\n",
    "            geom2 = gdf_dataset.iloc[index2]['geometry']\n",
    "\n",
    "            # Use buffered geometries if specified\n",
    "            use_buffer = row.get('buffered', True)\n",
    "            if use_buffer:\n",
    "                buffered_geom1 = geom1.buffer(buffer_distance)\n",
    "                buffered_geom2 = geom2.buffer(buffer_distance)\n",
    "            else:\n",
    "                buffered_geom1 = geom1\n",
    "                buffered_geom2 = geom2\n",
    "\n",
    "            # Calculate intersection area\n",
    "            intersection = buffered_geom1.intersection(buffered_geom2)\n",
    "\n",
    "            # Skip if intersection is empty or invalid\n",
    "            if intersection.is_empty or intersection.area <= 0:\n",
    "                failed_files.append({\n",
    "                    'file_path': f\"{tiff_path1} / {tiff_path2}\",\n",
    "                    'file_type': \"both\",\n",
    "                    'position': position,\n",
    "                    'error': \"Empty intersection\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Decide which file to modify based on overlap position\n",
    "            modify_idx1 = False\n",
    "            if 'right' in position and 'left' not in position:\n",
    "                modify_idx1 = True\n",
    "            elif 'left' in position and 'right' not in position:\n",
    "                modify_idx1 = False\n",
    "            elif 'top' in position and 'bottom' not in position:\n",
    "                modify_idx1 = False\n",
    "            elif 'bottom' in position and 'top' not in position:\n",
    "                modify_idx1 = True\n",
    "            elif 'center' in position or 'substantial' in position:\n",
    "                modify_idx1 = geom1.area <= geom2.area\n",
    "            else:\n",
    "                modify_idx1 = row['overlap_percentage_1'] <= row['overlap_percentage_2']\n",
    "\n",
    "            # Select file paths to modify\n",
    "            if modify_idx1:\n",
    "                img_to_modify = tiff_path1\n",
    "                mask_to_modify = mask_path1\n",
    "                overlap_with_img = tiff_path2\n",
    "                overlap_with_mask = mask_path2\n",
    "                tile_id = gdf_dataset.iloc[index1]['tile_id']\n",
    "            else:\n",
    "                img_to_modify = tiff_path2\n",
    "                mask_to_modify = mask_path2\n",
    "                overlap_with_img = tiff_path1\n",
    "                overlap_with_mask = mask_path1\n",
    "                tile_id = gdf_dataset.iloc[index2]['tile_id']\n",
    "\n",
    "            # Process both image and mask files\n",
    "            for file_type, file_to_modify in [(\"image\", img_to_modify), (\"mask\", mask_to_modify)]:\n",
    "                if not os.path.exists(file_to_modify):\n",
    "                    failed_files.append({\n",
    "                        'file_path': file_to_modify,\n",
    "                        'file_type': file_type,\n",
    "                        'position': position,\n",
    "                        'error': \"File does not exist\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                # Determine output file path\n",
    "                if overwrite:\n",
    "                    output_file = file_to_modify\n",
    "                else:\n",
    "                    output_dir = os.path.dirname(file_to_modify)\n",
    "                    base_name = os.path.basename(file_to_modify)\n",
    "                    output_file = os.path.join(output_dir, f\"overlap_fixed_{base_name}\")\n",
    "\n",
    "                try:\n",
    "                    temp_file = None\n",
    "                    if overwrite:\n",
    "                        temp_dir = os.path.dirname(file_to_modify)\n",
    "                        temp_file = os.path.join(temp_dir, f\"temp_{os.path.basename(file_to_modify)}\")\n",
    "\n",
    "                    with rasterio.open(file_to_modify) as src:\n",
    "                        data = src.read()\n",
    "                        minx, miny, maxx, maxy = intersection.bounds\n",
    "                        window = from_bounds(minx, miny, maxx, maxy, src.transform)\n",
    "\n",
    "                        # Validate window coordinates\n",
    "                        if (np.isnan(window.col_off) or np.isnan(window.row_off) or \n",
    "                            np.isnan(window.width) or np.isnan(window.height)):\n",
    "                            failed_files.append({\n",
    "                                'file_path': file_to_modify,\n",
    "                                'file_type': file_type,\n",
    "                                'position': position,\n",
    "                                'error': \"Invalid window coordinates\"\n",
    "                            })\n",
    "                            continue\n",
    "\n",
    "                        # Convert window coordinates to integers and check bounds\n",
    "                        col_off = max(0, int(window.col_off))\n",
    "                        row_off = max(0, int(window.row_off))\n",
    "                        width = min(int(np.ceil(window.width)), src.width - col_off)\n",
    "                        height = min(int(np.ceil(window.height)), src.height - row_off)\n",
    "\n",
    "                        if width <= 0 or height <= 0:\n",
    "                            failed_files.append({\n",
    "                                'file_path': file_to_modify,\n",
    "                                'file_type': file_type,\n",
    "                                'position': position,\n",
    "                                'error': \"Invalid window dimensions\"\n",
    "                            })\n",
    "                            continue\n",
    "\n",
    "                        # Set overlapping region pixels to 0\n",
    "                        for band in range(data.shape[0]):\n",
    "                            data[band, row_off:row_off+height, col_off:col_off+width] = 0\n",
    "\n",
    "                        profile = src.profile\n",
    "\n",
    "                    write_path = temp_file if overwrite else output_file\n",
    "\n",
    "                    # Write modified data to file\n",
    "                    with rasterio.open(write_path, 'w', **profile) as dst:\n",
    "                        dst.write(data)\n",
    "\n",
    "                    # Replace original file if overwriting\n",
    "                    if overwrite and temp_file:\n",
    "                        if os.path.exists(file_to_modify):\n",
    "                            os.remove(file_to_modify)\n",
    "                        shutil.move(temp_file, file_to_modify)\n",
    "\n",
    "                    processed_files.append({\n",
    "                        'file_path': file_to_modify,\n",
    "                        'file_type': file_type,\n",
    "                        'position': position,\n",
    "                        'overlap_with': overlap_with_img if file_type == 'image' else overlap_with_mask,\n",
    "                        'overlap_area': row['overlap_area'],\n",
    "                        'modified_pixels': width * height,\n",
    "                        'tile_id': tile_id\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    error_msg = str(e)\n",
    "                    print(f\"Error processing {file_type} file {file_to_modify}: {error_msg}\")\n",
    "                    if overwrite and temp_file and os.path.exists(temp_file):\n",
    "                        os.remove(temp_file)\n",
    "                    failed_files.append({\n",
    "                        'file_path': file_to_modify,\n",
    "                        'file_type': file_type,\n",
    "                        'position': position,\n",
    "                        'error': error_msg\n",
    "                    })\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Summarize results\n",
    "    if processed_files:\n",
    "        results_df = pd.DataFrame(processed_files)\n",
    "        print(f\"Successfully processed {len(results_df)} files\")\n",
    "        if failed_files:\n",
    "            failed_df = pd.DataFrame(failed_files)\n",
    "            print(f\"Failed to process {len(failed_df)} files\")\n",
    "            print(\"First few failures:\")\n",
    "            print(failed_df.head())\n",
    "        return results_df\n",
    "    else:\n",
    "        if failed_files:\n",
    "            failed_df = pd.DataFrame(failed_files)\n",
    "            print(f\"Failed to process all {len(failed_df)} files\")\n",
    "            print(\"First few failures:\")\n",
    "            print(failed_df.head())\n",
    "        print(\"No files were processed successfully\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "results = remove_overlap_in_geotiffs(overlap_df, gdf_dataset, overlap_positions=OVERLAP_POSITIONS, buffer_distance=BUFFER_DISTANCE)\n",
    "\n",
    "# Display summary of results\n",
    "if len(results) > 0:\n",
    "    print(\"\\nSummary of processed files:\")\n",
    "    print(f\"Total modified files: {len(results)}\")\n",
    "    file_type_counts = results['file_type'].value_counts()\n",
    "    print(\"\\nFiles by type:\")\n",
    "    print(file_type_counts)\n",
    "    print(\"\\nSample of processed files:\")\n",
    "    display(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_overlap_corrections(overlap_df, gdf_dataset, buffer_distance=0.01):\n",
    "    \"\"\"\n",
    "    Checks if overlapping regions in GeoTIFF files have been corrected by verifying\n",
    "    if one or both tiles contain background values (0) in the overlapping area.\n",
    "    Handles buffered geometries as needed.\n",
    "\n",
    "    Args:\n",
    "        overlap_df: DataFrame with overlap information.\n",
    "        gdf_dataset: GeoDataFrame with GeoTIFF paths and geometries.\n",
    "        buffer_distance: Buffer distance for geometry, should match the value used in overlap detection.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with verification results for each overlapping pair.\n",
    "    \"\"\"\n",
    "\n",
    "    verification_results = []\n",
    "    skipped_pairs = 0\n",
    "\n",
    "    if len(overlap_df) == 0:\n",
    "        print(\"No overlaps to verify\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Verifying {len(overlap_df)} overlapping pairs...\")\n",
    "    with tqdm(total=len(overlap_df), desc=\"Verifying overlaps\") as pbar:\n",
    "        for idx, row in overlap_df.iterrows():\n",
    "            index1 = row['index1']\n",
    "            index2 = row['index2']\n",
    "            position = row['relative_position']\n",
    "\n",
    "            tiff_path1 = gdf_dataset.iloc[index1]['processed_img_path_tif']\n",
    "            tiff_path2 = gdf_dataset.iloc[index2]['processed_img_path_tif']\n",
    "\n",
    "            geom1 = gdf_dataset.iloc[index1]['geometry']\n",
    "            geom2 = gdf_dataset.iloc[index2]['geometry']\n",
    "\n",
    "            result = {\n",
    "                'tile_id1': row['tile_id1'],\n",
    "                'tile_id2': row['tile_id2'],\n",
    "                'position': position,\n",
    "                'overlap_area': row['overlap_area'],\n",
    "                'file1_has_zeros': False,\n",
    "                'file2_has_zeros': False,\n",
    "                'file1_zero_percentage': 0.0,\n",
    "                'file2_zero_percentage': 0.0,\n",
    "                'both_have_zeros': False,\n",
    "                'either_has_zeros': False,\n",
    "                'avg_zero_percentage': 0.0,\n",
    "                'status': 'unchecked'\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Validate geometries\n",
    "                if geom1 is None or not geom1.is_valid or geom2 is None or not geom2.is_valid:\n",
    "                    result['status'] = 'invalid_geometry'\n",
    "                    verification_results.append(result)\n",
    "                    pbar.update(1)\n",
    "                    skipped_pairs += 1\n",
    "                    continue\n",
    "\n",
    "                # Apply buffer if required\n",
    "                use_buffer = row.get('buffered', True)\n",
    "                if use_buffer:\n",
    "                    buffered_geom1 = geom1.buffer(buffer_distance)\n",
    "                    buffered_geom2 = geom2.buffer(buffer_distance)\n",
    "                else:\n",
    "                    buffered_geom1 = geom1\n",
    "                    buffered_geom2 = geom2\n",
    "\n",
    "                # Compute intersection\n",
    "                intersection = buffered_geom1.intersection(buffered_geom2)\n",
    "\n",
    "                # Skip if intersection is empty or has no area\n",
    "                if intersection.is_empty or intersection.area <= 0:\n",
    "                    result['status'] = 'empty_intersection'\n",
    "                    verification_results.append(result)\n",
    "                    pbar.update(1)\n",
    "                    skipped_pairs += 1\n",
    "                    continue\n",
    "\n",
    "                # Check first file for zeros in overlap\n",
    "                with rasterio.open(tiff_path1) as src1:\n",
    "                    minx, miny, maxx, maxy = intersection.bounds\n",
    "                    window1 = from_bounds(minx, miny, maxx, maxy, src1.transform)\n",
    "\n",
    "                    # Validate window coordinates\n",
    "                    if (np.isnan(window1.col_off) or np.isnan(window1.row_off) or \n",
    "                        np.isnan(window1.width) or np.isnan(window1.height)):\n",
    "                        result['status'] = 'invalid_window_file1'\n",
    "                        verification_results.append(result)\n",
    "                        pbar.update(1)\n",
    "                        skipped_pairs += 1\n",
    "                        continue\n",
    "\n",
    "                    # Ensure window is within image bounds\n",
    "                    col_off1 = max(0, int(window1.col_off))\n",
    "                    row_off1 = max(0, int(window1.row_off))\n",
    "                    width1 = min(int(np.ceil(window1.width)), src1.width - col_off1)\n",
    "                    height1 = min(int(np.ceil(window1.height)), src1.height - row_off1)\n",
    "\n",
    "                    if width1 <= 0 or height1 <= 0:\n",
    "                        result['status'] = 'invalid_dimensions_file1'\n",
    "                        verification_results.append(result)\n",
    "                        pbar.update(1)\n",
    "                        skipped_pairs += 1\n",
    "                        continue\n",
    "\n",
    "                    data1 = src1.read(1, window=((row_off1, row_off1+height1), (col_off1, col_off1+width1)))\n",
    "                    zero_count1 = np.sum(data1 == 0)\n",
    "                    total_pixels1 = data1.size\n",
    "                    zero_percentage1 = (zero_count1 / total_pixels1) * 100\n",
    "\n",
    "                    result['file1_has_zeros'] = zero_count1 > 0\n",
    "                    result['file1_zero_percentage'] = zero_percentage1\n",
    "\n",
    "                # Check second file for zeros in overlap\n",
    "                with rasterio.open(tiff_path2) as src2:\n",
    "                    minx, miny, maxx, maxy = intersection.bounds\n",
    "                    window2 = from_bounds(minx, miny, maxx, maxy, src2.transform)\n",
    "\n",
    "                    if (np.isnan(window2.col_off) or np.isnan(window2.row_off) or \n",
    "                        np.isnan(window2.width) or np.isnan(window2.height)):\n",
    "                        result['status'] = 'invalid_window_file2' if result['status'] == 'unchecked' else 'invalid_windows_both'\n",
    "                        verification_results.append(result)\n",
    "                        pbar.update(1)\n",
    "                        skipped_pairs += 1\n",
    "                        continue\n",
    "\n",
    "                    col_off2 = max(0, int(window2.col_off))\n",
    "                    row_off2 = max(0, int(window2.row_off))\n",
    "                    width2 = min(int(np.ceil(window2.width)), src2.width - col_off2)\n",
    "                    height2 = min(int(np.ceil(window2.height)), src2.height - row_off2)\n",
    "\n",
    "                    if width2 <= 0 or height2 <= 0:\n",
    "                        result['status'] = 'invalid_dimensions_file2' if result['status'] == 'unchecked' else 'invalid_dimensions_both'\n",
    "                        verification_results.append(result)\n",
    "                        pbar.update(1)\n",
    "                        skipped_pairs += 1\n",
    "                        continue\n",
    "\n",
    "                    data2 = src2.read(1, window=((row_off2, row_off2+height2), (col_off2, col_off2+width2)))\n",
    "                    zero_count2 = np.sum(data2 == 0)\n",
    "                    total_pixels2 = data2.size\n",
    "                    zero_percentage2 = (zero_count2 / total_pixels2) * 100\n",
    "\n",
    "                    result['file2_has_zeros'] = zero_count2 > 0\n",
    "                    result['file2_zero_percentage'] = zero_percentage2\n",
    "\n",
    "                # Compute summary metrics for overlap\n",
    "                if result['status'] == 'unchecked':\n",
    "                    result['both_have_zeros'] = result['file1_has_zeros'] and result['file2_has_zeros']\n",
    "                    result['either_has_zeros'] = result['file1_has_zeros'] or result['file2_has_zeros']\n",
    "                    result['avg_zero_percentage'] = (result['file1_zero_percentage'] + result['file2_zero_percentage']) / 2\n",
    "\n",
    "                    if result['both_have_zeros']:\n",
    "                        result['status'] = 'both_have_zeros'\n",
    "                    elif result['either_has_zeros']:\n",
    "                        result['status'] = 'one_has_zeros'\n",
    "                    else:\n",
    "                        result['status'] = 'no_zeros'\n",
    "\n",
    "            except Exception as e:\n",
    "                result['status'] = f\"error: {str(e)}\"\n",
    "                skipped_pairs += 1\n",
    "\n",
    "            verification_results.append(result)\n",
    "            pbar.update(1)\n",
    "\n",
    "    if verification_results:\n",
    "        df_verification = pd.DataFrame(verification_results)\n",
    "\n",
    "        # Print summary statistics\n",
    "        status_counts = df_verification['status'].value_counts()\n",
    "        print(\"\\nVerification results:\")\n",
    "        for status, count in status_counts.items():\n",
    "            print(f\"  {status}: {count} pairs ({count/len(df_verification)*100:.1f}%)\")\n",
    "\n",
    "        # Show statistics for valid results\n",
    "        valid_df = df_verification[df_verification['status'].isin(['both_have_zeros', 'one_has_zeros', 'no_zeros'])]\n",
    "\n",
    "        if len(valid_df) > 0:\n",
    "            both_zeros_count = valid_df['both_have_zeros'].sum()\n",
    "            either_zeros_count = valid_df['either_has_zeros'].sum()\n",
    "\n",
    "            print(f\"\\n  Pairs where both tiles have zeros in overlap: {both_zeros_count} ({both_zeros_count/len(valid_df)*100:.1f}%)\")\n",
    "            print(f\"  Pairs where at least one tile has zeros in overlap: {either_zeros_count} ({either_zeros_count/len(valid_df)*100:.1f}%)\")\n",
    "\n",
    "            avg_zero_pct = valid_df['avg_zero_percentage'].mean()\n",
    "            print(f\"  Average percentage of zeros in overlap areas: {avg_zero_pct:.1f}%\")\n",
    "\n",
    "            # Warn if any pairs have no background pixels in overlap\n",
    "            failed_verification = valid_df[valid_df['status'] == 'no_zeros']\n",
    "            if len(failed_verification) > 0:\n",
    "                print(f\"\\nWARNING: {len(failed_verification)} pairs have no background pixels in overlap regions!\")\n",
    "                print(\"\\nSample of problematic pairs:\")\n",
    "                display(failed_verification.head(5))\n",
    "\n",
    "        print(f\"\\nSkipped {skipped_pairs} pairs due to geometry or window issues\")\n",
    "\n",
    "        return df_verification\n",
    "    else:\n",
    "        print(\"No verification results\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying 194 overlapping pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b8dbe1330e4e439f47e140913d8b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verifying overlaps:   0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification results:\n",
      "  both_have_zeros: 180 pairs (92.8%)\n",
      "  one_has_zeros: 14 pairs (7.2%)\n",
      "\n",
      "  Pairs where both tiles have zeros in overlap: 180 (92.8%)\n",
      "  Pairs where at least one tile has zeros in overlap: 194 (100.0%)\n",
      "  Average percentage of zeros in overlap areas: 85.2%\n",
      "\n",
      "Skipped 0 pairs due to geometry or window issues\n",
      "\n",
      "Pairs where both files have high zero percentage (>90%):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tile_id1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tile_id2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file1_zero_percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "file2_zero_percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e9b0305a-7ab1-4ef0-ad8d-acf4b4789283",
       "rows": [
        [
         "0",
         "15_6_7a6487",
         "14_6_cc7d0d",
         "top",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "1",
         "14_6_cc7d0d",
         "15_6_7a6487",
         "bottom",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "2",
         "15_6_7a6487",
         "14_7_b86707",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "3",
         "14_7_b86707",
         "15_6_7a6487",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "4",
         "17_6_8a7785",
         "16_7_68c3da",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "5",
         "16_7_68c3da",
         "17_6_8a7785",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "16",
         "13_3_0619aa",
         "12_3_fe57cb",
         "top",
         "99.761962890625",
         "100.0",
         "both_have_zeros"
        ],
        [
         "17",
         "12_3_fe57cb",
         "13_3_0619aa",
         "bottom",
         "100.0",
         "99.761962890625",
         "both_have_zeros"
        ],
        [
         "18",
         "13_15_c8052d",
         "13_14_47b1f2",
         "left",
         "99.0472412109375",
         "100.0",
         "both_have_zeros"
        ],
        [
         "19",
         "13_14_47b1f2",
         "13_15_c8052d",
         "right",
         "100.0",
         "99.0472412109375",
         "both_have_zeros"
        ],
        [
         "20",
         "19_10_d691f6",
         "19_9_e55938",
         "left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "21",
         "19_9_e55938",
         "19_10_d691f6",
         "right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "22",
         "14_16_56f89c",
         "13_16_1f40c2",
         "top",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "23",
         "13_16_1f40c2",
         "14_16_56f89c",
         "bottom",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "26",
         "3_15_66786d",
         "2_16_efa593",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "27",
         "2_16_efa593",
         "3_15_66786d",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "28",
         "5_15_686804",
         "5_14_fcd06e",
         "left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "29",
         "5_14_fcd06e",
         "5_15_686804",
         "right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "30",
         "16_1_27e50c",
         "15_0_1792b2",
         "top-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "31",
         "15_0_1792b2",
         "16_1_27e50c",
         "bottom-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "34",
         "5_14_fcd06e",
         "6_13_e63e45",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "35",
         "6_13_e63e45",
         "5_14_fcd06e",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "36",
         "17_11_237356",
         "18_12_5b3ee4",
         "bottom-right",
         "100.0",
         "93.24493408203125",
         "both_have_zeros"
        ],
        [
         "37",
         "18_12_5b3ee4",
         "17_11_237356",
         "top-left",
         "93.24493408203125",
         "100.0",
         "both_have_zeros"
        ],
        [
         "40",
         "1_7_c5b3d8",
         "2_7_6f4439",
         "bottom",
         "100.0",
         "98.7945556640625",
         "both_have_zeros"
        ],
        [
         "41",
         "2_7_6f4439",
         "1_7_c5b3d8",
         "top",
         "98.7945556640625",
         "100.0",
         "both_have_zeros"
        ],
        [
         "44",
         "1_6_d35657",
         "2_7_6f4439",
         "bottom-right",
         "100.0",
         "94.41375732421875",
         "both_have_zeros"
        ],
        [
         "45",
         "2_7_6f4439",
         "1_6_d35657",
         "top-left",
         "94.41375732421875",
         "100.0",
         "both_have_zeros"
        ],
        [
         "48",
         "13_16_94d0a7",
         "12_16_5bfa38",
         "top",
         "99.23614501953125",
         "100.0",
         "both_have_zeros"
        ],
        [
         "49",
         "12_16_5bfa38",
         "13_16_94d0a7",
         "bottom",
         "100.0",
         "99.23614501953125",
         "both_have_zeros"
        ],
        [
         "52",
         "15_3_e388dd",
         "16_2_ccf95d",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "53",
         "16_2_ccf95d",
         "15_3_e388dd",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "56",
         "19_5_22e308",
         "18_5_f475a0",
         "top",
         "98.3447265625",
         "100.0",
         "both_have_zeros"
        ],
        [
         "57",
         "18_5_f475a0",
         "19_5_22e308",
         "bottom",
         "100.0",
         "98.3447265625",
         "both_have_zeros"
        ],
        [
         "62",
         "16_10_eb231c",
         "16_9_b11959",
         "left",
         "98.63067626953125",
         "100.0",
         "both_have_zeros"
        ],
        [
         "63",
         "16_9_b11959",
         "16_10_eb231c",
         "right",
         "100.0",
         "98.63067626953125",
         "both_have_zeros"
        ],
        [
         "66",
         "0_18_3e6f69",
         "0_19_3bacf1",
         "right",
         "100.0",
         "91.4849853515625",
         "both_have_zeros"
        ],
        [
         "67",
         "0_19_3bacf1",
         "0_18_3e6f69",
         "left",
         "91.4849853515625",
         "100.0",
         "both_have_zeros"
        ],
        [
         "68",
         "9_15_717aa2",
         "9_16_d4a5db",
         "right",
         "100.0",
         "98.93157958984375",
         "both_have_zeros"
        ],
        [
         "69",
         "9_16_d4a5db",
         "9_15_717aa2",
         "left",
         "98.93157958984375",
         "100.0",
         "both_have_zeros"
        ],
        [
         "70",
         "17_2_f9bcc4",
         "18_1_c69147",
         "bottom-left",
         "98.17047119140625",
         "100.0",
         "both_have_zeros"
        ],
        [
         "71",
         "18_1_c69147",
         "17_2_f9bcc4",
         "top-right",
         "100.0",
         "98.17047119140625",
         "both_have_zeros"
        ],
        [
         "76",
         "2_17_b4f962",
         "3_18_e0bd40",
         "bottom-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "77",
         "3_18_e0bd40",
         "2_17_b4f962",
         "top-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "82",
         "2_15_c552ae",
         "3_14_1bf395",
         "bottom-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "83",
         "3_14_1bf395",
         "2_15_c552ae",
         "top-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "88",
         "2_18_ab3051",
         "1_18_0caf0d",
         "top",
         "99.5452880859375",
         "100.0",
         "both_have_zeros"
        ],
        [
         "89",
         "1_18_0caf0d",
         "2_18_ab3051",
         "bottom",
         "100.0",
         "99.5452880859375",
         "both_have_zeros"
        ],
        [
         "92",
         "2_13_8b6e6f",
         "3_14_1bf395",
         "bottom-right",
         "100.0",
         "100.0",
         "both_have_zeros"
        ],
        [
         "93",
         "3_14_1bf395",
         "2_13_8b6e6f",
         "top-left",
         "100.0",
         "100.0",
         "both_have_zeros"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 76
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id1</th>\n",
       "      <th>tile_id2</th>\n",
       "      <th>position</th>\n",
       "      <th>file1_zero_percentage</th>\n",
       "      <th>file2_zero_percentage</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15_6_7a6487</td>\n",
       "      <td>14_6_cc7d0d</td>\n",
       "      <td>top</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14_6_cc7d0d</td>\n",
       "      <td>15_6_7a6487</td>\n",
       "      <td>bottom</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15_6_7a6487</td>\n",
       "      <td>14_7_b86707</td>\n",
       "      <td>top-right</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14_7_b86707</td>\n",
       "      <td>15_6_7a6487</td>\n",
       "      <td>bottom-left</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17_6_8a7785</td>\n",
       "      <td>16_7_68c3da</td>\n",
       "      <td>top-right</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3_4_b3ad65</td>\n",
       "      <td>2_5_d310ba</td>\n",
       "      <td>top-right</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2_5_d310ba</td>\n",
       "      <td>3_6_9b5376</td>\n",
       "      <td>bottom-right</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3_6_9b5376</td>\n",
       "      <td>2_5_d310ba</td>\n",
       "      <td>top-left</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3_5_677ebf</td>\n",
       "      <td>4_4_6684a3</td>\n",
       "      <td>bottom-left</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>4_4_6684a3</td>\n",
       "      <td>3_5_677ebf</td>\n",
       "      <td>top-right</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>both_have_zeros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tile_id1     tile_id2      position  file1_zero_percentage  \\\n",
       "0    15_6_7a6487  14_6_cc7d0d           top                  100.0   \n",
       "1    14_6_cc7d0d  15_6_7a6487        bottom                  100.0   \n",
       "2    15_6_7a6487  14_7_b86707     top-right                  100.0   \n",
       "3    14_7_b86707  15_6_7a6487   bottom-left                  100.0   \n",
       "4    17_6_8a7785  16_7_68c3da     top-right                  100.0   \n",
       "..           ...          ...           ...                    ...   \n",
       "171   3_4_b3ad65   2_5_d310ba     top-right                  100.0   \n",
       "172   2_5_d310ba   3_6_9b5376  bottom-right                  100.0   \n",
       "173   3_6_9b5376   2_5_d310ba      top-left                  100.0   \n",
       "186   3_5_677ebf   4_4_6684a3   bottom-left                  100.0   \n",
       "187   4_4_6684a3   3_5_677ebf     top-right                  100.0   \n",
       "\n",
       "     file2_zero_percentage           status  \n",
       "0                    100.0  both_have_zeros  \n",
       "1                    100.0  both_have_zeros  \n",
       "2                    100.0  both_have_zeros  \n",
       "3                    100.0  both_have_zeros  \n",
       "4                    100.0  both_have_zeros  \n",
       "..                     ...              ...  \n",
       "171                  100.0  both_have_zeros  \n",
       "172                  100.0  both_have_zeros  \n",
       "173                  100.0  both_have_zeros  \n",
       "186                  100.0  both_have_zeros  \n",
       "187                  100.0  both_have_zeros  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run verification to check overlap corrections in GeoTIFF files\n",
    "df_verification = verify_overlap_corrections(overlap_df, gdf_dataset, buffer_distance=BUFFER_DISTANCE)\n",
    "\n",
    "if len(df_verification) > 0:\n",
    "    # Display pairs where the average percentage of zeros in the overlap is low (<10%)\n",
    "    low_zeros = df_verification[df_verification['avg_zero_percentage'] < 10]\n",
    "    if len(low_zeros) > 0:\n",
    "        print(\"\\nPairs with low zero percentage (<10%):\")\n",
    "        display(low_zeros[['tile_id1', 'tile_id2', 'position', 'file1_zero_percentage', 'file2_zero_percentage', 'status']])\n",
    "    \n",
    "    # Display pairs where both files have a high percentage of zeros in the overlap (>90%)\n",
    "    high_zeros = df_verification[\n",
    "        (df_verification['file1_zero_percentage'] > 90) & \n",
    "        (df_verification['file2_zero_percentage'] > 90)\n",
    "    ]\n",
    "    if len(high_zeros) > 0:\n",
    "        print(\"\\nPairs where both files have high zero percentage (>90%):\")\n",
    "        display(high_zeros[['tile_id1', 'tile_id2', 'position', 'file1_zero_percentage', 'file2_zero_percentage', 'status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlap_corrections(overlap_df, df_verification, gdf_dataset, dataset_output_checks_path, zero_threshold=99.9):\n",
    "    \"\"\"\n",
    "    Visualize overlap corrections between GeoTIFF files, including mask overlays.\n",
    "\n",
    "    Args:\n",
    "        overlap_df: DataFrame with overlap information.\n",
    "        df_verification: DataFrame with verification results.\n",
    "        gdf_dataset: GeoDataFrame with GeoTIFF paths and geometries.\n",
    "        dataset_output_checks_path: Directory to save visualizations.\n",
    "        zero_threshold: Threshold (%) to consider a region as background (default 99.9).\n",
    "\n",
    "    Returns:\n",
    "        dict: Statistics about the visualizations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output directory with timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = os.path.join(dataset_output_checks_path, f\"overlap_check_{timestamp}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Counters for results\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    mask_issues = 0\n",
    "\n",
    "    def get_safe_window_data(src, intersection_bounds):\n",
    "        \"\"\"\n",
    "        Extract window data from raster, ensuring dimensions are valid.\n",
    "        \"\"\"\n",
    "        minx, miny, maxx, maxy = intersection_bounds\n",
    "        window = from_bounds(minx, miny, maxx, maxy, src.transform)\n",
    "        col_off = max(0, min(int(round(window.col_off)), src.width - 1))\n",
    "        row_off = max(0, min(int(round(window.row_off)), src.height - 1))\n",
    "        width = max(1, min(int(round(window.width)), src.width - col_off))\n",
    "        height = max(1, min(int(round(window.height)), src.height - row_off))\n",
    "        safe_window = Window(col_off, row_off, width, height)\n",
    "        data = src.read(1, window=safe_window)\n",
    "        return data, safe_window\n",
    "\n",
    "    def visualize_pair(row, output_path):\n",
    "        try:\n",
    "            tile_id1 = row['tile_id1']\n",
    "            tile_id2 = row['tile_id2']\n",
    "\n",
    "            # Find indices for the tiles\n",
    "            idx1 = gdf_dataset[gdf_dataset['tile_id'] == tile_id1].index[0]\n",
    "            idx2 = gdf_dataset[gdf_dataset['tile_id'] == tile_id2].index[0]\n",
    "\n",
    "            # Get file paths\n",
    "            tiff_path1 = gdf_dataset.loc[idx1, 'processed_img_path_tif']\n",
    "            tiff_path2 = gdf_dataset.loc[idx2, 'processed_img_path_tif']\n",
    "\n",
    "            # Check file existence\n",
    "            if not os.path.exists(tiff_path1) or not os.path.exists(tiff_path2):\n",
    "                print(f\"Files not found for {tile_id1} and {tile_id2}\")\n",
    "                return False\n",
    "\n",
    "            # Check for mask files\n",
    "            has_masks = False\n",
    "            if 'processed_mask_path_tif' in gdf_dataset.columns:\n",
    "                mask_path1 = gdf_dataset.loc[idx1, 'processed_mask_path_tif']\n",
    "                mask_path2 = gdf_dataset.loc[idx2, 'processed_mask_path_tif']\n",
    "                has_masks = (os.path.exists(mask_path1) and os.path.exists(mask_path2))\n",
    "                if not has_masks:\n",
    "                    print(f\"Warning: Mask files not found for {tile_id1} and/or {tile_id2}\")\n",
    "            else:\n",
    "                print(\"Warning: 'processed_mask_path_tif' column not found in dataset, masks will not be visualized\")\n",
    "\n",
    "            # Open raster files and analyze data\n",
    "            with rasterio.open(tiff_path1) as src1, rasterio.open(tiff_path2) as src2:\n",
    "                bounds1 = src1.bounds\n",
    "                bounds2 = src2.bounds\n",
    "\n",
    "                # Calculate intersection of bounds\n",
    "                intersection = (\n",
    "                    max(bounds1.left, bounds2.left),\n",
    "                    max(bounds1.bottom, bounds2.bottom),\n",
    "                    min(bounds1.right, bounds2.right),\n",
    "                    min(bounds1.top, bounds2.top)\n",
    "                )\n",
    "\n",
    "                # Check for valid intersection\n",
    "                if intersection[2] <= intersection[0] or intersection[3] <= intersection[1]:\n",
    "                    print(f\"No valid intersection for {tile_id1} and {tile_id2}\")\n",
    "                    return False\n",
    "\n",
    "                # Extract overlap data using safe window extraction\n",
    "                data1, window1 = get_safe_window_data(src1, intersection)\n",
    "                data2, window2 = get_safe_window_data(src2, intersection)\n",
    "\n",
    "                # Read full images for background\n",
    "                full_data1 = src1.read(1)\n",
    "                full_data2 = src2.read(1)\n",
    "\n",
    "                # Create masks for overlap regions\n",
    "                overlap_mask1 = np.zeros_like(full_data1, dtype=bool)\n",
    "                overlap_mask1[window1.row_off:window1.row_off+window1.height, \n",
    "                             window1.col_off:window1.col_off+window1.width] = True\n",
    "\n",
    "                overlap_mask2 = np.zeros_like(full_data2, dtype=bool)\n",
    "                overlap_mask2[window2.row_off:window2.row_off+window2.height, \n",
    "                             window2.col_off:window2.col_off+window2.width] = True\n",
    "\n",
    "                # Initialize mask variables\n",
    "                has_mask_conflict = False\n",
    "                mask_conflict_percentage = 0\n",
    "                mask_data1 = None\n",
    "                mask_data2 = None\n",
    "                mask_overlap1 = None\n",
    "                mask_overlap2 = None\n",
    "\n",
    "                if has_masks:\n",
    "                    try:\n",
    "                        with rasterio.open(mask_path1) as mask_src1, rasterio.open(mask_path2) as mask_src2:\n",
    "                            mask_data1 = mask_src1.read(1)\n",
    "                            mask_data2 = mask_src2.read(1)\n",
    "                            mask_overlap1 = mask_src1.read(1, window=window1)\n",
    "                            mask_overlap2 = mask_src2.read(1, window=window2)\n",
    "\n",
    "                            # Handle shape mismatches\n",
    "                            if mask_overlap1.shape != mask_overlap2.shape:\n",
    "                                print(f\"Mask shape mismatch for {tile_id1} and {tile_id2}: {mask_overlap1.shape} vs {mask_overlap2.shape}\")\n",
    "                                min_height = min(mask_overlap1.shape[0], mask_overlap2.shape[0])\n",
    "                                min_width = min(mask_overlap1.shape[1], mask_overlap2.shape[1])\n",
    "                                mask_overlap1 = mask_overlap1[:min_height, :min_width]\n",
    "                                mask_overlap2 = mask_overlap2[:min_height, :min_width]\n",
    "                                data1 = data1[:min_height, :min_width]\n",
    "                                data2 = data2[:min_height, :min_width]\n",
    "\n",
    "                            # Check for mask conflicts in overlap\n",
    "                            if mask_overlap1.shape == mask_overlap2.shape and mask_overlap1.size > 0:\n",
    "                                mask_conflict = np.logical_and(mask_overlap1 > 0, mask_overlap2 > 0)\n",
    "                                has_mask_conflict = np.any(mask_conflict)\n",
    "                                mask_conflict_percentage = np.sum(mask_conflict) / mask_conflict.size * 100\n",
    "                            else:\n",
    "                                has_mask_conflict = False\n",
    "                                mask_conflict_percentage = 0\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading mask files for {tile_id1} and {tile_id2}: {str(e)}\")\n",
    "                        has_masks = False\n",
    "                        has_mask_conflict = False\n",
    "                        mask_conflict_percentage = 0\n",
    "\n",
    "                # Ensure image data has matching dimensions\n",
    "                if data1.shape != data2.shape:\n",
    "                    min_height = min(data1.shape[0], data2.shape[0])\n",
    "                    min_width = min(data1.shape[1], data2.shape[1])\n",
    "                    data1 = data1[:min_height, :min_width]\n",
    "                    data2 = data2[:min_height, :min_width]\n",
    "\n",
    "                # Create visualization figure\n",
    "                fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "                # Row 1: Image analysis\n",
    "\n",
    "                # Plot first tile with overlap highlighted\n",
    "                axs[0, 0].imshow(full_data1, cmap='gray')\n",
    "                highlighted1 = np.zeros((*full_data1.shape, 4))\n",
    "                highlighted1[..., 0] = 1  # Red\n",
    "                highlighted1[..., 3] = np.where(overlap_mask1, 0.4, 0)\n",
    "                axs[0, 0].imshow(highlighted1)\n",
    "                axs[0, 0].set_title(f\"Tile {tile_id1}\\nZero %: {row.get('file1_zero_percentage', 'N/A'):.1f}%\")\n",
    "                axs[0, 0].axis('off')\n",
    "\n",
    "                # Plot second tile with overlap highlighted\n",
    "                axs[0, 1].imshow(full_data2, cmap='gray')\n",
    "                highlighted2 = np.zeros((*full_data2.shape, 4))\n",
    "                highlighted2[..., 2] = 1  # Blue\n",
    "                highlighted2[..., 3] = np.where(overlap_mask2, 0.4, 0)\n",
    "                axs[0, 1].imshow(highlighted2)\n",
    "                axs[0, 1].set_title(f\"Tile {tile_id2}\\nZero %: {row.get('file2_zero_percentage', 'N/A'):.1f}%\")\n",
    "                axs[0, 1].axis('off')\n",
    "\n",
    "                # Composite image of overlap regions\n",
    "                if data1.size > 0 and data2.size > 0:\n",
    "                    composite = np.zeros((data1.shape[0], data1.shape[1] * 2))\n",
    "                    composite[:, :data1.shape[1]] = data1\n",
    "                    composite[:, data1.shape[1]:] = data2\n",
    "                    axs[0, 2].imshow(composite, cmap='gray')\n",
    "                    axs[0, 2].axvline(x=data1.shape[1], color='r', linestyle='--')\n",
    "\n",
    "                    # Calculate zero percentage in overlap\n",
    "                    zeros1 = np.sum(data1 == 0) / data1.size * 100\n",
    "                    zeros2 = np.sum(data2 == 0) / data2.size * 100\n",
    "\n",
    "                    # Determine content status\n",
    "                    if zeros1 >= zero_threshold and zeros2 >= zero_threshold:\n",
    "                        content_status = \"both_background\"\n",
    "                    else:\n",
    "                        content_status = \"partial_image\"\n",
    "\n",
    "                    axs[0, 2].set_title(f\"Overlap Comparison\\nPosition: {row.get('position', 'N/A')}, Status: {content_status}\")\n",
    "                    axs[0, 2].text(data1.shape[1] * 0.5, data1.shape[0] * 0.9, \n",
    "                                  f\"{zeros1:.1f}% zeros\", ha='center', color='white',\n",
    "                                  bbox=dict(facecolor='red', alpha=0.7))\n",
    "                    axs[0, 2].text(data1.shape[1] * 1.5, data1.shape[0] * 0.9, \n",
    "                                  f\"{zeros2:.1f}% zeros\", ha='center', color='white',\n",
    "                                  bbox=dict(facecolor='blue', alpha=0.7))\n",
    "                else:\n",
    "                    axs[0, 2].text(0.5, 0.5, \"No overlap data available\", \n",
    "                                 ha='center', va='center', fontsize=12)\n",
    "                    content_status = \"no_data\"\n",
    "                    zeros1 = zeros2 = 0\n",
    "\n",
    "                axs[0, 2].axis('off')\n",
    "\n",
    "                # Row 2: Mask analysis\n",
    "\n",
    "                if has_masks and mask_data1 is not None and mask_data2 is not None:\n",
    "                    # Plot first tile with mask overlay\n",
    "                    axs[1, 0].imshow(full_data1, cmap='gray')\n",
    "                    mask_overlay1 = np.zeros((*full_data1.shape, 4))\n",
    "                    mask_overlay1[..., 0] = 1  # Red\n",
    "                    mask_overlay1[..., 3] = np.where(mask_data1 > 0, 0.5, 0)\n",
    "                    axs[1, 0].imshow(mask_overlay1)\n",
    "                    axs[1, 0].set_title(f\"Tile {tile_id1} with mask overlay\")\n",
    "                    axs[1, 0].axis('off')\n",
    "\n",
    "                    # Plot second tile with mask overlay\n",
    "                    axs[1, 1].imshow(full_data2, cmap='gray')\n",
    "                    mask_overlay2 = np.zeros((*full_data2.shape, 4))\n",
    "                    mask_overlay2[..., 2] = 1  # Blue\n",
    "                    mask_overlay2[..., 3] = np.where(mask_data2 > 0, 0.5, 0)\n",
    "                    axs[1, 1].imshow(mask_overlay2)\n",
    "                    axs[1, 1].set_title(f\"Tile {tile_id2} with mask overlay\")\n",
    "                    axs[1, 1].axis('off')\n",
    "\n",
    "                    # Composite of overlap region with masks\n",
    "                    if (mask_overlap1 is not None and mask_overlap2 is not None and \n",
    "                        data1.size > 0 and data2.size > 0):\n",
    "\n",
    "                        mask_composite = np.zeros((data1.shape[0], data1.shape[1] * 2, 4))\n",
    "                        for c in range(3):\n",
    "                            if np.max(data1) > 0:\n",
    "                                mask_composite[:, :data1.shape[1], c] = data1 / np.max(data1)\n",
    "                            if np.max(data2) > 0:\n",
    "                                mask_composite[:, data1.shape[1]:, c] = data2 / np.max(data2)\n",
    "                        mask_composite[..., 3] = 1.0\n",
    "\n",
    "                        if mask_overlap1.shape == data1.shape and mask_overlap2.shape == data2.shape:\n",
    "                            mask_overlay_left = np.zeros((data1.shape[0], data1.shape[1], 4))\n",
    "                            mask_overlay_left[..., 0] = 1.0\n",
    "                            mask_overlay_left[..., 3] = np.where(mask_overlap1 > 0, 0.5, 0)\n",
    "                            mask_overlay_right = np.zeros((data2.shape[0], data2.shape[1], 4))\n",
    "                            mask_overlay_right[..., 2] = 1.0\n",
    "                            mask_overlay_right[..., 3] = np.where(mask_overlap2 > 0, 0.5, 0)\n",
    "                            axs[1, 2].imshow(mask_composite)\n",
    "                            axs[1, 2].imshow(np.pad(mask_overlay_left, ((0,0), (0,data1.shape[1]), (0,0)), 'constant'))\n",
    "                            axs[1, 2].imshow(np.pad(mask_overlay_right, ((0,0), (data1.shape[1],0), (0,0)), 'constant'))\n",
    "                            axs[1, 2].axvline(x=data1.shape[1], color='yellow', linestyle='--')\n",
    "                            if has_mask_conflict:\n",
    "                                title = f\"Mask Overlap Comparison\\nWarning: {mask_conflict_percentage:.1f}% mask conflict!\"\n",
    "                            else:\n",
    "                                title = \"Mask Overlap Comparison\\nNo mask conflicts\"\n",
    "                            axs[1, 2].set_title(title)\n",
    "                            axs[1, 2].axis('off')\n",
    "                        else:\n",
    "                            axs[1, 2].text(0.5, 0.5, \"Mask-image dimension mismatch\", \n",
    "                                         ha='center', va='center', fontsize=12)\n",
    "                            axs[1, 2].axis('off')\n",
    "                    else:\n",
    "                        axs[1, 2].text(0.5, 0.5, \"Unable to process mask overlaps\", \n",
    "                                     ha='center', va='center', fontsize=12)\n",
    "                        axs[1, 2].axis('off')\n",
    "\n",
    "                else:\n",
    "                    # No masks available\n",
    "                    for i in range(3):\n",
    "                        axs[1, i].text(0.5, 0.5, \"No mask files found\", \n",
    "                                     ha='center', va='center', fontsize=12)\n",
    "                        axs[1, i].axis('off')\n",
    "\n",
    "                # Add main title\n",
    "                plt.suptitle(f\"Overlap Analysis: {tile_id1} and {tile_id2}\", fontsize=16, y=0.98)\n",
    "                plt.tight_layout()\n",
    "                plt.subplots_adjust(top=0.92)\n",
    "                plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "                # Update row with analysis info\n",
    "                row['content_status'] = content_status\n",
    "                row['zeros1'] = zeros1\n",
    "                row['zeros2'] = zeros2\n",
    "\n",
    "                if has_masks:\n",
    "                    row['has_masks'] = True\n",
    "                    row['has_mask_conflict'] = has_mask_conflict\n",
    "                    row['mask_conflict_percentage'] = mask_conflict_percentage\n",
    "                else:\n",
    "                    row['has_masks'] = False\n",
    "\n",
    "                return True, has_masks and has_mask_conflict\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing pair {tile_id1} and {tile_id2}: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return False, False\n",
    "\n",
    "    # Process each verified pair\n",
    "    if len(df_verification) > 0:\n",
    "        print(f\"Processing {len(df_verification)} verified pairs...\")\n",
    "        results_df = pd.DataFrame()\n",
    "        for idx, row in tqdm(df_verification.iterrows(), total=len(df_verification)):\n",
    "            tile_id1 = row['tile_id1']\n",
    "            tile_id2 = row['tile_id2']\n",
    "            position = row.get('position', 'unknown')\n",
    "            row_copy = row.copy()\n",
    "            filename = f\"{tile_id1}_{tile_id2}_{position}.png\"\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            success, has_mask_issue = visualize_pair(row_copy, output_path)\n",
    "            if success:\n",
    "                successful += 1\n",
    "                if has_mask_issue:\n",
    "                    mask_issues += 1\n",
    "                results_df = pd.concat([results_df, pd.DataFrame([row_copy])], ignore_index=True)\n",
    "            else:\n",
    "                failed += 1\n",
    "\n",
    "        # Save results to CSV\n",
    "        results_path = os.path.join(output_dir, \"overlap_analysis_results.csv\")\n",
    "        results_df.to_csv(results_path, index=False)\n",
    "        print(f\"Saved results to {results_path}\")\n",
    "\n",
    "        # Save mask issues to separate CSV if any\n",
    "        if mask_issues > 0:\n",
    "            mask_issues_df = results_df[results_df.get('has_mask_conflict', False) == True]\n",
    "            mask_issues_path = os.path.join(output_dir, \"mask_issues.csv\")\n",
    "            mask_issues_df.to_csv(mask_issues_path, index=False)\n",
    "            print(f\"Found {mask_issues} tile pairs with mask issues. Saved to {mask_issues_path}\")\n",
    "\n",
    "    print(f\"Visualization complete. Created {successful} visualizations in {output_dir}\")\n",
    "    print(f\"- Successful visualizations: {successful}\")\n",
    "    print(f\"- Failed visualizations: {failed}\")\n",
    "    print(f\"- Pairs with mask issues: {mask_issues}\")\n",
    "\n",
    "    return {\n",
    "        \"successful\": successful,\n",
    "        \"failed\": failed,\n",
    "        \"mask_issues\": mask_issues,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"results_path\": results_path if len(df_verification) > 0 else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 194 verified pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d80573919d41458e15f8fe23e9010a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to datasets/supervisely/dataset_processed_20250523-173715/check_dataset/overlap_check_20250523-173751/overlap_analysis_results.csv\n",
      "Visualization complete. Created 194 visualizations in datasets/supervisely/dataset_processed_20250523-173715/check_dataset/overlap_check_20250523-173751\n",
      "- Successful visualizations: 194\n",
      "- Failed visualizations: 0\n",
      "- Pairs with mask issues: 0\n",
      "Results saved to directory: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/overlap_check_20250523-173751\n",
      "Successful visualizations: 194\n",
      "Failed visualizations: 0\n",
      "Tiles with mask issues: 0\n"
     ]
    }
   ],
   "source": [
    "# Visualize overlap corrections between GeoTIFF files and save the results.\n",
    "visualization_results = visualize_overlap_corrections(\n",
    "    overlap_df=overlap_df,\n",
    "    df_verification=df_verification,\n",
    "    gdf_dataset=gdf_dataset,\n",
    "    dataset_output_checks_path=DATASET_OUTPUT_CHECKS_PATH,\n",
    ")\n",
    "\n",
    "# Display summary of visualization results\n",
    "print(f\"Results saved to directory: {visualization_results['output_dir']}\")\n",
    "print(f\"Successful visualizations: {visualization_results['successful']}\")\n",
    "print(f\"Failed visualizations: {visualization_results['failed']}\")\n",
    "print(f\"Tiles with mask issues: {visualization_results['mask_issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding images pour 1280x1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 538 images to ensure 1280x1280 dimensions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b09670a2a614ff58cc35053696b1e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Standardizing images:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete:\n",
      "- Total images processed: 538\n",
      "- Image/mask pairs resized and overwritten: 42\n",
      "- Pairs skipped: 0\n",
      "- Errors encountered: 0\n",
      "- Images already at target size: 496\n",
      "\n",
      "Modified 42 file pairs. First 5 examples:\n",
      "1. 25011116_tile_13_19_d8b3fa.tif: (672, 1280) -> (1280, 1280)\n",
      "2. 25001117_tile_19_7_894243.tif: (1280, 672) -> (1280, 1280)\n",
      "3. 24971119_tile_9_19_924944.tif: (672, 1280) -> (1280, 1280)\n",
      "4. 25061123_tile_19_5_1c6023.tif: (1280, 672) -> (1280, 1280)\n",
      "5. 24911110_tile_0_19_c476a4.tif: (672, 1280) -> (1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "def standardize_image_dimensions(img_dir, mask_dir, target_size=(1280, 1280), overwrite=True):\n",
    "    \"\"\"\n",
    "    Pads images and masks to a target size with identical padding for each pair.\n",
    "    Overwrites original files or creates new ones, depending on the 'overwrite' flag.\n",
    "\n",
    "    Args:\n",
    "        img_dir (str): Directory containing GeoTIFF images.\n",
    "        mask_dir (str): Directory containing GeoTIFF masks.\n",
    "        target_size (tuple): Desired (width, height) for output images and masks.\n",
    "        overwrite (bool): If True, overwrite original files. If False, create new files with '_padded' suffix.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries for each modified file pair:\n",
    "            {\n",
    "                'img_file': path to modified image file,\n",
    "                'mask_file': path to modified mask file,\n",
    "                'from_size': original (width, height),\n",
    "                'to_size': new (width, height),\n",
    "                'padding': (start_x, start_y, pad_width, pad_height)\n",
    "            }\n",
    "    \"\"\"\n",
    "    # List image and mask files\n",
    "    img_files = [f for f in os.listdir(img_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "\n",
    "    # Map mask base names to file names\n",
    "    mask_map = {}\n",
    "    for mask_file in mask_files:\n",
    "        mask_basename = os.path.splitext(mask_file)[0]\n",
    "        mask_map[mask_basename] = mask_file\n",
    "\n",
    "    total_images = len(img_files)\n",
    "    resized_pairs = 0\n",
    "    errors = 0\n",
    "    skipped = 0\n",
    "    modified_files = []\n",
    "\n",
    "    print(f\"Processing {total_images} images to ensure {target_size[0]}x{target_size[1]} dimensions...\")\n",
    "\n",
    "    for img_filename in tqdm(img_files, desc=\"Standardizing images\"):\n",
    "        try:\n",
    "            img_path = os.path.join(img_dir, img_filename)\n",
    "            img_basename = os.path.splitext(img_filename)[0]\n",
    "            mask_filename = mask_map.get(img_basename)\n",
    "\n",
    "            if mask_filename:\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "                if not os.path.exists(mask_path):\n",
    "                    print(f\"Warning: Mask file {mask_path} not found. Skipping pair.\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Warning: No matching mask found for {img_filename}. Skipping.\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            # Open image to get dimensions\n",
    "            with rasterio.open(img_path) as src:\n",
    "                height, width = src.height, src.width\n",
    "\n",
    "                # Skip if already at target size\n",
    "                if (width, height) == target_size:\n",
    "                    continue\n",
    "\n",
    "                pad_width = max(0, target_size[0] - width)\n",
    "                pad_height = max(0, target_size[1] - height)\n",
    "                start_x = pad_width // 2\n",
    "                start_y = pad_height // 2\n",
    "\n",
    "                # Skip if image is larger than target\n",
    "                if pad_width < 0 or pad_height < 0:\n",
    "                    print(f\"Warning: {img_filename} is larger than target size. Skipping pair.\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                # Pad image\n",
    "                with rasterio.open(img_path) as src:\n",
    "                    img_data = src.read()\n",
    "                    bands = img_data.shape[0]\n",
    "                    padded_data = np.zeros((bands, target_size[1], target_size[0]), dtype=img_data.dtype)\n",
    "                    for b in range(bands):\n",
    "                        padded_data[b, start_y:start_y+height, start_x:start_x+width] = img_data[b]\n",
    "\n",
    "                    # Adjust georeferencing\n",
    "                    transform = src.transform\n",
    "                    xoff = transform.c - start_x * transform.a\n",
    "                    yoff = transform.f - start_y * transform.e\n",
    "                    new_transform = rasterio.Affine(transform.a, transform.b, xoff,\n",
    "                                                    transform.d, transform.e, yoff)\n",
    "\n",
    "                    meta = src.meta.copy()\n",
    "                    meta.update({\n",
    "                        'height': target_size[1],\n",
    "                        'width': target_size[0],\n",
    "                        'transform': new_transform\n",
    "                    })\n",
    "\n",
    "                    # Write padded image to temp file\n",
    "                    with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmp:\n",
    "                        tmp_path = tmp.name\n",
    "                    with rasterio.open(tmp_path, 'w', **meta) as dst:\n",
    "                        dst.write(padded_data)\n",
    "                    shutil.move(tmp_path, img_path)\n",
    "\n",
    "                # Pad mask\n",
    "                if mask_filename.lower().endswith('.png'):\n",
    "                    mask_img = Image.open(mask_path)\n",
    "                    mask_width, mask_height = mask_img.size\n",
    "                    if (mask_width, mask_height) != (width, height):\n",
    "                        print(f\"Warning: Dimensions mismatch between {img_filename} and {mask_filename}. Using GeoTIFF dimensions.\")\n",
    "\n",
    "                    new_mask = Image.new(mask_img.mode, target_size, 0)\n",
    "                    new_mask.paste(mask_img, (start_x, start_y))\n",
    "                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:\n",
    "                        tmp_path = tmp.name\n",
    "                    new_mask.save(tmp_path)\n",
    "                    shutil.move(tmp_path, mask_path)\n",
    "\n",
    "                elif mask_filename.lower().endswith(('.tif', '.tiff')):\n",
    "                    with rasterio.open(mask_path) as mask_src:\n",
    "                        mask_height, mask_width = mask_src.height, mask_src.width\n",
    "                        if (mask_width, mask_height) != (width, height):\n",
    "                            print(f\"Warning: Dimensions mismatch between {img_filename} and {mask_filename}. Using image dimensions.\")\n",
    "\n",
    "                        mask_data = mask_src.read()\n",
    "                        mask_bands = mask_data.shape[0]\n",
    "                        padded_mask_data = np.zeros((mask_bands, target_size[1], target_size[0]), dtype=mask_data.dtype)\n",
    "                        for b in range(mask_bands):\n",
    "                            padded_mask_data[b, start_y:start_y+mask_height, start_x:start_x+mask_width] = mask_data[b]\n",
    "\n",
    "                        mask_meta = mask_src.meta.copy()\n",
    "                        mask_meta.update({\n",
    "                            'height': target_size[1],\n",
    "                            'width': target_size[0],\n",
    "                            'transform': new_transform\n",
    "                        })\n",
    "\n",
    "                        with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmp:\n",
    "                            tmp_path = tmp.name\n",
    "                        with rasterio.open(tmp_path, 'w', **mask_meta) as dst:\n",
    "                            dst.write(padded_mask_data)\n",
    "                        shutil.move(tmp_path, mask_path)\n",
    "\n",
    "                modified_files.append({\n",
    "                    'img_file': img_path,\n",
    "                    'mask_file': mask_path,\n",
    "                    'from_size': (width, height),\n",
    "                    'to_size': target_size,\n",
    "                    'padding': (start_x, start_y, pad_width, pad_height)\n",
    "                })\n",
    "                resized_pairs += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"Error processing {img_filename}: {e}\")\n",
    "\n",
    "    print(\"Standardization complete:\")\n",
    "    print(f\"- Total images processed: {total_images}\")\n",
    "    print(f\"- Image/mask pairs resized and overwritten: {resized_pairs}\")\n",
    "    print(f\"- Pairs skipped: {skipped}\")\n",
    "    print(f\"- Errors encountered: {errors}\")\n",
    "    print(f\"- Images already at target size: {total_images - resized_pairs - skipped - errors}\")\n",
    "\n",
    "    return modified_files\n",
    "\n",
    "# Run the function and print summary\n",
    "modified_files = standardize_image_dimensions(\n",
    "    img_dir=DATASET_OUTPUT_IMG_PATH,\n",
    "    mask_dir=DATASET_OUTPUT_MASKS_PATH,\n",
    "    target_size=(1280, 1280)\n",
    ")\n",
    "\n",
    "if modified_files:\n",
    "    print(f\"\\nModified {len(modified_files)} file pairs. First 5 examples:\")\n",
    "    for i, file_info in enumerate(modified_files[:5]):\n",
    "        print(f\"{i+1}. {os.path.basename(file_info['img_file'])}: {file_info['from_size']} -> {file_info['to_size']}\")\n",
    "else:\n",
    "    print(\"\\nNo files were modified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 modified files and 496 unmodified files\n",
      "Verifying all 538 image-mask pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0936f95e9304a51944c6a1d6daa220d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verifying files:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Summary:\n",
      "- Total files checked: 538\n",
      "- Successfully verified pairs: 538\n",
      "- Dimension mismatches: 0\n",
      "- Missing masks: 0\n",
      "\n",
      "Generating visualizations for 5 modified samples...\n",
      "Visualization for 24911110_tile_0_19_c476a4 (Modified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 672×1280 → Current: 1280×1280\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/modified_sample_24911110_tile_0_19_c476a4.png\n",
      "--------------------------------------------------\n",
      "Visualization for 25001117_tile_8_19_d29b79 (Modified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 672×1280 → Current: 1280×1280\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/modified_sample_25001117_tile_8_19_d29b79.png\n",
      "--------------------------------------------------\n",
      "Visualization for 24971119_tile_19_9_e55938 (Modified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 1280×672 → Current: 1280×1280\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/modified_sample_24971119_tile_19_9_e55938.png\n",
      "--------------------------------------------------\n",
      "Visualization for 25061123_tile_19_5_1c6023 (Modified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 1280×672 → Current: 1280×1280\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/modified_sample_25061123_tile_19_5_1c6023.png\n",
      "--------------------------------------------------\n",
      "Visualization for 24961114_tile_19_19_53e46d (Modified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 672×672 → Current: 1280×1280\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/modified_sample_24961114_tile_19_19_53e46d.png\n",
      "--------------------------------------------------\n",
      "Successfully created 5 modified sample visualizations\n",
      "\n",
      "Generating visualizations for 3 unmodified samples...\n",
      "Visualization for 25001115_tile_16_7_68c3da (Unmodified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 1280×1280 (no change needed)\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/unmodified_sample_25001115_tile_16_7_68c3da.png\n",
      "--------------------------------------------------\n",
      "Visualization for 24961115_tile_18_15_76d4e5 (Unmodified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 1280×1280 (no change needed)\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/unmodified_sample_24961115_tile_18_15_76d4e5.png\n",
      "--------------------------------------------------\n",
      "Visualization for 24971120_tile_0_18_d8498d (Unmodified):\n",
      "- GeoTIFF dimensions: (1280, 1280)\n",
      "- Mask dimensions: (1280, 1280)\n",
      "- Original: 1280×1280 (no change needed)\n",
      "- Verification image saved to: datasets/supervisely/dataset_processed_20250523-173715/check_dataset/padding_verification/unmodified_sample_24971120_tile_0_18_d8498d.png\n",
      "--------------------------------------------------\n",
      "Successfully created 3 unmodified sample visualizations\n",
      "\n",
      "Final Verification Results:\n",
      "   total_files: 538\n",
      "   verified_files: 538\n",
      "   dimension_mismatches: 0\n",
      "   missing_masks: 0\n",
      "   modified_files_count: 42\n",
      "   unmodified_files_count: 496\n"
     ]
    }
   ],
   "source": [
    "def verify_padding(processed_img_dir, processed_mask_dir, output_dir, show_images=False, modified_files=None, \n",
    "                   modified_sample_count=5, unmodified_sample_count=5):\n",
    "    \"\"\"\n",
    "    Verifies padding consistency for all GeoTIFF and mask pairs.\n",
    "    Provides visualizations showing padding information and formatting.\n",
    "    Saves summary and sample images to the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        processed_img_dir (str): Directory containing processed GeoTIFF images.\n",
    "        processed_mask_dir (str): Directory containing processed mask files.\n",
    "        output_dir (str): Directory to save verification results and visualizations.\n",
    "        show_images (bool): If True, displays images inline. Otherwise, saves and closes them.\n",
    "        modified_files (list): List of dictionaries with information about modified files.\n",
    "        modified_sample_count (int): Number of modified samples to visualize.\n",
    "        unmodified_sample_count (int): Number of unmodified samples to visualize.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary of verification results.\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # List all GeoTIFF files in the image directory\n",
    "    all_tiff_files = [f for f in os.listdir(processed_img_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "    \n",
    "    if not all_tiff_files:\n",
    "        print(\"No GeoTIFF files found for verification.\")\n",
    "        return\n",
    "    \n",
    "    # Build a lookup for modified files and their padding info\n",
    "    modified_info = {}\n",
    "    if modified_files:\n",
    "        for info in modified_files:\n",
    "            filename = os.path.basename(info['img_file'])\n",
    "            modified_info[filename] = info\n",
    "    \n",
    "    modified_paths = set(modified_info.keys())\n",
    "    \n",
    "    # Separate files into modified and unmodified groups\n",
    "    modified_tiff_files = [f for f in all_tiff_files if f in modified_paths]\n",
    "    unmodified_tiff_files = [f for f in all_tiff_files if f not in modified_paths]\n",
    "    \n",
    "    print(f\"Found {len(modified_tiff_files)} modified files and {len(unmodified_tiff_files)} unmodified files\")\n",
    "    \n",
    "    # Initialize counters for verification results\n",
    "    total_files = len(all_tiff_files)\n",
    "    verified_files = 0\n",
    "    dimension_mismatches = 0\n",
    "    missing_masks = 0\n",
    "    \n",
    "    print(f\"Verifying all {total_files} image-mask pairs...\")\n",
    "    \n",
    "    # Check dimensions for all image-mask pairs\n",
    "    for img_filename in tqdm(all_tiff_files, desc=\"Verifying files\"):\n",
    "        img_path = os.path.join(processed_img_dir, img_filename)\n",
    "        img_basename = os.path.splitext(img_filename)[0]\n",
    "        \n",
    "        # Find the corresponding mask file\n",
    "        mask_filename = None\n",
    "        for ext in ['.tif', '.tiff', '.png', '.PNG']:\n",
    "            candidate_mask = img_basename + ext\n",
    "            if os.path.exists(os.path.join(processed_mask_dir, candidate_mask)):\n",
    "                mask_filename = candidate_mask\n",
    "                break\n",
    "        \n",
    "        if not mask_filename:\n",
    "            print(f\"No matching mask found for {img_filename}.\")\n",
    "            missing_masks += 1\n",
    "            continue\n",
    "        \n",
    "        mask_path = os.path.join(processed_mask_dir, mask_filename)\n",
    "        \n",
    "        try:\n",
    "            # Read GeoTIFF image dimensions\n",
    "            with rasterio.open(img_path) as src:\n",
    "                geotiff_height, geotiff_width = src.height, src.width\n",
    "            \n",
    "            # Read mask dimensions\n",
    "            if mask_filename.lower().endswith(('.tif', '.tiff')):\n",
    "                with rasterio.open(mask_path) as mask_src:\n",
    "                    mask_height, mask_width = mask_src.height, mask_src.width\n",
    "            else:\n",
    "                with Image.open(mask_path) as mask_img:\n",
    "                    mask_width, mask_height = mask_img.size\n",
    "            \n",
    "            # Compare dimensions\n",
    "            if (geotiff_height, geotiff_width) != (mask_height, mask_width):\n",
    "                print(f\"Dimension mismatch for {img_basename}: GeoTIFF {geotiff_width}x{geotiff_height}, \"\n",
    "                      f\"Mask {mask_width}x{mask_height}\")\n",
    "                dimension_mismatches += 1\n",
    "            else:\n",
    "                verified_files += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error verifying {img_filename}: {e}\")\n",
    "    \n",
    "    # Print summary of verification\n",
    "    print(\"\\nVerification Summary:\")\n",
    "    print(f\"- Total files checked: {total_files}\")\n",
    "    print(f\"- Successfully verified pairs: {verified_files}\")\n",
    "    print(f\"- Dimension mismatches: {dimension_mismatches}\")\n",
    "    print(f\"- Missing masks: {missing_masks}\")\n",
    "    \n",
    "    def visualize_sample(img_filename, sample_type):\n",
    "        \"\"\"\n",
    "        Visualizes a single image-mask pair, showing the image, mask, and overlay.\n",
    "        For modified files, highlights the original image area.\n",
    "        Saves the visualization to the output directory.\n",
    "\n",
    "        Args:\n",
    "            img_filename (str): Filename of the image to visualize.\n",
    "            sample_type (str): Label for the sample type (\"Modified\" or \"Unmodified\").\n",
    "\n",
    "        Returns:\n",
    "            bool: True if visualization was successful, False otherwise.\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(processed_img_dir, img_filename)\n",
    "        img_basename = os.path.splitext(img_filename)[0]\n",
    "        \n",
    "        # Find the corresponding mask file\n",
    "        mask_filename = None\n",
    "        for ext in ['.tif', '.tiff', '.png', '.PNG']:\n",
    "            candidate_mask = img_basename + ext\n",
    "            if os.path.exists(os.path.join(processed_mask_dir, candidate_mask)):\n",
    "                mask_filename = candidate_mask\n",
    "                break\n",
    "        \n",
    "        if not mask_filename:\n",
    "            print(f\"No mask found for {img_filename}\")\n",
    "            return False\n",
    "        \n",
    "        mask_path = os.path.join(processed_mask_dir, mask_filename)\n",
    "        \n",
    "        try:\n",
    "            # Read GeoTIFF image data\n",
    "            with rasterio.open(img_path) as src:\n",
    "                geotiff_data = src.read(1)\n",
    "            \n",
    "            # Read mask data\n",
    "            if mask_filename.lower().endswith(('.tif', '.tiff')):\n",
    "                with rasterio.open(mask_path) as mask_src:\n",
    "                    mask_data = mask_src.read(1)\n",
    "            else:\n",
    "                mask_data = np.array(Image.open(mask_path))\n",
    "                if len(mask_data.shape) == 3:\n",
    "                    mask_data = mask_data[:, :, 0]\n",
    "            \n",
    "            # Prepare dimension information for display\n",
    "            is_modified = img_filename in modified_paths\n",
    "            if is_modified:\n",
    "                padding_info = modified_info[img_filename]\n",
    "                original_size = padding_info['from_size']\n",
    "                dimension_text = f\"Original: {original_size[0]}×{original_size[1]} → Current: 1280×1280\"\n",
    "            else:\n",
    "                dimension_text = \"Original: 1280×1280 (no change needed)\"\n",
    "            \n",
    "            # Create visualization with three subplots\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            \n",
    "            # Show GeoTIFF image\n",
    "            axes[0].imshow(geotiff_data, cmap='gray')\n",
    "            axes[0].set_title(f\"GeoTIFF: {img_filename}\")\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Show mask image\n",
    "            axes[1].imshow(mask_data, cmap='gray')\n",
    "            axes[1].set_title(f\"Mask: {mask_filename}\")\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Prepare overlay for alignment check\n",
    "            if geotiff_data.max() > geotiff_data.min():\n",
    "                normalized_geotiff = (geotiff_data - geotiff_data.min()) / (geotiff_data.max() - geotiff_data.min())\n",
    "            else:\n",
    "                normalized_geotiff = np.zeros_like(geotiff_data)\n",
    "            \n",
    "            if mask_data.max() > mask_data.min():\n",
    "                normalized_mask = (mask_data - mask_data.min()) / (mask_data.max() - mask_data.min())\n",
    "            else:\n",
    "                normalized_mask = np.zeros_like(mask_data)\n",
    "            \n",
    "            overlay = np.zeros((geotiff_data.shape[0], geotiff_data.shape[1], 3))\n",
    "            overlay[:, :, 0] = normalized_geotiff  # Red channel for GeoTIFF\n",
    "            overlay[:, :, 2] = normalized_mask     # Blue channel for Mask\n",
    "            \n",
    "            axes[2].imshow(overlay)\n",
    "            axes[2].set_title(\"Overlay (purple shows alignment)\")\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            # Draw rectangle for original image area if modified\n",
    "            if is_modified:\n",
    "                padding_info = modified_info[img_filename]\n",
    "                padding = padding_info['padding']  # (start_x, start_y, pad_width, pad_height)\n",
    "                original_size = padding_info['from_size']\n",
    "                \n",
    "                start_x, start_y = padding[0], padding[1]\n",
    "                width, height = original_size\n",
    "                \n",
    "                from matplotlib.patches import Rectangle\n",
    "                rect_style = dict(linewidth=2, edgecolor='yellow', facecolor='none', linestyle='--')\n",
    "                \n",
    "                axes[0].add_patch(Rectangle((start_x, start_y), width, height, **rect_style))\n",
    "                axes[1].add_patch(Rectangle((start_x, start_y), width, height, **rect_style))\n",
    "                axes[2].add_patch(Rectangle((start_x, start_y), width, height, **rect_style))\n",
    "            \n",
    "            plt.suptitle(f\"{sample_type} Sample: {img_basename}\\n{dimension_text}\", fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            save_path = os.path.join(output_dir, f\"{sample_type.lower()}_sample_{img_basename}.png\")\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "            if show_images:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "            \n",
    "            print(f\"Visualization for {img_basename} ({sample_type}):\")\n",
    "            print(f\"- GeoTIFF dimensions: {geotiff_data.shape}\")\n",
    "            print(f\"- Mask dimensions: {mask_data.shape}\")\n",
    "            print(f\"- {dimension_text}\")\n",
    "            print(f\"- Verification image saved to: {save_path}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing {img_filename}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # Visualize a sample of modified files\n",
    "    if modified_sample_count > 0 and modified_tiff_files:\n",
    "        print(f\"\\nGenerating visualizations for {min(modified_sample_count, len(modified_tiff_files))} modified samples...\")\n",
    "        \n",
    "        modified_samples = random.sample(modified_tiff_files, min(modified_sample_count, len(modified_tiff_files)))\n",
    "        \n",
    "        successful_visualizations = 0\n",
    "        for img_filename in modified_samples:\n",
    "            if visualize_sample(img_filename, \"Modified\"):\n",
    "                successful_visualizations += 1\n",
    "        \n",
    "        print(f\"Successfully created {successful_visualizations} modified sample visualizations\")\n",
    "    \n",
    "    # Visualize a sample of unmodified files\n",
    "    if unmodified_sample_count > 0 and unmodified_tiff_files:\n",
    "        print(f\"\\nGenerating visualizations for {min(unmodified_sample_count, len(unmodified_tiff_files))} unmodified samples...\")\n",
    "        \n",
    "        unmodified_samples = random.sample(unmodified_tiff_files, min(unmodified_sample_count, len(unmodified_tiff_files)))\n",
    "        \n",
    "        successful_visualizations = 0\n",
    "        for img_filename in unmodified_samples:\n",
    "            if visualize_sample(img_filename, \"Unmodified\"):\n",
    "                successful_visualizations += 1\n",
    "        \n",
    "        print(f\"Successfully created {successful_visualizations} unmodified sample visualizations\")\n",
    "    \n",
    "    return {\n",
    "        'total_files': total_files,\n",
    "        'verified_files': verified_files, \n",
    "        'dimension_mismatches': dimension_mismatches,\n",
    "        'missing_masks': missing_masks,\n",
    "        'modified_files_count': len(modified_tiff_files),\n",
    "        'unmodified_files_count': len(unmodified_tiff_files)\n",
    "    }\n",
    "\n",
    "# Example usage with improved graphics and summary output\n",
    "verification_results = verify_padding(\n",
    "    processed_img_dir=DATASET_OUTPUT_IMG_PATH,\n",
    "    processed_mask_dir=DATASET_OUTPUT_MASKS_PATH,\n",
    "    output_dir=DATASET_OUTPUT_CHECKS_PATH + \"/padding_verification\",\n",
    "    modified_files=modified_files,\n",
    "    modified_sample_count=5,\n",
    "    unmodified_sample_count=3,\n",
    "    show_images=False\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Verification Results:\")\n",
    "for key, value in verification_results.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-VERIFICATION CLEANUP: REMOVING 100% ZERO FILES\n",
      "============================================================\n",
      "STEP 1: Filter out records with missing files\n",
      "Removed 1 records with missing files\n",
      "After filtering missing files: 538 records\n",
      "\n",
      "STEP 2: Remove 100% zero files and records\n",
      "Starting with 538 records\n",
      "\n",
      "1. Scanning for 100% zero files...\n",
      "   KEEPING: 10_12_8d26a8 (both image and mask have content)\n",
      "   KEEPING: 0_6_9201e5 (both image and mask have content)\n",
      "   KEEPING: 18_4_b35ef3 (both image and mask have content)\n",
      "   Mask is 100% zeros: 1_3_14c592\n",
      "   KEEPING: 1_3_14c592 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 15_17_5212bb\n",
      "   KEEPING: 15_17_5212bb (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 18_16_c9d875\n",
      "   KEEPING: 18_16_c9d875 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 4_3_5bdc96 (both image and mask have content)\n",
      "   KEEPING: 4_8_a4faea (both image and mask have content)\n",
      "   KEEPING: 13_19_d8b3fa (both image and mask have content)\n",
      "   KEEPING: 3_3_878a8d (both image and mask have content)\n",
      "   KEEPING: 19_7_894243 (both image and mask have content)\n",
      "   KEEPING: 13_18_a66e08 (both image and mask have content)\n",
      "   KEEPING: 18_15_76d4e5 (both image and mask have content)\n",
      "   KEEPING: 15_13_77013c (both image and mask have content)\n",
      "   KEEPING: 15_6_7a6487 (both image and mask have content)\n",
      "   KEEPING: 17_18_497745 (both image and mask have content)\n",
      "   KEEPING: 1_8_e4d68c (both image and mask have content)\n",
      "   KEEPING: 18_0_dea25e (both image and mask have content)\n",
      "   KEEPING: 18_16_609b97 (both image and mask have content)\n",
      "   KEEPING: 13_11_8e5b69 (both image and mask have content)\n",
      "   KEEPING: 1_3_651e11 (both image and mask have content)\n",
      "   KEEPING: 9_19_924944 (both image and mask have content)\n",
      "   KEEPING: 11_9_1cf639 (both image and mask have content)\n",
      "   KEEPING: 8_0_253f23 (both image and mask have content)\n",
      "   KEEPING: 14_0_d87048 (both image and mask have content)\n",
      "   KEEPING: 5_13_d0b945 (both image and mask have content)\n",
      "   KEEPING: 17_6_8a7785 (both image and mask have content)\n",
      "   KEEPING: 10_7_751f2f (both image and mask have content)\n",
      "   KEEPING: 7_6_e34429 (both image and mask have content)\n",
      "   KEEPING: 4_11_197599 (both image and mask have content)\n",
      "   KEEPING: 8_7_79a634 (both image and mask have content)\n",
      "   KEEPING: 16_7_c46f2b (both image and mask have content)\n",
      "   KEEPING: 16_18_e984ba (both image and mask have content)\n",
      "   KEEPING: 3_13_af143e (both image and mask have content)\n",
      "   KEEPING: 9_11_60b734 (both image and mask have content)\n",
      "   KEEPING: 18_15_b1aa56 (both image and mask have content)\n",
      "   KEEPING: 4_5_f46c7e (both image and mask have content)\n",
      "   KEEPING: 7_2_67d9df (both image and mask have content)\n",
      "   KEEPING: 16_6_b0c762 (both image and mask have content)\n",
      "   KEEPING: 6_7_3e769f (both image and mask have content)\n",
      "   KEEPING: 8_13_4b4d31 (both image and mask have content)\n",
      "   KEEPING: 3_2_010c9d (both image and mask have content)\n",
      "   KEEPING: 5_18_156ea7 (both image and mask have content)\n",
      "   KEEPING: 5_1_c6c54b (both image and mask have content)\n",
      "   KEEPING: 17_8_bb24cb (both image and mask have content)\n",
      "   KEEPING: 16_5_f5e391 (both image and mask have content)\n",
      "   KEEPING: 13_2_58b019 (both image and mask have content)\n",
      "   KEEPING: 17_1_c4db55 (both image and mask have content)\n",
      "   KEEPING: 2_2_42645e (both image and mask have content)\n",
      "   KEEPING: 19_5_1c6023 (both image and mask have content)\n",
      "   KEEPING: 8_13_deeb7a (both image and mask have content)\n",
      "   KEEPING: 8_15_6a3b90 (both image and mask have content)\n",
      "   KEEPING: 5_0_75afe4 (both image and mask have content)\n",
      "   KEEPING: 8_11_235318 (both image and mask have content)\n",
      "   KEEPING: 15_11_d7f4ea (both image and mask have content)\n",
      "   KEEPING: 9_10_91e10a (both image and mask have content)\n",
      "   KEEPING: 9_8_77f8b8 (both image and mask have content)\n",
      "   KEEPING: 8_3_becc02 (both image and mask have content)\n",
      "   KEEPING: 8_8_e609ee (both image and mask have content)\n",
      "   KEEPING: 2_15_e9abf2 (both image and mask have content)\n",
      "   KEEPING: 0_19_c476a4 (both image and mask have content)\n",
      "   KEEPING: 19_17_1742be (both image and mask have content)\n",
      "   KEEPING: 17_9_61b07b (both image and mask have content)\n",
      "   KEEPING: 8_10_0d33dd (both image and mask have content)\n",
      "   KEEPING: 9_6_e3d635 (both image and mask have content)\n",
      "   KEEPING: 12_15_9957f6 (both image and mask have content)\n",
      "   KEEPING: 4_0_a7afb6 (both image and mask have content)\n",
      "   KEEPING: 16_12_e2a3a9 (both image and mask have content)\n",
      "   KEEPING: 0_2_75b724 (both image and mask have content)\n",
      "   KEEPING: 14_18_e30a94 (both image and mask have content)\n",
      "   KEEPING: 6_1_7b4252 (both image and mask have content)\n",
      "   KEEPING: 12_3_4ba896 (both image and mask have content)\n",
      "   KEEPING: 15_6_a8c9d1 (both image and mask have content)\n",
      "   KEEPING: 10_5_1701a8 (both image and mask have content)\n",
      "   KEEPING: 5_17_bb3a62 (both image and mask have content)\n",
      "   KEEPING: 10_16_b841af (both image and mask have content)\n",
      "   KEEPING: 10_2_4e952b (both image and mask have content)\n",
      "   KEEPING: 11_2_632941 (both image and mask have content)\n",
      "   KEEPING: 0_18_d8498d (both image and mask have content)\n",
      "   KEEPING: 10_6_8c6070 (both image and mask have content)\n",
      "   KEEPING: 15_13_f30f6c (both image and mask have content)\n",
      "   KEEPING: 8_17_4b62ae (both image and mask have content)\n",
      "   KEEPING: 12_4_130694 (both image and mask have content)\n",
      "   KEEPING: 2_18_041a7a (both image and mask have content)\n",
      "   KEEPING: 18_17_b6ad9c (both image and mask have content)\n",
      "   KEEPING: 17_2_f3ab8b (both image and mask have content)\n",
      "   KEEPING: 6_3_50d201 (both image and mask have content)\n",
      "   KEEPING: 17_14_619184 (both image and mask have content)\n",
      "   KEEPING: 15_3_f5389f (both image and mask have content)\n",
      "   KEEPING: 11_4_0bd66c (both image and mask have content)\n",
      "   KEEPING: 13_3_0619aa (both image and mask have content)\n",
      "   KEEPING: 10_4_45188b (both image and mask have content)\n",
      "   KEEPING: 15_4_c7e318 (both image and mask have content)\n",
      "   KEEPING: 12_3_fe57cb (both image and mask have content)\n",
      "   KEEPING: 13_15_c8052d (both image and mask have content)\n",
      "   Mask is 100% zeros: 13_14_47b1f2\n",
      "   KEEPING: 13_14_47b1f2 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 11_5_3c9dc4 (both image and mask have content)\n",
      "   Mask is 100% zeros: 16_12_6e2b70\n",
      "   KEEPING: 16_12_6e2b70 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 16_17_ee6605 (both image and mask have content)\n",
      "   Mask is 100% zeros: 4_17_b09eb4\n",
      "   KEEPING: 4_17_b09eb4 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 0_13_b41956 (both image and mask have content)\n",
      "   KEEPING: 15_1_f6f101 (both image and mask have content)\n",
      "   Mask is 100% zeros: 18_9_ba3084\n",
      "   KEEPING: 18_9_ba3084 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 7_8_cf7375 (both image and mask have content)\n",
      "   KEEPING: 3_8_c81f3f (both image and mask have content)\n",
      "   KEEPING: 1_10_53d4aa (both image and mask have content)\n",
      "   KEEPING: 0_7_d6922e (both image and mask have content)\n",
      "   KEEPING: 16_0_816a7c (both image and mask have content)\n",
      "   KEEPING: 5_18_ca0aa1 (both image and mask have content)\n",
      "   KEEPING: 9_13_066cc7 (both image and mask have content)\n",
      "   KEEPING: 15_10_cc2aa7 (both image and mask have content)\n",
      "   KEEPING: 13_4_dd22f2 (both image and mask have content)\n",
      "   KEEPING: 11_16_698bc1 (both image and mask have content)\n",
      "   KEEPING: 0_19_263a5f (both image and mask have content)\n",
      "   KEEPING: 16_8_307f43 (both image and mask have content)\n",
      "   KEEPING: 17_2_3f5bbe (both image and mask have content)\n",
      "   KEEPING: 17_14_a43675 (both image and mask have content)\n",
      "   KEEPING: 2_7_062423 (both image and mask have content)\n",
      "   KEEPING: 9_15_25e9ee (both image and mask have content)\n",
      "   KEEPING: 18_11_9484b5 (both image and mask have content)\n",
      "   KEEPING: 10_2_1b7cae (both image and mask have content)\n",
      "   KEEPING: 0_3_c91130 (both image and mask have content)\n",
      "   KEEPING: 7_2_1f4183 (both image and mask have content)\n",
      "   KEEPING: 12_11_90cdd0 (both image and mask have content)\n",
      "   KEEPING: 19_10_d691f6 (both image and mask have content)\n",
      "   KEEPING: 13_15_319e10 (both image and mask have content)\n",
      "   KEEPING: 15_7_0d8da2 (both image and mask have content)\n",
      "   KEEPING: 1_7_75beb2 (both image and mask have content)\n",
      "   KEEPING: 12_18_96aa0c (both image and mask have content)\n",
      "   KEEPING: 2_4_f9e046 (both image and mask have content)\n",
      "   KEEPING: 16_4_222920 (both image and mask have content)\n",
      "   KEEPING: 14_16_56f89c (both image and mask have content)\n",
      "   KEEPING: 2_15_8ca4de (both image and mask have content)\n",
      "   KEEPING: 6_0_1b3b21 (both image and mask have content)\n",
      "   KEEPING: 15_17_06ab41 (both image and mask have content)\n",
      "   KEEPING: 5_1_c5ce73 (both image and mask have content)\n",
      "   KEEPING: 10_17_03150e (both image and mask have content)\n",
      "   KEEPING: 6_8_f78ab9 (both image and mask have content)\n",
      "   KEEPING: 1_18_d336b2 (both image and mask have content)\n",
      "   KEEPING: 16_2_81acd6 (both image and mask have content)\n",
      "   KEEPING: 6_6_a2d181 (both image and mask have content)\n",
      "   KEEPING: 15_18_05dfbf (both image and mask have content)\n",
      "   KEEPING: 10_16_604952 (both image and mask have content)\n",
      "   KEEPING: 3_15_66786d (both image and mask have content)\n",
      "   KEEPING: 1_18_643338 (both image and mask have content)\n",
      "   KEEPING: 13_11_c639b2 (both image and mask have content)\n",
      "   KEEPING: 19_6_093000 (both image and mask have content)\n",
      "   KEEPING: 4_13_421aab (both image and mask have content)\n",
      "   KEEPING: 2_13_3477a1 (both image and mask have content)\n",
      "   KEEPING: 14_2_01c8ba (both image and mask have content)\n",
      "   KEEPING: 2_16_efa593 (both image and mask have content)\n",
      "   KEEPING: 5_15_686804 (both image and mask have content)\n",
      "   KEEPING: 15_15_5c0062 (both image and mask have content)\n",
      "   KEEPING: 5_2_ea236b (both image and mask have content)\n",
      "   KEEPING: 5_4_f1b17b (both image and mask have content)\n",
      "   KEEPING: 0_2_834b3b (both image and mask have content)\n",
      "   KEEPING: 16_1_27e50c (both image and mask have content)\n",
      "   KEEPING: 19_18_2170a6 (both image and mask have content)\n",
      "   KEEPING: 19_3_486ee7 (both image and mask have content)\n",
      "   KEEPING: 9_4_7894d0 (both image and mask have content)\n",
      "   KEEPING: 17_1_940441 (both image and mask have content)\n",
      "   KEEPING: 14_8_5e1f28 (both image and mask have content)\n",
      "   KEEPING: 4_1_7ad6ff (both image and mask have content)\n",
      "   KEEPING: 6_7_6931bb (both image and mask have content)\n",
      "   KEEPING: 11_12_0c462f (both image and mask have content)\n",
      "   KEEPING: 17_16_b0d034 (both image and mask have content)\n",
      "   KEEPING: 5_8_7cc499 (both image and mask have content)\n",
      "   KEEPING: 4_15_78112f (both image and mask have content)\n",
      "   KEEPING: 4_13_4964b2 (both image and mask have content)\n",
      "   KEEPING: 6_14_31615d (both image and mask have content)\n",
      "   KEEPING: 16_18_126636 (both image and mask have content)\n",
      "   KEEPING: 11_6_c9441e (both image and mask have content)\n",
      "   KEEPING: 13_3_333e78 (both image and mask have content)\n",
      "   KEEPING: 6_6_5071b0 (both image and mask have content)\n",
      "   KEEPING: 13_14_9ac81e (both image and mask have content)\n",
      "   KEEPING: 9_16_0f8434 (both image and mask have content)\n",
      "   KEEPING: 12_8_253808 (both image and mask have content)\n",
      "   KEEPING: 17_8_493e47 (both image and mask have content)\n",
      "   KEEPING: 10_16_6d2ae5 (both image and mask have content)\n",
      "   KEEPING: 6_4_dd2014 (both image and mask have content)\n",
      "   KEEPING: 3_18_991a9d (both image and mask have content)\n",
      "   KEEPING: 16_9_50b46a (both image and mask have content)\n",
      "   KEEPING: 16_7_68c3da (both image and mask have content)\n",
      "   Mask is 100% zeros: 5_14_fcd06e\n",
      "   KEEPING: 5_14_fcd06e (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 8_10_dc8182 (both image and mask have content)\n",
      "   KEEPING: 0_9_235f1c (both image and mask have content)\n",
      "   KEEPING: 3_5_75bba3 (both image and mask have content)\n",
      "   KEEPING: 11_17_59a466 (both image and mask have content)\n",
      "   KEEPING: 8_13_951142 (both image and mask have content)\n",
      "   KEEPING: 13_7_5e4264 (both image and mask have content)\n",
      "   KEEPING: 12_7_951b46 (both image and mask have content)\n",
      "   Mask is 100% zeros: 13_17_fc1418\n",
      "   KEEPING: 13_17_fc1418 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 17_1_11882d (both image and mask have content)\n",
      "   Mask is 100% zeros: 4_13_2bd653\n",
      "   KEEPING: 4_13_2bd653 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 5_18_7d9690 (both image and mask have content)\n",
      "   Mask is 100% zeros: 16_8_46ad78\n",
      "   KEEPING: 16_8_46ad78 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 1_5_159f48 (both image and mask have content)\n",
      "   KEEPING: 7_14_502868 (both image and mask have content)\n",
      "   Mask is 100% zeros: 19_5_73943b\n",
      "   KEEPING: 19_5_73943b (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 9_1_991a94 (both image and mask have content)\n",
      "   KEEPING: 16_0_e89062 (both image and mask have content)\n",
      "   KEEPING: 8_16_52b793 (both image and mask have content)\n",
      "   KEEPING: 3_16_22036c (both image and mask have content)\n",
      "   KEEPING: 11_2_643e92 (both image and mask have content)\n",
      "   KEEPING: 3_4_ba1938 (both image and mask have content)\n",
      "   KEEPING: 14_5_150247 (both image and mask have content)\n",
      "   KEEPING: 13_14_1fcff2 (both image and mask have content)\n",
      "   KEEPING: 17_11_237356 (both image and mask have content)\n",
      "   KEEPING: 5_19_0d1b2f (both image and mask have content)\n",
      "   Mask is 100% zeros: 15_13_abffa7\n",
      "   KEEPING: 15_13_abffa7 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 18_12_5b3ee4 (both image and mask have content)\n",
      "   KEEPING: 13_19_3d7ae1 (both image and mask have content)\n",
      "   KEEPING: 4_0_26caa7 (both image and mask have content)\n",
      "   Mask is 100% zeros: 14_17_7acccc\n",
      "   KEEPING: 14_17_7acccc (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 19_4_d6a7b0 (both image and mask have content)\n",
      "   KEEPING: 19_14_8fe662 (both image and mask have content)\n",
      "   KEEPING: 9_0_8804cf (both image and mask have content)\n",
      "   KEEPING: 16_19_c8b263 (both image and mask have content)\n",
      "   KEEPING: 18_19_486420 (both image and mask have content)\n",
      "   KEEPING: 18_0_e1ae76 (both image and mask have content)\n",
      "   KEEPING: 15_10_cc6553 (both image and mask have content)\n",
      "   KEEPING: 18_9_5a36b8 (both image and mask have content)\n",
      "   KEEPING: 13_3_b1bd3f (both image and mask have content)\n",
      "   KEEPING: 15_12_c6f4cf (both image and mask have content)\n",
      "   KEEPING: 17_6_988643 (both image and mask have content)\n",
      "   KEEPING: 1_9_619675 (both image and mask have content)\n",
      "   KEEPING: 11_3_cedfd3 (both image and mask have content)\n",
      "   KEEPING: 19_10_32886c (both image and mask have content)\n",
      "   KEEPING: 16_17_db3479 (both image and mask have content)\n",
      "   KEEPING: 1_16_b88c9b (both image and mask have content)\n",
      "   KEEPING: 19_8_7af26e (both image and mask have content)\n",
      "   Mask is 100% zeros: 9_18_a0701e\n",
      "   KEEPING: 9_18_a0701e (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 16_18_00d3e6 (both image and mask have content)\n",
      "   KEEPING: 2_2_5dfcfa (both image and mask have content)\n",
      "   KEEPING: 19_19_52ccbb (both image and mask have content)\n",
      "   KEEPING: 10_2_6f6b09 (both image and mask have content)\n",
      "   Mask is 100% zeros: 4_16_70eeab\n",
      "   KEEPING: 4_16_70eeab (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 15_0_cb7252 (both image and mask have content)\n",
      "   KEEPING: 12_2_55c43d (both image and mask have content)\n",
      "   KEEPING: 1_7_c5b3d8 (both image and mask have content)\n",
      "   KEEPING: 4_0_d79447 (both image and mask have content)\n",
      "   Mask is 100% zeros: 0_13_003a89\n",
      "   KEEPING: 0_13_003a89 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 7_18_47ceb6\n",
      "   KEEPING: 7_18_47ceb6 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 19_19_53e46d (both image and mask have content)\n",
      "   Image is 100% zeros: 1_6_d35657\n",
      "   Mask is 100% zeros: 1_6_d35657\n",
      "   MARKED FOR REMOVAL: 1_6_d35657 (both image and mask are 100% zeros)\n",
      "   KEEPING: 14_15_06eaaa (both image and mask have content)\n",
      "   Mask is 100% zeros: 11_9_c9d59e\n",
      "   KEEPING: 11_9_c9d59e (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 7_7_f09117 (both image and mask have content)\n",
      "   KEEPING: 12_11_a581e8 (both image and mask have content)\n",
      "   KEEPING: 3_11_e8a90f (both image and mask have content)\n",
      "   KEEPING: 11_14_abbd6e (both image and mask have content)\n",
      "   KEEPING: 7_6_d481c4 (both image and mask have content)\n",
      "   KEEPING: 13_16_94d0a7 (both image and mask have content)\n",
      "   KEEPING: 9_10_29c1aa (both image and mask have content)\n",
      "   KEEPING: 2_9_eab511 (both image and mask have content)\n",
      "   KEEPING: 12_16_5bfa38 (both image and mask have content)\n",
      "   KEEPING: 14_2_4c9afb (both image and mask have content)\n",
      "   KEEPING: 15_3_e388dd (both image and mask have content)\n",
      "   KEEPING: 2_7_6f4439 (both image and mask have content)\n",
      "   Mask is 100% zeros: 19_5_22e308\n",
      "   KEEPING: 19_5_22e308 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 2_10_f8a4dc (both image and mask have content)\n",
      "   KEEPING: 16_3_7a3c61 (both image and mask have content)\n",
      "   KEEPING: 1_8_cf2e0c (both image and mask have content)\n",
      "   KEEPING: 16_2_ccf95d (both image and mask have content)\n",
      "   KEEPING: 8_13_17d3bd (both image and mask have content)\n",
      "   KEEPING: 16_13_df88d5 (both image and mask have content)\n",
      "   KEEPING: 5_19_b22102 (both image and mask have content)\n",
      "   KEEPING: 0_10_ee394a (both image and mask have content)\n",
      "   KEEPING: 18_5_f475a0 (both image and mask have content)\n",
      "   KEEPING: 4_6_6fec43 (both image and mask have content)\n",
      "   KEEPING: 5_2_d171e1 (both image and mask have content)\n",
      "   KEEPING: 2_8_e5e3bf (both image and mask have content)\n",
      "   KEEPING: 15_3_5156df (both image and mask have content)\n",
      "   KEEPING: 9_10_d1ad74 (both image and mask have content)\n",
      "   KEEPING: 12_14_ce308f (both image and mask have content)\n",
      "   KEEPING: 9_4_3117b4 (both image and mask have content)\n",
      "   KEEPING: 5_9_e13a9c (both image and mask have content)\n",
      "   KEEPING: 3_2_e8f6d8 (both image and mask have content)\n",
      "   KEEPING: 16_12_41d957 (both image and mask have content)\n",
      "   KEEPING: 15_4_2c9e3e (both image and mask have content)\n",
      "   KEEPING: 4_8_fb9fbc (both image and mask have content)\n",
      "   KEEPING: 7_7_2b90be (both image and mask have content)\n",
      "   KEEPING: 14_17_96e80d (both image and mask have content)\n",
      "   KEEPING: 8_4_3d981c (both image and mask have content)\n",
      "   KEEPING: 9_1_dbecff (both image and mask have content)\n",
      "   KEEPING: 16_2_a84d4d (both image and mask have content)\n",
      "   KEEPING: 5_6_031284 (both image and mask have content)\n",
      "   KEEPING: 16_10_eb231c (both image and mask have content)\n",
      "   Image is 100% zeros: 4_9_e48187\n",
      "   Mask is 100% zeros: 4_9_e48187\n",
      "   MARKED FOR REMOVAL: 4_9_e48187 (both image and mask are 100% zeros)\n",
      "   KEEPING: 0_18_3e6f69 (both image and mask have content)\n",
      "   Image is 100% zeros: 9_15_717aa2\n",
      "   Mask is 100% zeros: 9_15_717aa2\n",
      "   MARKED FOR REMOVAL: 9_15_717aa2 (both image and mask are 100% zeros)\n",
      "   KEEPING: 17_2_f9bcc4 (both image and mask have content)\n",
      "   KEEPING: 16_9_b11959 (both image and mask have content)\n",
      "   Image is 100% zeros: 18_1_c69147\n",
      "   Mask is 100% zeros: 18_1_c69147\n",
      "   MARKED FOR REMOVAL: 18_1_c69147 (both image and mask are 100% zeros)\n",
      "   KEEPING: 0_19_3bacf1 (both image and mask have content)\n",
      "   KEEPING: 5_9_4ffdcf (both image and mask have content)\n",
      "   KEEPING: 17_5_1bb5f4 (both image and mask have content)\n",
      "   KEEPING: 17_9_a2de00 (both image and mask have content)\n",
      "   KEEPING: 9_16_d4a5db (both image and mask have content)\n",
      "   KEEPING: 1_9_dca454 (both image and mask have content)\n",
      "   KEEPING: 6_18_7f53e8 (both image and mask have content)\n",
      "   KEEPING: 11_17_71fed5 (both image and mask have content)\n",
      "   KEEPING: 12_9_c5c2be (both image and mask have content)\n",
      "   KEEPING: 8_15_3c2899 (both image and mask have content)\n",
      "   KEEPING: 14_5_8c654c (both image and mask have content)\n",
      "   Mask is 100% zeros: 3_9_5ba8f7\n",
      "   KEEPING: 3_9_5ba8f7 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 7_15_984566\n",
      "   KEEPING: 7_15_984566 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 15_5_35ee59 (both image and mask have content)\n",
      "   KEEPING: 7_7_de36c9 (both image and mask have content)\n",
      "   Mask is 100% zeros: 17_4_c39b02\n",
      "   KEEPING: 17_4_c39b02 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 14_18_03b4ca (both image and mask have content)\n",
      "   KEEPING: 2_17_b4f962 (both image and mask have content)\n",
      "   KEEPING: 15_9_29c404 (both image and mask have content)\n",
      "   KEEPING: 0_9_54763b (both image and mask have content)\n",
      "   KEEPING: 15_16_834054 (both image and mask have content)\n",
      "   KEEPING: 3_8_0600c4 (both image and mask have content)\n",
      "   KEEPING: 17_4_58919e (both image and mask have content)\n",
      "   KEEPING: 10_6_29a837 (both image and mask have content)\n",
      "   KEEPING: 18_1_cced34 (both image and mask have content)\n",
      "   KEEPING: 5_12_29923c (both image and mask have content)\n",
      "   KEEPING: 5_10_36c93c (both image and mask have content)\n",
      "   KEEPING: 11_2_a44cc6 (both image and mask have content)\n",
      "   KEEPING: 3_17_df1e96 (both image and mask have content)\n",
      "   Mask is 100% zeros: 2_15_c552ae\n",
      "   KEEPING: 2_15_c552ae (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 18_11_e64fbe (both image and mask have content)\n",
      "   KEEPING: 12_13_12dda2 (both image and mask have content)\n",
      "   KEEPING: 7_15_f47d46 (both image and mask have content)\n",
      "   KEEPING: 17_2_bc1286 (both image and mask have content)\n",
      "   KEEPING: 3_16_11a7fb (both image and mask have content)\n",
      "   KEEPING: 4_4_3c7f98 (both image and mask have content)\n",
      "   Mask is 100% zeros: 8_3_1f80ac\n",
      "   KEEPING: 8_3_1f80ac (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 0_18_c29701\n",
      "   KEEPING: 0_18_c29701 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 2_18_ab3051\n",
      "   KEEPING: 2_18_ab3051 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 11_15_028b5c (both image and mask have content)\n",
      "   Mask is 100% zeros: 8_6_13be2f\n",
      "   KEEPING: 8_6_13be2f (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 13_1_83e022 (both image and mask have content)\n",
      "   Mask is 100% zeros: 12_18_22b235\n",
      "   KEEPING: 12_18_22b235 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 19_4_2757f2 (both image and mask have content)\n",
      "   KEEPING: 16_11_df0963 (both image and mask have content)\n",
      "   KEEPING: 8_15_155938 (both image and mask have content)\n",
      "   KEEPING: 12_10_f2cf82 (both image and mask have content)\n",
      "   KEEPING: 4_3_5dc6f8 (both image and mask have content)\n",
      "   KEEPING: 5_13_2921cf (both image and mask have content)\n",
      "   KEEPING: 19_9_e24960 (both image and mask have content)\n",
      "   KEEPING: 16_8_fd3555 (both image and mask have content)\n",
      "   KEEPING: 15_4_6dc643 (both image and mask have content)\n",
      "   KEEPING: 1_18_0caf0d (both image and mask have content)\n",
      "   KEEPING: 0_11_de7b6a (both image and mask have content)\n",
      "   KEEPING: 16_18_1d7d35 (both image and mask have content)\n",
      "   KEEPING: 15_7_fc799d (both image and mask have content)\n",
      "   KEEPING: 2_13_8b6e6f (both image and mask have content)\n",
      "   KEEPING: 12_9_4ca2a8 (both image and mask have content)\n",
      "   KEEPING: 10_0_bccbf1 (both image and mask have content)\n",
      "   KEEPING: 3_10_d297df (both image and mask have content)\n",
      "   KEEPING: 11_17_6c5800 (both image and mask have content)\n",
      "   KEEPING: 8_19_d29b79 (both image and mask have content)\n",
      "   KEEPING: 1_9_e9da49 (both image and mask have content)\n",
      "   KEEPING: 6_13_832b09 (both image and mask have content)\n",
      "   KEEPING: 3_16_76a25c (both image and mask have content)\n",
      "   KEEPING: 13_17_982f7c (both image and mask have content)\n",
      "   KEEPING: 16_19_6c39f9 (both image and mask have content)\n",
      "   KEEPING: 2_12_112004 (both image and mask have content)\n",
      "   KEEPING: 15_5_1766a4 (both image and mask have content)\n",
      "   KEEPING: 4_5_fe10d5 (both image and mask have content)\n",
      "   KEEPING: 6_19_4905ee (both image and mask have content)\n",
      "   KEEPING: 0_11_3c4488 (both image and mask have content)\n",
      "   KEEPING: 16_17_26e83a (both image and mask have content)\n",
      "   KEEPING: 2_11_918e97 (both image and mask have content)\n",
      "   KEEPING: 6_16_e84940 (both image and mask have content)\n",
      "   KEEPING: 0_16_b32b42 (both image and mask have content)\n",
      "   KEEPING: 10_18_b8744b (both image and mask have content)\n",
      "   Mask is 100% zeros: 13_16_1f40c2\n",
      "   KEEPING: 13_16_1f40c2 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 12_16_fe33b4 (both image and mask have content)\n",
      "   KEEPING: 11_18_80fbe1 (both image and mask have content)\n",
      "   KEEPING: 17_15_83f657 (both image and mask have content)\n",
      "   Mask is 100% zeros: 18_15_12722b\n",
      "   KEEPING: 18_15_12722b (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 18_14_96c5c6\n",
      "   KEEPING: 18_14_96c5c6 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 6_13_e63e45 (both image and mask have content)\n",
      "   Mask is 100% zeros: 4_10_42f8f0\n",
      "   KEEPING: 4_10_42f8f0 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 14_5_cdc6dc (both image and mask have content)\n",
      "   Mask is 100% zeros: 3_17_3a940c\n",
      "   KEEPING: 3_17_3a940c (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 19_10_eed0d3\n",
      "   KEEPING: 19_10_eed0d3 (image has content, mask is 100% zeros - acceptable)\n",
      "   Image is 100% zeros: 15_17_94ec0c\n",
      "   Mask is 100% zeros: 15_17_94ec0c\n",
      "   MARKED FOR REMOVAL: 15_17_94ec0c (both image and mask are 100% zeros)\n",
      "   KEEPING: 15_0_8f88d2 (both image and mask have content)\n",
      "   KEEPING: 8_2_0985cb (both image and mask have content)\n",
      "   KEEPING: 19_16_610e59 (both image and mask have content)\n",
      "   KEEPING: 2_2_835caf (both image and mask have content)\n",
      "   KEEPING: 4_1_1984c2 (both image and mask have content)\n",
      "   KEEPING: 3_4_2c6dbf (both image and mask have content)\n",
      "   KEEPING: 17_0_99b529 (both image and mask have content)\n",
      "   KEEPING: 3_1_d28ae1 (both image and mask have content)\n",
      "   KEEPING: 2_4_64947d (both image and mask have content)\n",
      "   KEEPING: 18_16_e1de4c (both image and mask have content)\n",
      "   KEEPING: 16_0_9eda70 (both image and mask have content)\n",
      "   KEEPING: 1_12_2a0c28 (both image and mask have content)\n",
      "   KEEPING: 3_2_cca44e (both image and mask have content)\n",
      "   KEEPING: 13_15_e89c55 (both image and mask have content)\n",
      "   KEEPING: 1_9_654962 (both image and mask have content)\n",
      "   KEEPING: 10_1_e9591b (both image and mask have content)\n",
      "   KEEPING: 15_18_51d0db (both image and mask have content)\n",
      "   KEEPING: 6_1_6e080c (both image and mask have content)\n",
      "   KEEPING: 13_8_512b98 (both image and mask have content)\n",
      "   KEEPING: 7_0_c1288b (both image and mask have content)\n",
      "   KEEPING: 2_7_1b1f57 (both image and mask have content)\n",
      "   KEEPING: 16_7_c2a3d5 (both image and mask have content)\n",
      "   KEEPING: 16_10_0a08bf (both image and mask have content)\n",
      "   KEEPING: 5_11_03865c (both image and mask have content)\n",
      "   KEEPING: 2_2_c6ed30 (both image and mask have content)\n",
      "   KEEPING: 9_19_7ebcec (both image and mask have content)\n",
      "   KEEPING: 13_4_f0a0bf (both image and mask have content)\n",
      "   KEEPING: 6_9_82522e (both image and mask have content)\n",
      "   KEEPING: 4_0_404045 (both image and mask have content)\n",
      "   KEEPING: 17_15_636309 (both image and mask have content)\n",
      "   KEEPING: 15_13_c619ad (both image and mask have content)\n",
      "   KEEPING: 5_18_5405e4 (both image and mask have content)\n",
      "   KEEPING: 4_0_1a6a26 (both image and mask have content)\n",
      "   KEEPING: 9_18_b59fe5 (both image and mask have content)\n",
      "   Mask is 100% zeros: 9_6_4c747e\n",
      "   KEEPING: 9_6_4c747e (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 2_9_2489fe (both image and mask have content)\n",
      "   KEEPING: 7_9_fb34cf (both image and mask have content)\n",
      "   KEEPING: 3_18_e0bd40 (both image and mask have content)\n",
      "   KEEPING: 12_5_2036bc (both image and mask have content)\n",
      "   KEEPING: 13_5_8c5a32 (both image and mask have content)\n",
      "   KEEPING: 9_7_f011fa (both image and mask have content)\n",
      "   KEEPING: 8_7_b29ccd (both image and mask have content)\n",
      "   Mask is 100% zeros: 17_4_52cb42\n",
      "   KEEPING: 17_4_52cb42 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 6_15_3ff73c\n",
      "   KEEPING: 6_15_3ff73c (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 19_8_067ade\n",
      "   KEEPING: 19_8_067ade (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 17_12_4a9905 (both image and mask have content)\n",
      "   KEEPING: 11_18_e52a60 (both image and mask have content)\n",
      "   KEEPING: 7_9_56b55b (both image and mask have content)\n",
      "   KEEPING: 3_9_c693e2 (both image and mask have content)\n",
      "   KEEPING: 13_13_f2d1d4 (both image and mask have content)\n",
      "   KEEPING: 12_3_88e83b (both image and mask have content)\n",
      "   KEEPING: 6_10_06ad3e (both image and mask have content)\n",
      "   KEEPING: 12_11_5c0a00 (both image and mask have content)\n",
      "   KEEPING: 17_1_bbc94e (both image and mask have content)\n",
      "   KEEPING: 10_13_55bd29 (both image and mask have content)\n",
      "   KEEPING: 7_19_34c1bf (both image and mask have content)\n",
      "   KEEPING: 2_17_d313cf (both image and mask have content)\n",
      "   KEEPING: 1_5_12a135 (both image and mask have content)\n",
      "   KEEPING: 14_18_843918 (both image and mask have content)\n",
      "   KEEPING: 15_5_75acac (both image and mask have content)\n",
      "   KEEPING: 11_6_32f7af (both image and mask have content)\n",
      "   KEEPING: 13_10_ad9733 (both image and mask have content)\n",
      "   KEEPING: 19_16_dc9a54 (both image and mask have content)\n",
      "   KEEPING: 2_9_cc2572 (both image and mask have content)\n",
      "   KEEPING: 15_11_88568b (both image and mask have content)\n",
      "   KEEPING: 13_5_8c8469 (both image and mask have content)\n",
      "   KEEPING: 13_2_5950d2 (both image and mask have content)\n",
      "   KEEPING: 5_4_bab76a (both image and mask have content)\n",
      "   KEEPING: 10_8_4b6495 (both image and mask have content)\n",
      "   KEEPING: 17_0_027bcc (both image and mask have content)\n",
      "   KEEPING: 11_13_8c5d46 (both image and mask have content)\n",
      "   KEEPING: 2_4_e68479 (both image and mask have content)\n",
      "   KEEPING: 2_9_8afa14 (both image and mask have content)\n",
      "   KEEPING: 11_18_ac7623 (both image and mask have content)\n",
      "   KEEPING: 12_10_fbf1be (both image and mask have content)\n",
      "   KEEPING: 7_1_496f02 (both image and mask have content)\n",
      "   KEEPING: 6_17_256755 (both image and mask have content)\n",
      "   KEEPING: 1_12_878fd1 (both image and mask have content)\n",
      "   KEEPING: 6_4_ce9259 (both image and mask have content)\n",
      "   KEEPING: 16_12_db0d21 (both image and mask have content)\n",
      "   KEEPING: 6_19_284362 (both image and mask have content)\n",
      "   KEEPING: 5_5_6afed1 (both image and mask have content)\n",
      "   KEEPING: 10_16_dc45c0 (both image and mask have content)\n",
      "   KEEPING: 1_8_85f51e (both image and mask have content)\n",
      "   KEEPING: 3_7_e3883a (both image and mask have content)\n",
      "   KEEPING: 15_1_89e768 (both image and mask have content)\n",
      "   Mask is 100% zeros: 2_1_c5b199\n",
      "   KEEPING: 2_1_c5b199 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 9_16_637cf7 (both image and mask have content)\n",
      "   KEEPING: 5_7_99c229 (both image and mask have content)\n",
      "   KEEPING: 18_4_1ea4b9 (both image and mask have content)\n",
      "   Image is 100% zeros: 14_6_cc7d0d\n",
      "   Mask is 100% zeros: 14_6_cc7d0d\n",
      "   MARKED FOR REMOVAL: 14_6_cc7d0d (both image and mask are 100% zeros)\n",
      "   KEEPING: 17_8_e4da92 (both image and mask have content)\n",
      "   KEEPING: 0_11_a3fb96 (both image and mask have content)\n",
      "   KEEPING: 1_17_e37ef8 (both image and mask have content)\n",
      "   KEEPING: 15_17_f06b8b (both image and mask have content)\n",
      "   KEEPING: 14_7_b86707 (both image and mask have content)\n",
      "   Image is 100% zeros: 16_18_6da6db\n",
      "   Mask is 100% zeros: 16_18_6da6db\n",
      "   MARKED FOR REMOVAL: 16_18_6da6db (both image and mask are 100% zeros)\n",
      "   KEEPING: 0_12_50356f (both image and mask have content)\n",
      "   KEEPING: 0_13_5af324 (both image and mask have content)\n",
      "   KEEPING: 10_6_eecedc (both image and mask have content)\n",
      "   KEEPING: 18_2_5ce11a (both image and mask have content)\n",
      "   KEEPING: 13_8_29f213 (both image and mask have content)\n",
      "   Image is 100% zeros: 16_2_2d7981\n",
      "   Mask is 100% zeros: 16_2_2d7981\n",
      "   MARKED FOR REMOVAL: 16_2_2d7981 (both image and mask are 100% zeros)\n",
      "   KEEPING: 6_11_4ee69d (both image and mask have content)\n",
      "   KEEPING: 19_9_e55938 (both image and mask have content)\n",
      "   KEEPING: 17_19_100c5a (both image and mask have content)\n",
      "   KEEPING: 0_5_e1e034 (both image and mask have content)\n",
      "   KEEPING: 6_4_b1ab72 (both image and mask have content)\n",
      "   KEEPING: 12_6_265345 (both image and mask have content)\n",
      "   KEEPING: 0_10_aaff35 (both image and mask have content)\n",
      "   KEEPING: 15_0_1792b2 (both image and mask have content)\n",
      "   KEEPING: 1_6_e46af6 (both image and mask have content)\n",
      "   KEEPING: 11_8_51e0da (both image and mask have content)\n",
      "   Mask is 100% zeros: 16_18_987fed\n",
      "   KEEPING: 16_18_987fed (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 11_1_048b29 (both image and mask have content)\n",
      "   KEEPING: 15_19_373a1d (both image and mask have content)\n",
      "   KEEPING: 15_4_ea438d (both image and mask have content)\n",
      "   KEEPING: 3_1_8d3072 (both image and mask have content)\n",
      "   KEEPING: 0_19_6345d6 (both image and mask have content)\n",
      "   KEEPING: 14_19_fe2f34 (both image and mask have content)\n",
      "   KEEPING: 17_3_95b4ae (both image and mask have content)\n",
      "   KEEPING: 5_7_5cb752 (both image and mask have content)\n",
      "   KEEPING: 8_10_abc4aa (both image and mask have content)\n",
      "   Mask is 100% zeros: 0_0_e80490\n",
      "   KEEPING: 0_0_e80490 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 16_0_a7ee08 (both image and mask have content)\n",
      "   KEEPING: 15_13_11010e (both image and mask have content)\n",
      "   KEEPING: 11_10_aca611 (both image and mask have content)\n",
      "   KEEPING: 5_6_eaf656 (both image and mask have content)\n",
      "   KEEPING: 10_2_fc2625 (both image and mask have content)\n",
      "   KEEPING: 13_10_2b79a2 (both image and mask have content)\n",
      "   KEEPING: 0_1_9866d2 (both image and mask have content)\n",
      "   KEEPING: 5_5_e3173b (both image and mask have content)\n",
      "   KEEPING: 5_3_322356 (both image and mask have content)\n",
      "   KEEPING: 0_2_168b12 (both image and mask have content)\n",
      "   KEEPING: 18_15_51772e (both image and mask have content)\n",
      "   KEEPING: 16_17_281e90 (both image and mask have content)\n",
      "   KEEPING: 1_1_d0ed0f (both image and mask have content)\n",
      "   KEEPING: 16_15_378625 (both image and mask have content)\n",
      "   Mask is 100% zeros: 18_6_793cc1\n",
      "   KEEPING: 18_6_793cc1 (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 17_17_4da21e\n",
      "   KEEPING: 17_17_4da21e (image has content, mask is 100% zeros - acceptable)\n",
      "   Mask is 100% zeros: 17_6_f0afaf\n",
      "   KEEPING: 17_6_f0afaf (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 7_6_309166 (both image and mask have content)\n",
      "   Mask is 100% zeros: 10_7_9b9f86\n",
      "   KEEPING: 10_7_9b9f86 (image has content, mask is 100% zeros - acceptable)\n",
      "   KEEPING: 14_4_0973b3 (both image and mask have content)\n",
      "   KEEPING: 10_8_fd3477 (both image and mask have content)\n",
      "   KEEPING: 10_9_53e3f3 (both image and mask have content)\n",
      "   KEEPING: 2_4_3ff5a7 (both image and mask have content)\n",
      "   KEEPING: 2_5_d310ba (both image and mask have content)\n",
      "   KEEPING: 3_14_1bf395 (both image and mask have content)\n",
      "   KEEPING: 3_15_86ce23 (both image and mask have content)\n",
      "   KEEPING: 3_4_b3ad65 (both image and mask have content)\n",
      "   KEEPING: 3_5_677ebf (both image and mask have content)\n",
      "   KEEPING: 3_6_9b5376 (both image and mask have content)\n",
      "   KEEPING: 4_4_6684a3 (both image and mask have content)\n",
      "   KEEPING: 4_5_cfeb4f (both image and mask have content)\n",
      "\n",
      "2. Found 8 records where image is 100% zeros\n",
      "   Records to remove: ['1_6_d35657', '4_9_e48187', '9_15_717aa2', '18_1_c69147', '15_17_94ec0c', '14_6_cc7d0d', '16_18_6da6db', '16_2_2d7981']\n",
      "   Note: Removing pairs ONLY when image is 100% zeros (mask state doesn't matter)\n",
      "\n",
      "3. Deleting 16 files from disk...\n",
      "   Deleted: 24981115_tile_1_6_d35657.tif\n",
      "   Deleted: 24981115_tile_1_6_d35657.tif\n",
      "   Deleted: 24871112_tile_4_9_e48187.tif\n",
      "   Deleted: 24871112_tile_4_9_e48187.tif\n",
      "   Deleted: 24961114_tile_9_15_717aa2.tif\n",
      "   Deleted: 24961114_tile_9_15_717aa2.tif\n",
      "   Deleted: 25031120_tile_18_1_c69147.tif\n",
      "   Deleted: 25031120_tile_18_1_c69147.tif\n",
      "   Deleted: 24911111_tile_15_17_94ec0c.tif\n",
      "   Deleted: 24911111_tile_15_17_94ec0c.tif\n",
      "   Deleted: 24971117_tile_14_6_cc7d0d.tif\n",
      "   Deleted: 24971117_tile_14_6_cc7d0d.tif\n",
      "   Deleted: 24951116_tile_16_18_6da6db.tif\n",
      "   Deleted: 24951116_tile_16_18_6da6db.tif\n",
      "   Deleted: 24891118_tile_16_2_2d7981.tif\n",
      "   Deleted: 24891118_tile_16_2_2d7981.tif\n",
      "   Successfully deleted 16 files\n",
      "\n",
      "4. Removing 8 records from dataframe...\n",
      "   Dataframe now has 530 records\n",
      "\n",
      "5. Cleanup summary:\n",
      "   Original records: 538\n",
      "   Records removed: 8\n",
      "   Final records: 530\n",
      "   Files deleted: 16\n",
      "\n",
      "STEP 3: Running final verification on cleaned dataset\n",
      "Records going into verification: 530\n",
      "RUNNING FINAL VERIFICATION CHECKS (NO ZERO CHECK)\n",
      "==================================================\n",
      "\n",
      "0. Initialized validation_processing column for 530 records\n",
      "\n",
      "1. Verifying all referenced files exist...\n",
      "   All 530 image and mask files exist\n",
      "\n",
      "2. Verifying file dimensions are 1280x1280...\n",
      "   Sample check: All 10 files have correct 1280x1280 dimensions\n",
      "\n",
      "3. Validating critical columns...\n",
      "   All required columns present with no null values\n",
      "\n",
      "4. Validating geometries...\n",
      "   All 530 geometries are valid\n",
      "\n",
      "5. Verifying directory structure...\n",
      "   Directory structure correct: 530 expected images, 530 expected masks\n",
      "\n",
      "6. Checking basic data integrity...\n",
      "   Dataset integrity OK: 530 records, 1.3 MB\n",
      "\n",
      "7. Zero content check: SKIPPED (already done in preprocessing)\n",
      "\n",
      "8. Checking for duplicate images...\n",
      "   Found 0 duplicate groups affecting 0 files\n",
      "\n",
      "9. Validation summary...\n",
      "   Records marked 'ok': 530\n",
      "   Records marked 'ko': 0\n",
      "   Success rate: 100.0%\n",
      "\n",
      "==================================================\n",
      "ALL VERIFICATION CHECKS PASSED\n",
      "Dataset validated: 530 OK, 0 KO\n",
      "Dataset is ready for saving\n",
      "==================================================\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS AFTER CLEANUP AND VERIFICATION\n",
      "============================================================\n",
      "Final validation counts:\n",
      "validation_processing\n",
      "ok    530\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset ready for saving: 530 total records\n",
      "High-quality records: 530\n"
     ]
    }
   ],
   "source": [
    "# Remove files that are 100% zeros and update the dataset accordingly\n",
    "print(\"PRE-VERIFICATION CLEANUP: REMOVING 100% ZERO FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def remove_zero_files_and_records(gdf_dataset, dataset_output_img_path, dataset_output_masks_path):\n",
    "    \"\"\"\n",
    "    Remove image and mask files that are 100% zeros, and remove corresponding dataframe records.\n",
    "    This is done before the final verification to clean up the dataset.\n",
    "    \n",
    "    Args:\n",
    "        gdf_dataset: The GeoDataFrame with file paths.\n",
    "        dataset_output_img_path: Path to processed images directory.\n",
    "        dataset_output_masks_path: Path to processed masks directory.\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned GeoDataFrame with zero-content records removed.\n",
    "    \"\"\"\n",
    "    print(f\"Starting with {len(gdf_dataset)} records\")\n",
    "    gdf_cleaned = gdf_dataset.copy()\n",
    "    zero_files_to_remove = []\n",
    "    files_deleted = []\n",
    "    records_to_remove = []\n",
    "    print(\"\\nScanning for 100% zero files...\")\n",
    "\n",
    "    for idx, row in gdf_cleaned.iterrows():\n",
    "        img_path = row.get('processed_img_path_tif')\n",
    "        mask_path = row.get('processed_mask_path_tif')\n",
    "        tile_id = row['tile_id']\n",
    "        img_all_zero = False\n",
    "        mask_all_zero = False\n",
    "        should_remove = False\n",
    "\n",
    "        # Check if image is all zeros\n",
    "        if pd.notna(img_path) and os.path.exists(img_path):\n",
    "            try:\n",
    "                with rasterio.open(img_path) as src:\n",
    "                    img_data = src.read(1)\n",
    "                    if np.all(img_data == 0):\n",
    "                        img_all_zero = True\n",
    "                        print(f\"   Image is 100% zeros: {tile_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Error reading image {tile_id}: {e}\")\n",
    "                should_remove = True\n",
    "\n",
    "        # Check if mask is all zeros\n",
    "        if pd.notna(mask_path) and os.path.exists(mask_path):\n",
    "            try:\n",
    "                with rasterio.open(mask_path) as src:\n",
    "                    mask_data = src.read(1)\n",
    "                    if np.all(mask_data == 0):\n",
    "                        mask_all_zero = True\n",
    "                        print(f\"   Mask is 100% zeros: {tile_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Error reading mask {tile_id}: {e}\")\n",
    "                should_remove = True\n",
    "\n",
    "        # Remove if image is all zeros or if there was a read error\n",
    "        if img_all_zero or should_remove:\n",
    "            zero_files_to_remove.append(tile_id)\n",
    "            records_to_remove.append(idx)\n",
    "            if img_all_zero and mask_all_zero:\n",
    "                print(f\"   Marked for removal: {tile_id} (both image and mask are 100% zeros)\")\n",
    "            elif img_all_zero and not mask_all_zero:\n",
    "                print(f\"   Marked for removal: {tile_id} (image is 100% zeros, removing both)\")\n",
    "            elif should_remove:\n",
    "                print(f\"   Marked for removal: {tile_id} (file read errors)\")\n",
    "            if pd.notna(img_path) and os.path.exists(img_path):\n",
    "                files_deleted.append(img_path)\n",
    "            if pd.notna(mask_path) and os.path.exists(mask_path):\n",
    "                files_deleted.append(mask_path)\n",
    "        else:\n",
    "            if not img_all_zero and mask_all_zero:\n",
    "                print(f\"   Keeping: {tile_id} (image has content, mask is 100% zeros - acceptable)\")\n",
    "            elif not img_all_zero and not mask_all_zero:\n",
    "                print(f\"   Keeping: {tile_id} (both image and mask have content)\")\n",
    "\n",
    "    print(f\"\\nFound {len(zero_files_to_remove)} records where image is 100% zeros\")\n",
    "    if zero_files_to_remove:\n",
    "        print(f\"   Records to remove: {zero_files_to_remove}\")\n",
    "        print(\"   Removing pairs only when image is 100% zeros (mask state doesn't matter)\")\n",
    "\n",
    "    # Delete files from disk\n",
    "    print(f\"\\nDeleting {len(files_deleted)} files from disk...\")\n",
    "    deleted_count = 0\n",
    "    delete_errors = 0\n",
    "    for file_path in files_deleted:\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                deleted_count += 1\n",
    "                print(f\"   Deleted: {os.path.basename(file_path)}\")\n",
    "            else:\n",
    "                print(f\"   File already missing: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error deleting {os.path.basename(file_path)}: {e}\")\n",
    "            delete_errors += 1\n",
    "\n",
    "    print(f\"   Successfully deleted {deleted_count} files\")\n",
    "    if delete_errors > 0:\n",
    "        print(f\"   Failed to delete {delete_errors} files\")\n",
    "\n",
    "    # Remove records from dataframe\n",
    "    if records_to_remove:\n",
    "        print(f\"\\nRemoving {len(records_to_remove)} records from dataframe...\")\n",
    "        gdf_cleaned = gdf_cleaned.drop(records_to_remove)\n",
    "        gdf_cleaned = gdf_cleaned.reset_index(drop=True)\n",
    "        print(f\"   Dataframe now has {len(gdf_cleaned)} records\")\n",
    "    else:\n",
    "        print(\"\\nNo records to remove from dataframe\")\n",
    "\n",
    "    # Cleanup summary\n",
    "    print(\"\\nCleanup summary:\")\n",
    "    print(f\"   Original records: {len(gdf_dataset)}\")\n",
    "    print(f\"   Records removed: {len(records_to_remove)}\")\n",
    "    print(f\"   Final records: {len(gdf_cleaned)}\")\n",
    "    print(f\"   Files deleted: {deleted_count}\")\n",
    "\n",
    "    return gdf_cleaned\n",
    "\n",
    "# Filter out records with missing files\n",
    "print(\"Filtering out records with missing files\")\n",
    "gdf_dataset_filtered = gdf_dataset.copy()\n",
    "missing_file_records = []\n",
    "for idx, row in gdf_dataset_filtered.iterrows():\n",
    "    img_path = row.get('processed_img_path_tif')\n",
    "    mask_path = row.get('processed_mask_path_tif')\n",
    "    img_exists = pd.notna(img_path) and os.path.exists(img_path)\n",
    "    mask_exists = pd.notna(mask_path) and os.path.exists(mask_path)\n",
    "    if not (img_exists and mask_exists):\n",
    "        missing_file_records.append(idx)\n",
    "\n",
    "if missing_file_records:\n",
    "    gdf_dataset_filtered = gdf_dataset_filtered.drop(missing_file_records)\n",
    "    print(f\"Removed {len(missing_file_records)} records with missing files\")\n",
    "else:\n",
    "    print(\"No records with missing files found\")\n",
    "\n",
    "print(f\"After filtering missing files: {len(gdf_dataset_filtered)} records\")\n",
    "\n",
    "# Remove 100% zero files and their records\n",
    "print(\"\\nRemoving 100% zero files and records\")\n",
    "gdf_dataset_cleaned = remove_zero_files_and_records(\n",
    "    gdf_dataset=gdf_dataset_filtered,\n",
    "    dataset_output_img_path=DATASET_OUTPUT_IMG_PATH,\n",
    "    dataset_output_masks_path=DATASET_OUTPUT_MASKS_PATH\n",
    ")\n",
    "\n",
    "# Run final verification on cleaned dataset\n",
    "print(\"\\nRunning final verification on cleaned dataset\")\n",
    "print(f\"Records going into verification: {len(gdf_dataset_cleaned)}\")\n",
    "\n",
    "def final_verification_checks_no_zeros(gdf_dataset, dataset_output_img_path, dataset_output_masks_path):\n",
    "    \"\"\"\n",
    "    Perform final verification checks on the dataset.\n",
    "    Zero-content checking is skipped as it was already done in preprocessing.\n",
    "    \"\"\"\n",
    "    print(\"RUNNING FINAL VERIFICATION CHECKS (NO ZERO CHECK)\")\n",
    "    print(\"=\" * 50)\n",
    "    gdf_dataset = gdf_dataset.copy()\n",
    "    gdf_dataset['validation_processing'] = 'ok'\n",
    "    print(f\"\\nInitialized validation_processing column for {len(gdf_dataset)} records\")\n",
    "\n",
    "    # Verify all referenced files exist\n",
    "    print(\"\\nVerifying all referenced files exist...\")\n",
    "    missing_images = []\n",
    "    missing_masks = []\n",
    "    for idx, row in gdf_dataset.iterrows():\n",
    "        img_path = row.get('processed_img_path_tif')\n",
    "        if pd.notna(img_path) and not os.path.exists(img_path):\n",
    "            missing_images.append(row['tile_id'])\n",
    "            gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "        mask_path = row.get('processed_mask_path_tif')\n",
    "        if pd.notna(mask_path) and not os.path.exists(mask_path):\n",
    "            missing_masks.append(row['tile_id'])\n",
    "            gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "    assert len(missing_images) == 0, f\"Missing image files for tiles: {missing_images[:10]}\"\n",
    "    assert len(missing_masks) == 0, f\"Missing mask files for tiles: {missing_masks[:10]}\"\n",
    "    print(f\"   All {len(gdf_dataset)} image and mask files exist\")\n",
    "\n",
    "    # Check file dimensions\n",
    "    print(\"\\nVerifying file dimensions are 1280x1280...\")\n",
    "    target_size = (1280, 1280)\n",
    "    dimension_errors = []\n",
    "    sample_size = min(10, len(gdf_dataset))\n",
    "    sample_indices = np.random.choice(len(gdf_dataset), sample_size, replace=False)\n",
    "    for idx in sample_indices:\n",
    "        row = gdf_dataset.iloc[idx]\n",
    "        tile_id = row['tile_id']\n",
    "        img_path = row.get('processed_img_path_tif')\n",
    "        if pd.notna(img_path):\n",
    "            with rasterio.open(img_path) as src:\n",
    "                if (src.width, src.height) != target_size:\n",
    "                    dimension_errors.append(f\"Image {tile_id}: {src.width}x{src.height}\")\n",
    "                    gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "        mask_path = row.get('processed_mask_path_tif')\n",
    "        if pd.notna(mask_path):\n",
    "            with rasterio.open(mask_path) as mask_src:\n",
    "                if (mask_src.width, mask_src.height) != target_size:\n",
    "                    dimension_errors.append(f\"Mask {tile_id}: {mask_src.width}x{mask_src.height}\")\n",
    "                    gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "    assert len(dimension_errors) == 0, f\"Dimension errors found: {dimension_errors}\"\n",
    "    print(f\"   Sample check: All {sample_size} files have correct 1280x1280 dimensions\")\n",
    "\n",
    "    # Validate critical columns\n",
    "    print(\"\\nValidating critical columns...\")\n",
    "    required_columns = ['tile_id', 'processed_img_path_tif', 'processed_mask_path_tif']\n",
    "    for col in required_columns:\n",
    "        assert col in gdf_dataset.columns, f\"Required column missing: {col}\"\n",
    "        null_count = gdf_dataset[col].isnull().sum()\n",
    "        assert null_count == 0, f\"Found {null_count} null values in required column: {col}\"\n",
    "    print(\"   All required columns present with no null values\")\n",
    "\n",
    "    # Validate geometries\n",
    "    print(\"\\nValidating geometries...\")\n",
    "    if 'geometry' in gdf_dataset.columns:\n",
    "        null_geoms = gdf_dataset['geometry'].isnull().sum()\n",
    "        assert null_geoms == 0, f\"Found {null_geoms} null geometries\"\n",
    "        invalid_geoms = []\n",
    "        for idx, row in gdf_dataset.iterrows():\n",
    "            if not row['geometry'].is_valid:\n",
    "                invalid_geoms.append(row['tile_id'])\n",
    "                gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "        assert len(invalid_geoms) == 0, f\"Invalid geometries found for tiles: {invalid_geoms[:10]}\"\n",
    "        print(f\"   All {len(gdf_dataset)} geometries are valid\")\n",
    "\n",
    "    # Verify directory structure\n",
    "    print(\"\\nVerifying directory structure...\")\n",
    "    assert os.path.exists(dataset_output_img_path), f\"Image directory does not exist: {dataset_output_img_path}\"\n",
    "    assert os.path.exists(dataset_output_masks_path), f\"Mask directory does not exist: {dataset_output_masks_path}\"\n",
    "    expected_img_files = set()\n",
    "    expected_mask_files = set()\n",
    "    for idx, row in gdf_dataset.iterrows():\n",
    "        img_path = row.get('processed_img_path_tif')\n",
    "        mask_path = row.get('processed_mask_path_tif')\n",
    "        if pd.notna(img_path):\n",
    "            expected_img_files.add(os.path.basename(img_path))\n",
    "        if pd.notna(mask_path):\n",
    "            expected_mask_files.add(os.path.basename(mask_path))\n",
    "    actual_img_files = set([f for f in os.listdir(dataset_output_img_path) if f.endswith(('.tif', '.tiff'))])\n",
    "    actual_mask_files = set([f for f in os.listdir(dataset_output_masks_path) if f.endswith(('.tif', '.tiff'))])\n",
    "    missing_expected_imgs = expected_img_files - actual_img_files\n",
    "    missing_expected_masks = expected_mask_files - actual_mask_files\n",
    "    assert len(missing_expected_imgs) == 0, f\"Expected image files missing: {list(missing_expected_imgs)[:5]}\"\n",
    "    assert len(missing_expected_masks) == 0, f\"Expected mask files missing: {list(missing_expected_masks)[:5]}\"\n",
    "    print(f\"   Directory structure correct: {len(expected_img_files)} expected images, {len(expected_mask_files)} expected masks\")\n",
    "\n",
    "    # Check basic data integrity\n",
    "    print(\"\\nChecking basic data integrity...\")\n",
    "    empty_rows = gdf_dataset.isnull().all(axis=1).sum()\n",
    "    assert empty_rows == 0, f\"Found {empty_rows} completely empty rows\"\n",
    "    assert len(gdf_dataset) > 0, \"Dataset is empty\"\n",
    "    memory_mb = gdf_dataset.memory_usage(deep=True).sum() / 1024**2\n",
    "    assert memory_mb < 1000, f\"Dataset unusually large: {memory_mb:.1f} MB\"\n",
    "    print(f\"   Dataset integrity OK: {len(gdf_dataset)} records, {memory_mb:.1f} MB\")\n",
    "\n",
    "    # Zero content check skipped (already done)\n",
    "    print(\"\\nZero content check: SKIPPED (already done in preprocessing)\")\n",
    "\n",
    "    # Check for duplicate images\n",
    "    print(\"\\nChecking for duplicate images...\")\n",
    "    image_hashes = {}\n",
    "    duplicate_groups = []\n",
    "    for idx, row in gdf_dataset.iterrows():\n",
    "        img_path = row.get('processed_img_path_tif')\n",
    "        tile_id = row['tile_id']\n",
    "        if pd.notna(img_path) and os.path.exists(img_path):\n",
    "            try:\n",
    "                with rasterio.open(img_path) as src:\n",
    "                    img_data = src.read()\n",
    "                    img_hash = hash(img_data.tobytes())\n",
    "                    if img_hash in image_hashes:\n",
    "                        if len(image_hashes[img_hash]) == 1:\n",
    "                            duplicate_groups.append(image_hashes[img_hash] + [tile_id])\n",
    "                        else:\n",
    "                            for group in duplicate_groups:\n",
    "                                if image_hashes[img_hash][0] in group:\n",
    "                                    group.append(tile_id)\n",
    "                                    break\n",
    "                        image_hashes[img_hash].append(tile_id)\n",
    "                    else:\n",
    "                        image_hashes[img_hash] = [tile_id]\n",
    "            except Exception as e:\n",
    "                print(f\"   Error processing image {tile_id}: {e}\")\n",
    "                gdf_dataset.loc[idx, 'validation_processing'] = 'ko'\n",
    "    duplicate_count = 0\n",
    "    for group in duplicate_groups:\n",
    "        for tile_id in group:\n",
    "            tile_idx = gdf_dataset[gdf_dataset['tile_id'] == tile_id].index[0]\n",
    "            gdf_dataset.loc[tile_idx, 'validation_processing'] = 'ko'\n",
    "            duplicate_count += 1\n",
    "    print(f\"   Found {len(duplicate_groups)} duplicate groups affecting {duplicate_count} files\")\n",
    "    if duplicate_groups:\n",
    "        print(f\"   Example duplicate group: {duplicate_groups[0]}\")\n",
    "\n",
    "    # Validation summary\n",
    "    print(\"\\nValidation summary...\")\n",
    "    validation_counts = gdf_dataset['validation_processing'].value_counts()\n",
    "    ok_count = validation_counts.get('ok', 0)\n",
    "    ko_count = validation_counts.get('ko', 0)\n",
    "    print(f\"   Records marked 'ok': {ok_count}\")\n",
    "    print(f\"   Records marked 'ko': {ko_count}\")\n",
    "    print(f\"   Success rate: {ok_count/len(gdf_dataset)*100:.1f}%\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ALL VERIFICATION CHECKS PASSED\")\n",
    "    print(f\"Dataset validated: {ok_count} OK, {ko_count} KO\")\n",
    "    print(\"Dataset is ready for saving\")\n",
    "    print(\"=\" * 50)\n",
    "    return gdf_dataset\n",
    "\n",
    "# Run the verification on the cleaned dataset\n",
    "gdf_dataset_final = final_verification_checks_no_zeros(\n",
    "    gdf_dataset=gdf_dataset_cleaned,\n",
    "    dataset_output_img_path=DATASET_OUTPUT_IMG_PATH,\n",
    "    dataset_output_masks_path=DATASET_OUTPUT_MASKS_PATH\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS AFTER CLEANUP AND VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Final validation counts:\")\n",
    "print(gdf_dataset_final['validation_processing'].value_counts())\n",
    "print(f\"\\nDataset ready for saving: {len(gdf_dataset_final)} total records\")\n",
    "print(f\"High-quality records: {(gdf_dataset_final['validation_processing'] == 'ok').sum()}\")\n",
    "\n",
    "assert (gdf_dataset_final['validation_processing'] == 'ko').sum() == 0, \"There are still 'ko' records in the dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save verification and dataset results to parquet files for future use\n",
    "df_verification.to_parquet(VERIFICATION_OUTPUT_PARQUET_PATH, index=False)\n",
    "gdf_dataset.to_parquet(DATASET_OUTPUT_PARQUET_PATH, index=False)\n",
    "gdf_dataset_final.to_parquet(DATASET_FINAL_OUTPUT_PARQUET_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
