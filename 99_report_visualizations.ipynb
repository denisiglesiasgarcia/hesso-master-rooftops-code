{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from cairosvg import svg2png\n",
    "from IPython.display import display, SVG\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamp for output organization\n",
    "todays_date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Define base paths\n",
    "GRAPHICS_BASE_PATH = \"data/notebook_99/graphics\"\n",
    "GRAPHICS_PATH = os.path.join(GRAPHICS_BASE_PATH, todays_date)\n",
    "os.makedirs(GRAPHICS_PATH, exist_ok=True)\n",
    "\n",
    "TILE_1024_FOLDER_PATH = \"data/notebook_04/geotiff/tile_1024_split\"\n",
    "GEOTIFF_ORTHO2019_PATH = \"data/SITG/ortho2019\"\n",
    "\n",
    "# Output filenames for generated diagrams\n",
    "# Machine learning workflow\n",
    "ML_WORKFLOW_PNG = \"01_ML_workflow.png\"\n",
    "\n",
    "# Classification process\n",
    "CLASSIFICATION_WORKFLOW_PNG = \"ch3_piste_exploree_classification_01_workflow.png\"\n",
    "\n",
    "# ETL data pipeline\n",
    "ETL_WORKFLOW_PNG = \"ch3_preparation_donnees_01_etl.png\"\n",
    "\n",
    "# Orthophoto processing\n",
    "ETL_ORTHOPHOTOS_PNG = \"ch3_preparation_donnees_orthophotos_01_etl.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG = \"ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG = \"ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_03_PNG = \"ch3_preparation_donnees_orthophotos_04_exemple_decoupe_orthophoto3.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_04_PNG = \"ch3_preparation_donnees_orthophotos_05_exemple_decoupe_orthophoto5.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_05_PNG = \"ch3_preparation_donnees_orthophotos_06_exemple_decoupe_orthophoto5.png\"\n",
    "EXEMPLE_DECOUPE_ORTHOPHOTO_06_PNG = \"ch3_preparation_donnees_orthophotos_07_exemple_decoupe_orthophoto6.png\"\n",
    "\n",
    "# Post-processing dataset\n",
    "POST_TREATMENT_DATASET_01_OVERVIEW_PNG = \"ch3_postprocessing_dataset_03_overview.png\"\n",
    "\n",
    "# Model training architecture\n",
    "ARCHITECTURE_SIZE_DECODER_PNG = \"ch36_architecture_02_architecture_taille_decodeur.png\"\n",
    "BACKBONE_SIZE_ENCODER_FAMILY_PNG = \"ch36_architecture_03_backbone_taille_encodeur_famille.png\"\n",
    "BACKBONE_SIZE_ENCODER_ORDER_PNG = \"ch36_architecture_04_backbone_taille_encodeur_ordonnee.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_svg_as_png(svg_content, filename, dpi=2400, scale=4.0):\n",
    "    \"\"\"\n",
    "    Save SVG content as high-resolution PNG file.\n",
    "    \n",
    "    Parameters:\n",
    "        svg_content (str): SVG content as string\n",
    "        filename (str): Output filename for PNG file\n",
    "        dpi (int): Resolution in dots per inch\n",
    "        scale (float): Scaling factor for size increase\n",
    "    \"\"\"\n",
    "    # Extract dimensions from SVG content\n",
    "    width_match = re.search(r'width=\"([^\"]*)\"', svg_content)\n",
    "    height_match = re.search(r'height=\"([^\"]*)\"', svg_content)\n",
    "    \n",
    "    if width_match and height_match:\n",
    "        # Parse dimensions removing non-numeric characters\n",
    "        width = float(re.sub(r'[^\\d.]', '', width_match.group(1)))\n",
    "        height = float(re.sub(r'[^\\d.]', '', height_match.group(1)))\n",
    "        \n",
    "        # Calculate output dimensions\n",
    "        output_width = int(width * scale)\n",
    "        output_height = int(height * scale)\n",
    "        \n",
    "        # Convert SVG to PNG with specified dimensions\n",
    "        svg2png(\n",
    "            bytestring=svg_content.encode('utf-8'),\n",
    "            write_to=filename,\n",
    "            output_width=output_width,\n",
    "            output_height=output_height,\n",
    "            dpi=dpi\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: Width and height not found in SVG. Using default scale and DPI.\")\n",
    "        # Fallback to default conversion\n",
    "        svg2png(\n",
    "            bytestring=svg_content.encode('utf-8'),\n",
    "            write_to=filename,\n",
    "            scale=scale,\n",
    "            dpi=dpi\n",
    "        )\n",
    "\n",
    "    # Display the SVG content\n",
    "    display(SVG(svg_content))\n",
    "    \n",
    "    print(f\"High-resolution PNG saved to {filename} (DPI: {dpi}, Scale: {scale}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_high_quality_kroki(img_obj, filename):\n",
    "    \"\"\"\n",
    "    Save IPython Image object to file.\n",
    "    \n",
    "    Extracts binary data from various image object attributes\n",
    "    and saves to specified filename.\n",
    "    \n",
    "    Parameters:\n",
    "        img_obj: IPython Image object containing binary data\n",
    "        filename (str): Output filename for saving the image\n",
    "    \"\"\"\n",
    "    binary_data = None\n",
    "    \n",
    "    # Try different methods to extract binary data\n",
    "    if hasattr(img_obj, 'data') and img_obj.data:\n",
    "        binary_data = img_obj.data\n",
    "    elif hasattr(img_obj, '_repr_png_') and img_obj._repr_png_():\n",
    "        binary_data = img_obj._repr_png_()\n",
    "    elif hasattr(img_obj, '_data') and img_obj._data:\n",
    "        binary_data = img_obj._data\n",
    "    else:\n",
    "        # Search for any attribute containing binary data\n",
    "        for attr_name in dir(img_obj):\n",
    "            if not attr_name.startswith('__'):\n",
    "                attr_value = getattr(img_obj, attr_name)\n",
    "                if isinstance(attr_value, bytes) and len(attr_value) > 1000:\n",
    "                    binary_data = attr_value\n",
    "                    break\n",
    "    \n",
    "    if binary_data:\n",
    "        # Save binary data to file\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(binary_data)\n",
    "        \n",
    "        file_size = os.path.getsize(filename)\n",
    "        \n",
    "        # Format file size for display\n",
    "        if file_size < 1024:\n",
    "            size_str = f\"{file_size} B\"\n",
    "        elif file_size < 1024**2:\n",
    "            size_str = f\"{file_size/1024:.1f} KB\"\n",
    "        elif file_size < 1024**3:\n",
    "            size_str = f\"{file_size/(1024**2):.1f} MB\"\n",
    "        else:\n",
    "            size_str = f\"{file_size/(1024**3):.1f} GB\"\n",
    "        \n",
    "        # Extract image dimensions if possible\n",
    "        try:\n",
    "            from PIL import Image\n",
    "            with Image.open(filename) as img:\n",
    "                width, height = img.size\n",
    "                dimensions = f\"{width}x{height}\"\n",
    "        except ImportError:\n",
    "            dimensions = \"dimensions unknown (PIL not available)\"\n",
    "        except Exception:\n",
    "            dimensions = \"dimensions unknown\"\n",
    "        \n",
    "        print(f\"PNG saved: {filename} ({size_str}, {dimensions})\")\n",
    "    else:\n",
    "        print(f\"No binary data found. Available attributes: {[attr for attr in dir(img_obj) if not attr.startswith('__')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Workflow Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "digraph MLWorkflow {\n",
    "    rankdir=TB;\n",
    "    ranksep=\"0.5 equally\";\n",
    "    nodesep=0.5;\n",
    "    dpi=300;\n",
    "    \n",
    "    graph [splines=ortho];\n",
    "    edge [color=\"#2E86AB\", penwidth=1.5, arrowsize=0.6];\n",
    "    \n",
    "    // Define base style\n",
    "    node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=11,\n",
    "          height=0.65, width=1.5, fixedsize=true];\n",
    "    \n",
    "    // Planning style - Blue theme\n",
    "    A [label=<<FONT POINT-SIZE=\"14\">①</FONT><BR/>Définition de la tâche>, \n",
    "       fillcolor=\"#e3f2fd\", color=\"#1976d2\", penwidth=1];\n",
    "    B [label=<<FONT POINT-SIZE=\"14\">②</FONT><BR/>Choix algorithme>, \n",
    "       fillcolor=\"#e3f2fd\", color=\"#1976d2\", penwidth=1];\n",
    "    \n",
    "    // Data preparation style - Green theme\n",
    "    C [label=<<FONT POINT-SIZE=\"14\">③</FONT><BR/>Sélection données>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    D [label=<<FONT POINT-SIZE=\"14\">④</FONT><BR/>Labellisation>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    E [label=<<FONT POINT-SIZE=\"14\">⑤</FONT><BR/>Datasets>, \n",
    "       fillcolor=\"#e8f5e8\", color=\"#388e3c\", penwidth=1];\n",
    "    \n",
    "    // Training style - Orange theme\n",
    "    F [label=<<FONT POINT-SIZE=\"14\">⑥</FONT><BR/>Entraînement>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    G [label=<<FONT POINT-SIZE=\"14\">⑦</FONT><BR/>Validation>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    H [label=<<FONT POINT-SIZE=\"14\">⑧</FONT><BR/>Test>, \n",
    "       fillcolor=\"#fff3e0\", color=\"#f57c00\", penwidth=1];\n",
    "    \n",
    "    // Production style - Purple theme\n",
    "    I [label=<<FONT POINT-SIZE=\"14\">⑨</FONT><BR/>Production>, \n",
    "       fillcolor=\"#f3e5f5\", color=\"#7b1fa2\", penwidth=2];\n",
    "    \n",
    "    // Control horizontal positioning\n",
    "    {rank=same; A, B}\n",
    "    B -> A [dir=back];\n",
    "    \n",
    "    {rank=same; C, D, E}\n",
    "    C -> D -> E;\n",
    "    \n",
    "    {rank=same; H, G, F}\n",
    "    H -> G -> F [dir=back];\n",
    "    \n",
    "    {rank=same; I}\n",
    "    \n",
    "    // Workflow edges\n",
    "    B -> C [weight=1];\n",
    "    E -> F [weight=1];\n",
    "    H -> I [label=\" OK\", fontsize=10, fontcolor=\"darkgreen\"];\n",
    "    \n",
    "    // Feedback loop\n",
    "    H -> C [style=\"dashed\", color=\"red\", constraint=false, \n",
    "            taillabel=\"KO \", fontsize=10, fontcolor=\"red\"];\n",
    "    H -> F [style=\"dashed\", color=\"red\", constraint=false, \n",
    "            taillabel=\"KO \", fontsize=10, fontcolor=\"red\"];\n",
    "}\n",
    "'''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# write to file\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, ML_WORKFLOW_PNG))\n",
    "\n",
    "# display(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph RoofClassification {\n",
    "        rankdir=TB;\n",
    "        bgcolor=transparent;\n",
    "        fontname=\"Arial\";\n",
    "        pad=\"1.0\";\n",
    "        nodesep=\"0.2\";        // Reduced from 1.0 to 0.3 (less horizontal spacing)\n",
    "        ranksep=\"0.4\";        // Reduced from 0.8 to 0.6 (tighter vertical spacing)\n",
    "        ratio=compress;\n",
    "        dpi=300;\n",
    "        size=\"8,12!\";         // Limit width to 8 inches, height to 12 inches\n",
    "        \n",
    "        // Base node style - auto-sized to content with larger font\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=14,\n",
    "              margin=\"0.15\"];  // Increased fontsize from 10 to 14\n",
    "        \n",
    "        // Edge style with larger font for labels\n",
    "        edge [color=\"#2E86AB\", penwidth=1.5, arrowsize=0.6, fontsize=12];\n",
    "        \n",
    "        // Subgraph for classification section\n",
    "        subgraph cluster_1 {\n",
    "            label=\"2. Classification des Toitures\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            margin=20;\n",
    "            fontsize=16;        // Increased cluster title font size\n",
    "            fontname=\"Arial\";\n",
    "            \n",
    "            // Process nodes - Green theme\n",
    "            classify_start [label=\"Classification\\\\nToitures\", \n",
    "                          fillcolor=\"#F1F8E9\", color=\"#558B2F\"];\n",
    "            \n",
    "            // Validation nodes - Orange theme (diamonds)\n",
    "            surface_check [label=\"Surface > 2m²?\", \n",
    "                          fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            trou_check [label=\"Polygone toiture avec\\\\ntrou contenu dedans?\", \n",
    "                       fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            sp_check_avec_trou [label=\"Superstructure?\", \n",
    "                              fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            sp_check_sans_trou [label=\"Superstructure?\", \n",
    "                              fillcolor=\"#FFF3E0\", color=\"#EF6C00\", shape=diamond];\n",
    "            \n",
    "            // Action nodes - Purple theme\n",
    "            classe2a [label=\"Classe 2a\\\\nPartiellement occupée\\\\nPas de trou\\\\nSuperstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe2b [label=\"Classe 2b:\\\\nPartiellement occupée\\\\nTrou\\\\nSuperstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe3a [label=\"Classe 3a:\\\\nLibre\\\\nPas de trou\\\\nPas de superstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            classe3b [label=\"Classe 3b:\\\\nLibre\\\\nTrou\\\\nPas de superstructure\", \n",
    "                     fillcolor=\"#E8EAF6\", color=\"#3949AB\"];\n",
    "            \n",
    "            // Action on image nodes - Red theme\n",
    "            classe2a_sans_sp [label=\"Action sur image:\\\\nSupprimer SP\\\\nde l'image\", \n",
    "                             fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe2a_avec_sp [label=\"Pas d'action sur image\", \n",
    "                             fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe3b_sans_trou [label=\"Action sur image:\\\\nSupprimer trou\\\\nde l'image\", \n",
    "                               fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            classe3b_avec_trou [label=\"Pas d'action sur image\", \n",
    "                               fillcolor=\"#FFEBEE\", color=\"#D32F2F\"];\n",
    "            \n",
    "            // Output files - Blue theme with bold border\n",
    "            classe1 [label=\"Classe 1:\\\\nTotalement occupée\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "            \n",
    "            classe2 [label=\"Classe 2:\\\\nPartiellement occupée\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "            \n",
    "            classe3 [label=\"Classe 3:\\\\nLibre\", \n",
    "                    fillcolor=\"#E3F2FD\", color=\"#1565C0\", penwidth=2.5, style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for better layout - stack more vertically\n",
    "        {rank=source; classify_start, surface_check}\n",
    "        {rank=same; trou_check}\n",
    "        // Split the superstructure checks into separate ranks to reduce width\n",
    "        {rank=same; sp_check_sans_trou}\n",
    "        {rank=same; sp_check_avec_trou}\n",
    "        // Stack classification nodes vertically instead of horizontally\n",
    "        {rank=same; classe2a, classe3a}\n",
    "        {rank=same; classe2b, classe3b}\n",
    "        {rank=same; classe2a_sans_sp, classe2a_avec_sp}\n",
    "        {rank=same; classe3b_sans_trou, classe3b_avec_trou}\n",
    "        {rank=sink; classe1, classe2, classe3}\n",
    "        \n",
    "        // Flow edges\n",
    "        classify_start -> surface_check;\n",
    "        surface_check -> classe1 [label=\" ≤ 2m²\", fontsize=12];\n",
    "        surface_check -> trou_check [label=\" > 2m²\", fontsize=12];\n",
    "        trou_check -> sp_check_sans_trou [label=\" Non\", fontsize=12];\n",
    "        trou_check -> sp_check_avec_trou [label=\" Oui\", fontsize=12];\n",
    "        sp_check_avec_trou -> classe2b [label=\" Oui\", fontsize=12];\n",
    "        sp_check_avec_trou -> classe3b [label=\" Non\", fontsize=12];\n",
    "        sp_check_sans_trou -> classe2a [label=\" Oui\", fontsize=12];\n",
    "        sp_check_sans_trou -> classe3a [label=\" Non\", fontsize=12];\n",
    "        \n",
    "        // Action connections\n",
    "        classe2a -> classe2a_sans_sp;\n",
    "        classe2a -> classe2a_avec_sp;\n",
    "        classe3b -> classe3b_sans_trou;\n",
    "        classe3b -> classe3b_avec_trou;\n",
    "        \n",
    "        // Final classification\n",
    "        classe2a_sans_sp -> classe3;\n",
    "        classe2a_avec_sp -> classe2;\n",
    "        classe3b_sans_trou -> classe3;\n",
    "        classe3b_avec_trou -> classe2;\n",
    "        classe3a -> classe3;\n",
    "        classe2b -> classe2;\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# write to file\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, CLASSIFICATION_WORKFLOW_PNG))\n",
    "\n",
    "# display(png_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph SimplifiedDataFlow {\n",
    "        rankdir=TB;\n",
    "        bgcolor=transparent;\n",
    "        fontname=\"Arial\";\n",
    "        pad=\"1.0\";\n",
    "        nodesep=\"0.8\";\n",
    "        ranksep=\"0.6\";\n",
    "        ratio=compress;\n",
    "        dpi=300;\n",
    "        size=\"10,8!\";\n",
    "        ordering=out;\n",
    "        \n",
    "        // Base node style\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=12,\n",
    "              margin=\"0.3\", width=\"2.5\", height=\"0.6\"];\n",
    "        \n",
    "        // Edge style\n",
    "        edge [color=\"#2E86AB\", penwidth=2, arrowsize=0.8, fontsize=11];\n",
    "        \n",
    "        // Subgraph for simplified workflow\n",
    "        subgraph cluster_0 {\n",
    "            label=\"Traitement des données GPKG - Workflow simplifié\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            margin=25;\n",
    "            fontsize=16;\n",
    "            fontname=\"Arial\";\n",
    "            \n",
    "            // Input files - Blue theme\n",
    "            input_files [label=\"Fichiers GPKG de SITG\\\\n\\\\n CAD_COMMUNE\\\\n CAD_BATIMENT_HORSOL_TOIT\\\\n CAD_BATIMENT_HORSOL_TOIT_SP\\\\n CAD_BATIMENT_HORSOL\", \n",
    "                        fillcolor=\"#E3F2FD\", color=\"#1565C0\", height=\"0.8\"];\n",
    "            \n",
    "            // Process nodes - Green theme\n",
    "            validation [label=\"Nettoyage données\\\\n\\\\n Géométries\\\\n CRS (EPSG:2056)\\\\n Types de données\\\\n Bug Céligny\", \n",
    "                       fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            filter_canton [label=\"Filtrage hors GE\\\\n\\\\n Retirer polygones hors canton\", \n",
    "                          fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            filter_egid [label=\"Filtrage EGID\\\\n\\\\n Associer toitures aux bâtiments\\\\n Éliminer EGID non valables\\\\n\", \n",
    "                        fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            add_categories [label=\"Classification SIA\\\\n\\\\n Ajout catégories SIA\\\\n Validation données\", \n",
    "                           fillcolor=\"#F1F8E9\", color=\"#558B2F\", height=\"0.8\"];\n",
    "            \n",
    "            // Output file - Blue theme with bold border\n",
    "            output_file [label=\"Données finales\\\\n\\\\n gdf_toiture_ajout_cat_sia.parquet\", \n",
    "                        fillcolor=\"#E3F2FD\", color=\"#1565C0\", height=\"0.8\", \n",
    "                        penwidth=\"3\", style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for clean vertical layout\n",
    "        {rank=source; input_files}\n",
    "        {rank=same; validation, filter_canton}\n",
    "        {rank=same; add_categories, filter_egid}\n",
    "        {rank=sink; output_file}\n",
    "        \n",
    "        // Sequential flow\n",
    "        input_files -> validation;\n",
    "        validation -> filter_canton;\n",
    "        filter_canton -> filter_egid;\n",
    "        add_categories -> filter_egid [dir=back];\n",
    "        add_categories -> output_file;\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# Save to file (adjust path as needed)\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, ETL_WORKFLOW_PNG))\n",
    "\n",
    "display(png_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load processed roof data\n",
    "gdf_toiture_3_ajout_cat_sia = gpd.read_parquet(\"data/notebook_02/parquet/02_gdf_toiture_3_ajout_cat_sia.parquet\")\n",
    "display(gdf_toiture_3_ajout_cat_sia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and convert EGID to integer\n",
    "gdf_toiture_3_ajout_cat_sia.dtypes\n",
    "gdf_toiture_3_ajout_cat_sia['egid'] = gdf_toiture_3_ajout_cat_sia['egid'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_truncate(text, max_length=25):\n",
    "    \"\"\"\n",
    "    Truncate text for LaTeX display.\n",
    "    \n",
    "    Parameters:\n",
    "        text: Input text to truncate\n",
    "        max_length (int): Maximum length before truncation\n",
    "        \n",
    "    Returns:\n",
    "        str: Truncated text with LaTeX formatting\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    # Use LaTeX formatting for truncated text\n",
    "    truncated = text[:max_length-3]\n",
    "    return f\"\\\\parbox{{3cm}}{{{truncated}...}}\"\n",
    "\n",
    "def latex_truncate_float(value, max_length=25, decimal_places=2):\n",
    "    \"\"\"\n",
    "    Format and truncate float values for LaTeX display.\n",
    "    \n",
    "    Parameters:\n",
    "        value: Numeric value to format\n",
    "        max_length (int): Maximum string length\n",
    "        decimal_places (int): Number of decimal places\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted float with LaTeX truncation if needed\n",
    "    \"\"\"\n",
    "    if not isinstance(value, (int, float)):\n",
    "        return value\n",
    "    \n",
    "    # Format to specified decimal places\n",
    "    formatted = f\"{value:.{decimal_places}f}\"\n",
    "    \n",
    "    # Truncate if still too long\n",
    "    if len(formatted) > max_length:\n",
    "        truncated = formatted[:max_length-3]\n",
    "        return f\"\\\\parbox{{3cm}}{{{truncated}...}}\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "def auto_truncate_dataframe(df, drop_columns, max_length=25, threshold=30):\n",
    "    \"\"\"\n",
    "    Automatically detect and truncate long columns in DataFrame for LaTeX display.\n",
    "    \n",
    "    Parameters:\n",
    "        df: DataFrame to process\n",
    "        drop_columns: List of columns to drop\n",
    "        max_length (int): Maximum display length\n",
    "        threshold (int): Length threshold for truncation\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (processed_df, long_columns, column_format)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    df_display = df.copy()\n",
    "    long_columns = []\n",
    "\n",
    "    # Drop specified columns if they exist\n",
    "    if drop_columns:\n",
    "        df_display.drop(columns=[col for col in drop_columns if col in df_display.columns], inplace=True, errors='ignore')\n",
    "    \n",
    "    # Fix column names for LaTeX (escape underscores)\n",
    "    new_column_names = {}\n",
    "    for col in df_display.columns:\n",
    "        new_col = col\n",
    "        if \"__\" in col:\n",
    "            new_col = col.replace(\"__\", \"\\\\_\\\\_\")\n",
    "        elif \"_\" in col:\n",
    "            new_col = col.replace(\"_\", \"\\\\_\")\n",
    "        new_column_names[col] = new_col\n",
    "    \n",
    "    # Rename columns in DataFrame\n",
    "    df_display.rename(columns=new_column_names, inplace=True)\n",
    "    \n",
    "    # Detect and process long columns\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            # Handle numeric columns\n",
    "            if df[col].dtype in ['int64', 'int32', 'float64', 'float32']:\n",
    "                # Format float columns with truncation indicator\n",
    "                if df[col].dtype in ['float64', 'float32']:\n",
    "                    new_col_name = new_column_names[col]\n",
    "                    df_display[new_col_name] = df[col].apply(\n",
    "                        lambda x: f\"{x:.2f}...\" if pd.notna(x) else x\n",
    "                    )\n",
    "                else:\n",
    "                    # Check if integers are very long\n",
    "                    formatted_lengths = df[col].astype(str).str.len()\n",
    "                    max_len_in_col = formatted_lengths.max()\n",
    "                    \n",
    "                    if max_len_in_col > 15:\n",
    "                        new_col_name = new_column_names[col]\n",
    "                        long_columns.append(new_col_name)\n",
    "                        df_display[new_col_name] = df[col].apply(\n",
    "                            lambda x: latex_truncate(str(x), max_length)\n",
    "                        )\n",
    "                continue\n",
    "            \n",
    "            # Process non-numeric columns\n",
    "            string_series = df[col].astype(str)\n",
    "            max_len_in_col = string_series.str.len().max()\n",
    "            avg_len_in_col = string_series.str.len().mean()\n",
    "            \n",
    "            # Check if column needs truncation\n",
    "            is_long = (max_len_in_col > threshold) or (avg_len_in_col > threshold * 0.7)\n",
    "            is_geometry = 'geometry' in col.lower() or str(df[col].dtype).startswith('geometry')\n",
    "            \n",
    "            if is_long or is_geometry:\n",
    "                new_col_name = new_column_names[col]\n",
    "                long_columns.append(new_col_name)\n",
    "                \n",
    "                # Apply truncation\n",
    "                df_display[new_col_name] = df[col].apply(\n",
    "                    lambda x: latex_truncate(str(x), max_length)\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process column '{col}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Generate column format for LaTeX\n",
    "    column_format = \"@{}\"\n",
    "    for col in df_display.columns:\n",
    "        if col in long_columns:\n",
    "            column_format += \"p{3cm}\"  # Paragraph column for long text\n",
    "        elif df_display[col].dtype in ['int64', 'float64'] or col.endswith('...'):\n",
    "            column_format += \"r\"  # Right-align numbers\n",
    "        else:\n",
    "            column_format += \"l\"  # Left-align short text\n",
    "    column_format += \"@{}\"\n",
    "    \n",
    "    return df_display, long_columns, column_format\n",
    "\n",
    "def add_line_spacing_to_latex_table(latex_code, spacing_factor=2):\n",
    "    \"\"\"\n",
    "    Add line spacing to LaTeX table.\n",
    "    \n",
    "    Parameters:\n",
    "        latex_code (str): LaTeX table code\n",
    "        spacing_factor (float): Line spacing multiplier\n",
    "        \n",
    "    Returns:\n",
    "        str: Modified LaTeX code with spacing\n",
    "    \"\"\"\n",
    "    lines = latex_code.split('\\n')\n",
    "    result_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        result_lines.append(line)\n",
    "        # Insert spacing command after table begin\n",
    "        if line.strip().startswith('\\\\begin{table}'):\n",
    "            result_lines.append(f'\\\\renewcommand{{\\\\arraystretch}}{{{spacing_factor}}}')\n",
    "    \n",
    "    return '\\n'.join(result_lines)\n",
    "\n",
    "# Process and display table with truncation\n",
    "df_display, truncated_cols, col_format = auto_truncate_dataframe(\n",
    "    gdf_toiture_3_ajout_cat_sia.head(3),\n",
    "    drop_columns=[\"SHAPE__Area\", \"SHAPE__Length\", \"altitude_min\", \"altitude_max\", \"date_leve\"],\n",
    "    max_length=20,\n",
    "    threshold=25,\n",
    ")\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_code = df_display.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Principales colonnes de gdf\\\\_toiture\\\\_ajout\\\\_cat\\\\_sia.parquet\",\n",
    "    label=\"tab:gdf_toiture_ajout_cat_sia_parquet_head\",\n",
    "    escape=False,\n",
    "    column_format=col_format,\n",
    ")\n",
    "\n",
    "# Add line spacing\n",
    "latex_code_with_spacing = add_line_spacing_to_latex_table(latex_code, spacing_factor=1.3)\n",
    "print(latex_code_with_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthophoto Processing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<svg viewBox=\"0 0 800 600\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "  <!-- Background -->\n",
    "  <rect x=\"0\" y=\"0\" width=\"800\" height=\"600\" fill=\"#f8f9fa\" rx=\"6\" ry=\"6\"/>\n",
    "  \n",
    "  <!-- Title -->\n",
    "  <text x=\"400\" y=\"30\" font-family=\"Arial\" font-size=\"22\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#333\">GeoTIFF Building Detection and Tiling Process</text>\n",
    "  \n",
    "  <!-- Input Files Section -->\n",
    "  <rect x=\"50\" y=\"60\" width=\"700\" height=\"80\" rx=\"10\" ry=\"10\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"85\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#0d47a1\">Input Data</text>\n",
    "  \n",
    "  <!-- Input Icons -->\n",
    "  <rect x=\"100\" y=\"95\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#bbdefb\" stroke=\"#1976d2\" stroke-width=\"1\"/>\n",
    "  <text x=\"225\" y=\"115\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#0d47a1\">GeoTIFF SITG 20000x20000</text>\n",
    "  \n",
    "  <rect x=\"450\" y=\"95\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#bbdefb\" stroke=\"#1976d2\" stroke-width=\"1\"/>\n",
    "  <text x=\"575\" y=\"115\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#0d47a1\">Parquet Toitures</text>\n",
    "  \n",
    "  <!-- Process Flow -->\n",
    "  <rect x=\"50\" y=\"160\" width=\"700\" height=\"310\" rx=\"10\" ry=\"10\" fill=\"#e8f5e9\" stroke=\"#4caf50\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"185\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">Génération des tuiles</text>\n",
    "\n",
    "  <!-- Main Image Processing -->\n",
    "  <rect x=\"70\" y=\"200\" width=\"320\" height=\"250\" rx=\"8\" ry=\"8\" fill=\"#fff\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <text x=\"230\" y=\"225\" font-family=\"Arial\" font-size=\"16\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">GeoTIFF 200000x20000</text>\n",
    "  \n",
    "  <!-- Main Image Representation -->\n",
    "  <rect x=\"100\" y=\"240\" width=\"140\" height=\"140\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"240\" x2=\"240\" y2=\"240\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"270\" x2=\"240\" y2=\"270\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"300\" x2=\"240\" y2=\"300\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"330\" x2=\"240\" y2=\"330\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"100\" y1=\"240\" x2=\"100\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"135\" y1=\"240\" x2=\"135\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"170\" y1=\"240\" x2=\"170\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"205\" y1=\"240\" x2=\"205\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <line x1=\"240\" y1=\"240\" x2=\"240\" y2=\"380\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  \n",
    "  <!-- Building Polygons -->\n",
    "  <polygon points=\"125,260 145,250 165,265 155,280 135,275\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <polygon points=\"205,320 220,310 230,330 210,340\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <polygon points=\"110,340 130,330 140,350 120,360\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  \n",
    "  <!-- Tiling Process -->\n",
    "  <text x=\"170\" y=\"395\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#1b5e20\">GeoTIFF + Parquet Toitures</text>\n",
    "  \n",
    "  <!-- Tiling Result -->\n",
    "  <rect x=\"410\" y=\"200\" width=\"320\" height=\"250\" rx=\"8\" ry=\"8\" fill=\"#fff\" stroke=\"#2e7d32\" stroke-width=\"1\"/>\n",
    "  <text x=\"570\" y=\"225\" font-family=\"Arial\" font-size=\"16\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#1b5e20\">Tuile 1280x1280</text>\n",
    "  \n",
    "  <!-- Tile Representations -->\n",
    "  <rect x=\"430\" y=\"240\" width=\"90\" height=\"90\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"2\"/>\n",
    "  <polygon points=\"470,260 485,250 500,265 490,280 475,275\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <rect x=\"430\" y=\"240\" width=\"90\" height=\"90\" fill=\"none\" stroke=\"#2e7d32\" stroke-width=\"1\" stroke-dasharray=\"4,2\"/>\n",
    "  \n",
    "  <rect x=\"530\" y=\"240\" width=\"90\" height=\"90\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"1\" fill-opacity=\"0.3\"/>\n",
    "  \n",
    "  <rect x=\"430\" y=\"340\" width=\"90\" height=\"90\" fill=\"#e3f2fd\" stroke=\"#2196f3\" stroke-width=\"1\" fill-opacity=\"0.3\"/>\n",
    "  \n",
    "  <rect x=\"530\" y=\"340\" width=\"90\" height=\"90\" fill=\"#c8e6c9\" stroke=\"#2e7d32\" stroke-width=\"2\"/>\n",
    "  <polygon points=\"570,360 590,355 600,375 580,380\" fill=\"#f44336\" fill-opacity=\"0.5\" stroke=\"#d32f2f\" stroke-width=\"1.5\"/>\n",
    "  <rect x=\"530\" y=\"340\" width=\"90\" height=\"90\" fill=\"none\" stroke=\"#2e7d32\" stroke-width=\"1\" stroke-dasharray=\"4,2\"/>\n",
    "  \n",
    "  <!-- Buffer Illustration -->\n",
    "  <rect x=\"420\" y=\"230\" width=\"110\" height=\"110\" fill=\"none\" stroke=\"#ff9800\" stroke-width=\"1.5\" stroke-dasharray=\"5,3\"/>\n",
    "  <rect x=\"520\" y=\"330\" width=\"110\" height=\"110\" fill=\"none\" stroke=\"#ff9800\" stroke-width=\"1.5\" stroke-dasharray=\"5,3\"/>\n",
    "  \n",
    "  <text x=\"640\" y=\"390\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">Overlap</text>\n",
    "  <text x=\"640\" y=\"405\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">256 pixels</text>\n",
    "  <text x=\"640\" y=\"420\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"left\" fill=\"#1b5e20\">entre tuiles</text>\n",
    "  \n",
    "  <!-- Process Arrows -->\n",
    "  <path d=\"M 250 310 L 400 310\" stroke=\"#2e7d32\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n",
    "  # <text x=\"325\" y=\"300\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#1b5e20\">Quadrillage</text>\n",
    "  \n",
    "  <!-- Arrow Marker -->\n",
    "  <defs>\n",
    "    <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#2e7d32\"/>\n",
    "    </marker>\n",
    "  </defs>\n",
    "  \n",
    "  <!-- Output Section -->\n",
    "  <rect x=\"50\" y=\"490\" width=\"700\" height=\"80\" rx=\"10\" ry=\"10\" fill=\"#fff3e0\" stroke=\"#ff9800\" stroke-width=\"2\"/>\n",
    "  <text x=\"400\" y=\"515\" font-family=\"Arial\" font-size=\"18\" font-weight=\"bold\" text-anchor=\"middle\" fill=\"#e65100\">Output Data</text>\n",
    "  \n",
    "  <!-- Output Icons -->\n",
    "  <rect x=\"100\" y=\"525\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#ffe0b2\" stroke=\"#f57c00\" stroke-width=\"1\"/>\n",
    "  <text x=\"225\" y=\"545\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#e65100\">Tuiles GeoTIFF 1280x1280</text>\n",
    "  \n",
    "  <rect x=\"450\" y=\"525\" width=\"250\" height=\"30\" rx=\"5\" ry=\"5\" fill=\"#ffe0b2\" stroke=\"#f57c00\" stroke-width=\"1\"/>\n",
    "  <text x=\"575\" y=\"545\" font-family=\"Arial\" font-size=\"14\" text-anchor=\"middle\" fill=\"#e65100\">Dataframe tuiles (Parquet)</text>\n",
    "  \n",
    "\n",
    "\n",
    "  <!-- Final Arrow -->\n",
    "  <path d=\"M 400 470 L 400 490\" stroke=\"#e65100\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead2)\"/>\n",
    "  \n",
    "  <!-- Arrow Marker -->\n",
    "  <defs>\n",
    "    <marker id=\"arrowhead2\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#e65100\"/>\n",
    "    </marker>\n",
    "  </defs>\n",
    "\n",
    "</svg>\n",
    "\"\"\"\n",
    "\n",
    "svg2png(bytestring=svg, scale=2, dpi=600, write_to=os.path.join(GRAPHICS_PATH, ETL_ORTHOPHOTOS_PNG))\n",
    "# display the png file\n",
    "# display(Image.open(os.path.join(GRAPHICS_PATH, ETL_ORTHOPHOTOS_PNG)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthophoto Tile Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "def images_decoupe(GEOTIFF_ORTHO2019_PATH,\n",
    "    TILE_1024_FOLDER_PATH,\n",
    "    GRAPHICS_PATH,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG,\n",
    "    EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG,\n",
    "    selected_tile=None,\n",
    "    text_number_on_tiles=True):\n",
    "    \"\"\"\n",
    "    Visualize the tiling process of orthophotos.\n",
    "    \n",
    "    Creates visualizations showing how orthophotos are divided into tiles\n",
    "    for processing. Shows both the overlay on the original image and\n",
    "    a schematic view of the tile layout.\n",
    "    \n",
    "    Parameters:\n",
    "        GEOTIFF_ORTHO2019_PATH (str): Path to orthophoto GeoTIFF files\n",
    "        TILE_1024_FOLDER_PATH (str): Path to generated tile files\n",
    "        GRAPHICS_PATH (str): Output path for visualizations\n",
    "        EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG (str): Filename for first visualization\n",
    "        EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG (str): Filename for second visualization\n",
    "        selected_tile (str): Specific tile to visualize (optional)\n",
    "        text_number_on_tiles (bool): Whether to show tile numbers\n",
    "    \"\"\"\n",
    "    # Configure visualization style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(21)\n",
    "\n",
    "    if selected_tile:\n",
    "        print(f\"Using selected tile: {selected_tile}\")\n",
    "        random_ortho_file = selected_tile\n",
    "    else:\n",
    "        # Select random orthophoto for visualization\n",
    "        ortho_files = [f for f in os.listdir(GEOTIFF_ORTHO2019_PATH) if f.endswith('.tif') and not f.endswith('with_crs.tif')]\n",
    "        print(f\"Found {len(ortho_files)} ortho files\")\n",
    "        random_ortho_file = random.choice(ortho_files)\n",
    "        print(f\"Selected random ortho file: {random_ortho_file}\")\n",
    "\n",
    "    # Open and process the orthophoto\n",
    "    ortho_path = os.path.join(GEOTIFF_ORTHO2019_PATH, random_ortho_file)\n",
    "    try:\n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            print(f\"Ortho file shape: {src.shape}\")\n",
    "            print(f\"Ortho file CRS: {src.crs}\")\n",
    "            print(f\"Ortho file bounds: {src.bounds}\")\n",
    "            \n",
    "            # Find corresponding tiles\n",
    "            ortho_basename = os.path.splitext(random_ortho_file)[0]\n",
    "            print(f\"\\nSearching for tiles matching: {ortho_basename}\")\n",
    "            \n",
    "            tile_bounds_list = []\n",
    "            tile_files = []\n",
    "            \n",
    "            if os.path.exists(TILE_1024_FOLDER_PATH):\n",
    "                matching_tiles = [f for f in os.listdir(TILE_1024_FOLDER_PATH) if f.startswith(ortho_basename) and f.endswith('.tif')]\n",
    "                print(f\"Found {len(matching_tiles)} corresponding tiles\")\n",
    "                \n",
    "                # Extract bounds for each tile\n",
    "                for tile_file in matching_tiles:\n",
    "                    tile_path = os.path.join(TILE_1024_FOLDER_PATH, tile_file)\n",
    "                    try:\n",
    "                        with rasterio.open(tile_path) as tile_src:\n",
    "                            tile_bounds_list.append(tile_src.bounds)\n",
    "                            tile_files.append(tile_file)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {tile_file}: {e}\")\n",
    "                \n",
    "                print(f\"Successfully processed {len(tile_bounds_list)} tiles\")\n",
    "\n",
    "                # Sort tiles in reading order (top-left to bottom-right)\n",
    "                tile_data = []\n",
    "                for bounds, filename in zip(tile_bounds_list, tile_files):\n",
    "                    center_x = (bounds[0] + bounds[2]) / 2\n",
    "                    center_y = (bounds[1] + bounds[3]) / 2\n",
    "                    tile_data.append((bounds, filename, center_x, center_y))\n",
    "                \n",
    "                # Sort by y descending (top first), then x ascending (left first)\n",
    "                tile_data.sort(key=lambda x: (-x[3], x[2]))\n",
    "                \n",
    "                # Extract sorted data\n",
    "                tile_bounds_list = [item[0] for item in tile_data]\n",
    "                tile_files = [item[1] for item in tile_data]\n",
    "\n",
    "                # Create visualization 1: Overlay on orthophoto\n",
    "                fig, ax = plt.subplots(figsize=(6.5, 6.5))\n",
    "                \n",
    "                # Display the orthophoto\n",
    "                show(src, ax=ax, title=f\"Découpage pour l'orthophoto {random_ortho_file}\")\n",
    "                \n",
    "                # Generate colors for tiles\n",
    "                colors = sns.color_palette(\"pastel\", len(tile_bounds_list))\n",
    "                \n",
    "                # Add tile boundaries\n",
    "                for i, (bounds, tile_file) in enumerate(zip(tile_bounds_list, tile_files)):\n",
    "                    left, bottom, right, top = bounds\n",
    "                    width = right - left\n",
    "                    height = top - bottom\n",
    "                    \n",
    "                    # Create rectangle for tile boundary\n",
    "                    rect = patches.Rectangle(\n",
    "                        (left, bottom), width, height,\n",
    "                        linewidth=1.2, \n",
    "                        edgecolor=colors[i], \n",
    "                        facecolor='none',\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add tile number label\n",
    "                    if text_number_on_tiles:\n",
    "                        center_x = left + width / 2\n",
    "                        center_y = bottom + height / 2\n",
    "                        ax.text(center_x, center_y, str(i+1), \n",
    "                            ha='center', va='center', \n",
    "                            fontsize=7, color=\"white\",\n",
    "                            fontweight='semibold',)\n",
    "                \n",
    "                # Configure axes\n",
    "                ax.set_xlabel('x (m)')\n",
    "                ax.set_ylabel('y (m)')\n",
    "                \n",
    "                # Add legend\n",
    "                legend_text = f\"Tuiles découpées: {len(tile_bounds_list)}/400\"\n",
    "                ax.text(0.02, 0.98, legend_text, transform=ax.transAxes, \n",
    "                    verticalalignment='top', ha=\"left\", bbox=dict(boxstyle='round', \n",
    "                    facecolor='white', alpha=0.8))\n",
    "                \n",
    "                ax.grid(False)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save first visualization\n",
    "                plt.savefig(os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG), dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "                # Create visualization 2: Tile grid schematic\n",
    "                fig2, ax2 = plt.subplots(figsize=(6.5, 6.5))\n",
    "                \n",
    "                # Plot main image bounds\n",
    "                main_bounds = src.bounds\n",
    "                main_rect = patches.Rectangle(\n",
    "                    (main_bounds[0], main_bounds[1]), \n",
    "                    main_bounds[2] - main_bounds[0], \n",
    "                    main_bounds[3] - main_bounds[1],\n",
    "                    linewidth=3, edgecolor='black', facecolor='lightgray', alpha=0.3\n",
    "                )\n",
    "                ax2.add_patch(main_rect)\n",
    "                \n",
    "                # Add tile rectangles with colors\n",
    "                for i, (bounds, tile_file) in enumerate(zip(tile_bounds_list, tile_files)):\n",
    "                    left, bottom, right, top = bounds\n",
    "                    width = right - left\n",
    "                    height = top - bottom\n",
    "                    \n",
    "                    rect = patches.Rectangle(\n",
    "                        (left, bottom), width, height,\n",
    "                        linewidth=1, \n",
    "                        edgecolor=colors[i], \n",
    "                        facecolor=colors[i],\n",
    "                        alpha=0.6\n",
    "                    )\n",
    "                    ax2.add_patch(rect)\n",
    "                    \n",
    "                    # Add tile labels\n",
    "                    center_x = left + width / 2\n",
    "                    center_y = bottom + height / 2\n",
    "                    ax2.text(center_x, center_y, str(i+1), \n",
    "                            ha='center', va='center', fontsize=8)\n",
    "                \n",
    "                # Configure plot\n",
    "                ax2.set_xlim(main_bounds[0], main_bounds[2])\n",
    "                ax2.set_ylim(main_bounds[1], main_bounds[3])\n",
    "                ax2.set_xlabel('x (m)')\n",
    "                ax2.set_ylabel('y (m)')\n",
    "                ax2.set_title(f\"Calepinage des tuiles pour l'orthophoto {random_ortho_file}\", fontsize=12, fontweight='bold')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.set_aspect('equal')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save second visualization\n",
    "                plt.savefig(os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG), dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "            else:\n",
    "                print(f\"Tile folder does not exist: {TILE_1024_FOLDER_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ortho file {ortho_path}: {e}\")   \n",
    "\n",
    "# Generate visualizations for specific and random orthophotos\n",
    "images_decoupe(GEOTIFF_ORTHO2019_PATH,\n",
    "                TILE_1024_FOLDER_PATH,\n",
    "                GRAPHICS_PATH,\n",
    "                EXEMPLE_DECOUPE_ORTHOPHOTO_01_PNG,\n",
    "                EXEMPLE_DECOUPE_ORTHOPHOTO_02_PNG,\n",
    "                selected_tile=\"24991118.tif\",\n",
    "                text_number_on_tiles=False)\n",
    "\n",
    "images_decoupe(GEOTIFF_ORTHO2019_PATH,\n",
    "                TILE_1024_FOLDER_PATH,\n",
    "                GRAPHICS_PATH,\n",
    "                EXEMPLE_DECOUPE_ORTHOPHOTO_04_PNG,\n",
    "                EXEMPLE_DECOUPE_ORTHOPHOTO_05_PNG,\n",
    "                selected_tile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.close()\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "\n",
    "# Select specific tile for visualization\n",
    "target_tile = '24991118_tile_11_7_4db66f.tif'\n",
    "print(f\"Target tile: {target_tile}\")\n",
    "\n",
    "# Get all tiles from the specified orthophoto\n",
    "tile_files = [f for f in os.listdir(TILE_1024_FOLDER_PATH) if f.startswith('24991118_tile_') and f.endswith('.tif')]\n",
    "\n",
    "# Verify target tile exists\n",
    "if target_tile not in tile_files:\n",
    "    print(f\"Error: {target_tile} not found in tile_files list\")\n",
    "    similar_tiles = [t for t in tile_files if '24991118_tile_11_7' in t]\n",
    "    print(f\"Similar tiles found: {similar_tiles}\")\n",
    "    if similar_tiles:\n",
    "        target_tile = similar_tiles[0]\n",
    "        print(f\"Using: {target_tile}\")\n",
    "    else:\n",
    "        print(\"No similar tiles found. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "# Open and analyze the target tile\n",
    "tile_path = os.path.join(TILE_1024_FOLDER_PATH, target_tile)\n",
    "with rasterio.open(tile_path) as tile_src:\n",
    "    print(f\"Tile shape: {tile_src.shape}\")\n",
    "    print(f\"Tile CRS: {tile_src.crs}\")\n",
    "    print(f\"Tile bounds: {tile_src.bounds}\")\n",
    "    \n",
    "    # Get tile bounds\n",
    "    target_bounds = tile_src.bounds\n",
    "    \n",
    "    # Parse tile coordinates from filename\n",
    "    parts = target_tile.split('_')\n",
    "    target_row = int(parts[2])  # 11\n",
    "    target_col = int(parts[3])  # 7\n",
    "    print(f\"Target tile coordinates: row={target_row}, col={target_col}\")\n",
    "    \n",
    "    # Find all adjacent tiles (8 neighbors including diagonals)\n",
    "    adjacent_tiles = []\n",
    "    \n",
    "    # Define the 8 adjacent positions\n",
    "    adjacent_positions = [\n",
    "        (target_row-1, target_col-1),  # NW\n",
    "        (target_row-1, target_col),    # N\n",
    "        (target_row-1, target_col+1),  # NE\n",
    "        (target_row, target_col-1),    # W\n",
    "        (target_row, target_col+1),    # E\n",
    "        (target_row+1, target_col-1),  # SW\n",
    "        (target_row+1, target_col),    # S\n",
    "        (target_row+1, target_col+1),  # SE\n",
    "    ]\n",
    "    \n",
    "    # Search for adjacent tiles\n",
    "    for filename in tile_files:\n",
    "        if filename.startswith('24991118_tile_'):\n",
    "            parts = filename.split('_')\n",
    "            try:\n",
    "                row = int(parts[2])\n",
    "                col = int(parts[3])\n",
    "                \n",
    "                # Check if this tile is adjacent\n",
    "                if (row, col) in adjacent_positions:\n",
    "                    # Get bounds by opening the tile\n",
    "                    tile_path_check = os.path.join(TILE_1024_FOLDER_PATH, filename)\n",
    "                    try:\n",
    "                        with rasterio.open(tile_path_check) as check_src:\n",
    "                            bounds = check_src.bounds\n",
    "                            adjacent_tiles.append((bounds, filename, row, col))\n",
    "                            print(f\"Found adjacent tile: {filename} at ({row},{col})\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not read bounds for {filename}: {e}\")\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    print(f\"Found {len(adjacent_tiles)} adjacent tiles\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.5, 6.5))\n",
    "    \n",
    "    # Display the target tile\n",
    "    show(tile_src, ax=ax, alpha=0.8)\n",
    "    \n",
    "    # Define pastel colors for tiles\n",
    "    pastel_colors = [\n",
    "        '#FFB3BA',  # Light pink\n",
    "        '#BAFFC9',  # Light green  \n",
    "        '#BAE1FF',  # Light blue\n",
    "        '#FFFFBA',  # Light yellow\n",
    "        '#FFDFBA',  # Light peach\n",
    "        '#E0BBE4',  # Light purple\n",
    "        '#C7CEEA',  # Light lavender\n",
    "        '#B5EAD7',  # Light mint\n",
    "        '#FFE5CC'   # Light orange\n",
    "    ]\n",
    "    \n",
    "    # Track all bounds for plot limits\n",
    "    all_bounds = [target_bounds]\n",
    "    \n",
    "    # Overlay adjacent tiles\n",
    "    for i, (bounds, filename, row, col) in enumerate(adjacent_tiles):\n",
    "        tile_path_adj = os.path.join(TILE_1024_FOLDER_PATH, filename)\n",
    "        \n",
    "        try:\n",
    "            with rasterio.open(tile_path_adj) as adj_src:\n",
    "                # Display the adjacent tile with transparency\n",
    "                show(adj_src, ax=ax, alpha=0.6)\n",
    "                \n",
    "                # Add colored border\n",
    "                left, bottom, right, top = bounds\n",
    "                width_tile = right - left\n",
    "                height_tile = top - bottom\n",
    "                \n",
    "                # Draw border with unique color\n",
    "                color = pastel_colors[i % len(pastel_colors)]\n",
    "                rect = patches.Rectangle(\n",
    "                    (left, bottom), width_tile, height_tile,\n",
    "                    linewidth=3, \n",
    "                    edgecolor=color, \n",
    "                    facecolor='none',\n",
    "                    alpha=0.8\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # Add tile label with offset to avoid overlap\n",
    "                center_x = left + width_tile / 2\n",
    "                center_y = bottom + height_tile / 2\n",
    "                \n",
    "                label_offset_x = (center_x - (target_bounds.left + target_bounds.right) / 2) * 0.1\n",
    "                label_offset_y = (center_y - (target_bounds.bottom + target_bounds.top) / 2) * 0.1\n",
    "\n",
    "                # Map tile names to numbers\n",
    "                tile_dict = {\n",
    "                    \"24991118_tile_10_6_4fc85d.tif\": \"237\",\n",
    "                    \"24991118_tile_10_7_18eac4.tif\": \"238\",\n",
    "                    \"24991118_tile_10_8_2931b8.tif\": \"239\",\n",
    "                    \"24991118_tile_11_6_d743cd.tif\": \"257\",\n",
    "                    \"24991118_tile_11_8_6b34a7.tif\": \"259\",\n",
    "                    \"24991118_tile_12_6_a82c81.tif\": \"277\",\n",
    "                    \"24991118_tile_12_7_7ce219.tif\": \"278\",\n",
    "                    \"24991118_tile_12_8_83485c.tif\": \"279\",\n",
    "                }\n",
    "                tile_label = tile_dict.get(filename, filename)\n",
    "                \n",
    "                ax.text(center_x + label_offset_x, center_y + label_offset_y, \n",
    "                       tile_label, \n",
    "                       ha='center', va='center', \n",
    "                       fontsize=10, color='black', fontweight='demibold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', \n",
    "                               facecolor='white', \n",
    "                               alpha=0.9,\n",
    "                               edgecolor=color,\n",
    "                               linewidth=2))\n",
    "                \n",
    "                all_bounds.append(bounds)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Could not load adjacent tile {filename}: {e}\")\n",
    "    \n",
    "    # Highlight target tile with red border\n",
    "    left, bottom, right, top = target_bounds\n",
    "    width_tile = right - left\n",
    "    height_tile = top - bottom\n",
    "    \n",
    "    target_rect = patches.Rectangle(\n",
    "        (left, bottom), width_tile, height_tile,\n",
    "        linewidth=6, \n",
    "        edgecolor='red', \n",
    "        facecolor='none',\n",
    "        alpha=1.0,\n",
    "        ls = \":\"  # Dashed line for emphasis\n",
    "    )\n",
    "    ax.add_patch(target_rect)\n",
    "    \n",
    "    # Add target tile label\n",
    "    center_x = left + width_tile / 2\n",
    "    center_y = bottom + height_tile / 2\n",
    "    ax.text(center_x, center_y, \n",
    "           \"258\",\n",
    "           ha='center', va='center', \n",
    "           fontsize=10, color='white', fontweight='bold',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', \n",
    "                   facecolor='red', \n",
    "                   alpha=0.8,\n",
    "                   edgecolor='red',\n",
    "                   linewidth=2))\n",
    "   \n",
    "    # Set plot bounds with padding\n",
    "    if all_bounds:\n",
    "        min_x = min(b.left if hasattr(b, 'left') else b[0] for b in all_bounds)\n",
    "        max_x = max(b.right if hasattr(b, 'right') else b[2] for b in all_bounds)\n",
    "        min_y = min(b.bottom if hasattr(b, 'bottom') else b[1] for b in all_bounds)\n",
    "        max_y = max(b.top if hasattr(b, 'top') else b[3] for b in all_bounds)\n",
    "        \n",
    "        ax.set_xlim(min_x, max_x)\n",
    "        ax.set_ylim(min_y, max_y)\n",
    "    \n",
    "    # Configure axes\n",
    "    ax.set_xlabel('x (m)', fontsize=10)\n",
    "    ax.set_ylabel('y (m)', fontsize=10)\n",
    "    ax.set_title('Tuile 258 et adjacentes', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=10)\n",
    "    ax.xaxis.get_offset_text().set_fontsize(10)\n",
    "    ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "    ax.grid(False, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save visualization\n",
    "    plt.savefig(os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_03_PNG), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ADJACENT TILES SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Target tile: {target_tile} at position ({target_row},{target_col})\")\n",
    "    print(f\"Adjacent tiles found: {len(adjacent_tiles)}\")\n",
    "    print(\"\\nAdjacent tiles list:\")\n",
    "    for bounds, filename, row, col in sorted(adjacent_tiles, key=lambda x: (x[2], x[3])):\n",
    "        # Determine direction relative to target\n",
    "        direction = \"\"\n",
    "        if row < target_row and col < target_col:\n",
    "            direction = \"NW\"\n",
    "        elif row < target_row and col == target_col:\n",
    "            direction = \"N\"\n",
    "        elif row < target_row and col > target_col:\n",
    "            direction = \"NE\"\n",
    "        elif row == target_row and col < target_col:\n",
    "            direction = \"W\"\n",
    "        elif row == target_row and col > target_col:\n",
    "            direction = \"E\"\n",
    "        elif row > target_row and col < target_col:\n",
    "            direction = \"SW\"\n",
    "        elif row > target_row and col == target_col:\n",
    "            direction = \"S\"\n",
    "        elif row > target_row and col > target_col:\n",
    "            direction = \"SE\"\n",
    "        \n",
    "        print(f\"  {filename} at ({row},{col}) - {direction} of target\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "plt.close()\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "def read_single_orthophoto_metadata(args):\n",
    "    \"\"\"\n",
    "    Read metadata for a single orthophoto file.\n",
    "    \n",
    "    Used for parallel processing of orthophoto metadata extraction.\n",
    "    \n",
    "    Parameters:\n",
    "        args: Tuple of (ortho_file, ortho_path)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (filename, metadata_dict) or (filename, None) on error\n",
    "    \"\"\"\n",
    "    ortho_file, ortho_path = args\n",
    "    ortho_filepath = os.path.join(ortho_path, ortho_file)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(ortho_filepath) as src:\n",
    "            return ortho_file, {\n",
    "                'bounds': src.bounds,\n",
    "                'crs': src.crs,\n",
    "                'shape': src.shape,\n",
    "                'path': ortho_filepath,\n",
    "                'tiles': []\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {ortho_file}: {e}\")\n",
    "        return ortho_file, None\n",
    "\n",
    "def collect_orthophoto_metadata(ortho_path, max_workers=None):\n",
    "    \"\"\"\n",
    "    Collect metadata for all orthophoto files using parallel processing.\n",
    "    \n",
    "    Parameters:\n",
    "        ortho_path (str): Path to orthophoto directory\n",
    "        max_workers (int): Maximum parallel workers\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ortho_data_dict, overall_bounds)\n",
    "    \"\"\"\n",
    "    print(\"Scanning orthophoto files...\")\n",
    "    \n",
    "    # Find all orthophoto files\n",
    "    ortho_files = [f for f in os.listdir(ortho_path) if f.endswith('.tif') and not f.endswith('with_crs.tif')]\n",
    "    print(f\"Found {len(ortho_files)} orthophoto files\")\n",
    "    \n",
    "    if max_workers is None:\n",
    "        max_workers = min(mp.cpu_count(), 16)  # Limit to avoid too many file handles\n",
    "    \n",
    "    ortho_data = {}\n",
    "    all_bounds = []\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args_list = [(ortho_file, ortho_path) for ortho_file in ortho_files]\n",
    "    \n",
    "    # Process files in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(read_single_orthophoto_metadata, args): args[0] \n",
    "                         for args in args_list}\n",
    "        \n",
    "        for future in tqdm(as_completed(future_to_file), total=len(ortho_files), \n",
    "                          desc=\"Reading orthophoto metadata\"):\n",
    "            ortho_file = future_to_file[future]\n",
    "            try:\n",
    "                filename, data = future.result()\n",
    "                if data is not None:\n",
    "                    ortho_data[filename] = data\n",
    "                    all_bounds.append(data['bounds'])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ortho_file}: {e}\")\n",
    "    \n",
    "    # Calculate overall extent\n",
    "    if all_bounds:\n",
    "        min_x = min(b[0] for b in all_bounds)\n",
    "        min_y = min(b[1] for b in all_bounds)\n",
    "        max_x = max(b[2] for b in all_bounds)\n",
    "        max_y = max(b[3] for b in all_bounds)\n",
    "        overall_bounds = (min_x, min_y, max_x, max_y)\n",
    "        print(f\"Overall extent: {overall_bounds}\")\n",
    "        print(f\"Successfully processed {len(ortho_data)} orthophoto files\")\n",
    "    else:\n",
    "        overall_bounds = None\n",
    "    \n",
    "    return ortho_data, overall_bounds\n",
    "\n",
    "def read_single_tile_metadata(args):\n",
    "    \"\"\"\n",
    "    Read metadata for a single tile file.\n",
    "    \n",
    "    Parameters:\n",
    "        args: Tuple of (tile_file, tile_path)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (filename, bounds) or (filename, None) on error\n",
    "    \"\"\"\n",
    "    tile_file, tile_path = args\n",
    "    tile_filepath = os.path.join(tile_path, tile_file)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(tile_filepath) as tile_src:\n",
    "            return tile_file, tile_src.bounds\n",
    "    except Exception:\n",
    "        return tile_file, None\n",
    "\n",
    "def match_tiles_to_orthophotos(ortho_data, tile_path, max_workers=None):\n",
    "    \"\"\"\n",
    "    Match tile files to their corresponding orthophotos.\n",
    "    \n",
    "    Uses optimized lookup for efficient matching of tiles to source orthophotos.\n",
    "    \n",
    "    Parameters:\n",
    "        ortho_data (dict): Dictionary of orthophoto metadata\n",
    "        tile_path (str): Path to tile directory\n",
    "        max_workers (int): Maximum parallel workers\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated ortho_data with tile information\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tile_path):\n",
    "        print(f\"Tile folder does not exist: {tile_path}\")\n",
    "        return ortho_data\n",
    "    \n",
    "    print(\"Scanning tile files...\")\n",
    "    tile_files = [f for f in os.listdir(tile_path) if f.endswith('.tif')]\n",
    "    print(f\"Found {len(tile_files)} tile files\")\n",
    "    \n",
    "    if max_workers is None:\n",
    "        max_workers = min(mp.cpu_count(), 16)\n",
    "    \n",
    "    # Create lookup dictionary for faster matching\n",
    "    ortho_basenames = {}\n",
    "    for ortho_file in ortho_data.keys():\n",
    "        ortho_name = os.path.splitext(ortho_file)[0]\n",
    "        ortho_basenames[ortho_name] = ortho_file\n",
    "    \n",
    "    # Read tile metadata in parallel\n",
    "    args_list = [(tile_file, tile_path) for tile_file in tile_files]\n",
    "    tile_metadata = {}\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(read_single_tile_metadata, args): args[0] \n",
    "                         for args in args_list}\n",
    "        \n",
    "        for future in tqdm(as_completed(future_to_file), total=len(tile_files), \n",
    "                          desc=\"Reading tile metadata\"):\n",
    "            tile_file = future_to_file[future]\n",
    "            try:\n",
    "                filename, bounds = future.result()\n",
    "                if bounds is not None:\n",
    "                    tile_metadata[filename] = bounds\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {tile_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Match tiles to orthophotos\n",
    "    tiles_processed = 0\n",
    "    \n",
    "    print(\"Matching tiles to orthophotos...\")\n",
    "    for tile_file, tile_bounds in tqdm(tile_metadata.items(), desc=\"Matching tiles\"):\n",
    "        # Find matching orthophoto using optimized lookup\n",
    "        matched_ortho = None\n",
    "        for ortho_name, ortho_file in ortho_basenames.items():\n",
    "            if tile_file.startswith(ortho_name):\n",
    "                matched_ortho = ortho_file\n",
    "                break\n",
    "        \n",
    "        if matched_ortho:\n",
    "            ortho_data[matched_ortho]['tiles'].append({\n",
    "                'filename': tile_file,\n",
    "                'bounds': tile_bounds\n",
    "            })\n",
    "            tiles_processed += 1\n",
    "    \n",
    "    print(f\"Successfully matched {tiles_processed} tiles to orthophotos\")\n",
    "    \n",
    "    # Sort tiles for each orthophoto by spatial position\n",
    "    print(\"Sorting tiles by spatial position...\")\n",
    "    for ortho_file in tqdm(ortho_data.keys(), desc=\"Sorting tiles\"):\n",
    "        tiles = ortho_data[ortho_file]['tiles']\n",
    "        if tiles:\n",
    "            # Calculate center coordinates for sorting\n",
    "            tile_data = []\n",
    "            for tile in tiles:\n",
    "                bounds = tile['bounds']\n",
    "                center_x = (bounds[0] + bounds[2]) * 0.5\n",
    "                center_y = (bounds[1] + bounds[3]) * 0.5\n",
    "                tile_data.append((tile, center_x, center_y))\n",
    "            \n",
    "            # Sort by y descending (top first), then x ascending (left first)\n",
    "            tile_data.sort(key=lambda x: (-x[2], x[1]))\n",
    "            ortho_data[ortho_file]['tiles'] = [item[0] for item in tile_data]\n",
    "    \n",
    "    return ortho_data\n",
    "\n",
    "def process_single_orthophoto(args):\n",
    "    \"\"\"\n",
    "    Process a single orthophoto for visualization.\n",
    "    \n",
    "    Parameters:\n",
    "        args: Tuple of (ortho_file, data, tile_color, downsample_target)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (filename, img_data, extent, tile_patches, num_tiles)\n",
    "    \"\"\"\n",
    "    ortho_file, data, tile_color, downsample_target = args\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(data['path']) as src:\n",
    "            # Calculate downsample factor\n",
    "            downsample_factor = max(1, max(src.shape) // downsample_target)\n",
    "            \n",
    "            # Read downsampled data\n",
    "            downsampled_data = src.read(\n",
    "                out_shape=(src.count, src.height // downsample_factor, src.width // downsample_factor),\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "            \n",
    "            # Prepare image data\n",
    "            extent = [data['bounds'][0], data['bounds'][2], data['bounds'][1], data['bounds'][3]]\n",
    "            \n",
    "            if downsampled_data.shape[0] >= 3:  # RGB\n",
    "                img_data = np.transpose(downsampled_data[:3], (1, 2, 0))\n",
    "                # Optimize contrast\n",
    "                p98 = np.percentile(img_data, 98)\n",
    "                if p98 > 0:\n",
    "                    img_data = np.clip(img_data / p98 * 255, 0, 255).astype(np.uint8)\n",
    "            else:  # Single band\n",
    "                img_data = downsampled_data[0]\n",
    "            \n",
    "            # Prepare tile rectangles\n",
    "            tile_patches = []\n",
    "            for tile in data['tiles']:\n",
    "                tile_bounds = tile['bounds']\n",
    "                left, bottom, right, top = tile_bounds\n",
    "                width_tile = right - left\n",
    "                height_tile = top - bottom\n",
    "                \n",
    "                rect_data = {\n",
    "                    'xy': (left, bottom),\n",
    "                    'width': width_tile,\n",
    "                    'height': height_tile,\n",
    "                    'color': tile_color\n",
    "                }\n",
    "                tile_patches.append(rect_data)\n",
    "            \n",
    "            return ortho_file, img_data, extent, tile_patches, len(data['tiles'])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ortho_file}: {e}\")\n",
    "        return ortho_file, None, None, None, 0\n",
    "\n",
    "def create_canton_visualization(ortho_data, overall_bounds, output_path=None, downsample_target=600):\n",
    "    \"\"\"\n",
    "    Create visualization showing all orthophotos and their tile divisions.\n",
    "    \n",
    "    Creates a comprehensive map showing all orthophotos in the canton\n",
    "    with their tile boundaries highlighted.\n",
    "    \n",
    "    Parameters:\n",
    "        ortho_data (dict): Dictionary of orthophoto metadata\n",
    "        overall_bounds (tuple): Overall extent of all orthophotos\n",
    "        output_path (str): Output path for saving visualization\n",
    "        downsample_target (int): Target size for downsampling\n",
    "    \"\"\"\n",
    "    print(\"Creating canton-wide visualization...\")\n",
    "    \n",
    "    # Calculate figure dimensions\n",
    "    width = overall_bounds[2] - overall_bounds[0]\n",
    "    height = overall_bounds[3] - overall_bounds[1]\n",
    "    aspect_ratio = width / height\n",
    "    \n",
    "    fig_width = 6.5\n",
    "    fig_height = fig_width / aspect_ratio\n",
    "    if fig_height > 30:\n",
    "        fig_height = 30\n",
    "        fig_width = fig_height * aspect_ratio\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Filter orthophotos with tiles\n",
    "    orthos_with_tiles = {k: v for k, v in ortho_data.items() if v['tiles']}\n",
    "    print(f\"Processing {len(orthos_with_tiles)} orthophotos with tiles\")\n",
    "    \n",
    "    # Use high-contrast color for tile boundaries\n",
    "    tile_color = '#FF0000'  # Bright red for visibility\n",
    "    \n",
    "    # Process orthophotos in batches\n",
    "    max_workers = min(16, mp.cpu_count())\n",
    "    batch_size = 20\n",
    "    \n",
    "    ortho_items = list(orthos_with_tiles.items())\n",
    "    total_tiles = 0\n",
    "    ortho_count = 0\n",
    "    \n",
    "    # Process in batches to manage memory\n",
    "    for batch_start in tqdm(range(0, len(ortho_items), batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, len(ortho_items))\n",
    "        batch_items = ortho_items[batch_start:batch_end]\n",
    "        \n",
    "        # Prepare arguments for batch processing\n",
    "        args_list = [(ortho_file, data, tile_color, downsample_target) \n",
    "                    for ortho_file, data in batch_items]\n",
    "        \n",
    "        # Process batch in parallel\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(process_single_orthophoto, args) for args in args_list]\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    ortho_file, img_data, extent, tile_patches, num_tiles = future.result()\n",
    "                    \n",
    "                    if img_data is not None:\n",
    "                        # Display orthophoto with reduced alpha\n",
    "                        ax.imshow(img_data, extent=extent, alpha=0.6)\n",
    "                        \n",
    "                        # Add tile boundaries with enhanced visibility\n",
    "                        for patch_data in tile_patches:\n",
    "                            # White outline for contrast\n",
    "                            rect_outline = patches.Rectangle(\n",
    "                                patch_data['xy'], patch_data['width'], patch_data['height'],\n",
    "                                linewidth=4.0, \n",
    "                                edgecolor='white', \n",
    "                                facecolor='none',\n",
    "                                alpha=0.8,\n",
    "                                zorder=1\n",
    "                            )\n",
    "                            ax.add_patch(rect_outline)\n",
    "                            \n",
    "                            # Main red rectangle\n",
    "                            rect_main = patches.Rectangle(\n",
    "                                patch_data['xy'], patch_data['width'], patch_data['height'],\n",
    "                                linewidth=2.5, \n",
    "                                edgecolor=tile_color, \n",
    "                                facecolor='none',\n",
    "                                alpha=1.0,\n",
    "                                zorder=2\n",
    "                            )\n",
    "                            ax.add_patch(rect_main)\n",
    "                        \n",
    "                        total_tiles += num_tiles\n",
    "                        ortho_count += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch processing: {e}\")\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "    \n",
    "    # Configure plot\n",
    "    ax.set_xlim(overall_bounds[0], overall_bounds[2])\n",
    "    ax.set_ylim(overall_bounds[1], overall_bounds[3])\n",
    "    ax.set_xlabel('x (m)')\n",
    "    ax.set_ylabel('y (m)')\n",
    "    ax.set_title('Tuiles pour toutes les orthophotos', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add information box\n",
    "    info_text = f\"Orthophotos: {ortho_count}\\nTuiles totales: 38294\"\n",
    "    ax.text(0.02, 0.98, info_text, transform=ax.transAxes, \n",
    "           verticalalignment='top', horizontalalignment='left', \n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax.grid(False)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_path:\n",
    "        print(f\"Saving to: {output_path}\")\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualization complete: {ortho_count} orthophotos, {total_tiles} tiles\")\n",
    "    return fig, ax\n",
    "\n",
    "def process_all_orthophotos(ortho_path, tile_path, output_path=None, max_workers=None):\n",
    "    \"\"\"\n",
    "    Complete workflow to process all orthophotos and create visualization.\n",
    "    \n",
    "    Parameters:\n",
    "        ortho_path (str): Path to orthophoto directory\n",
    "        tile_path (str): Path to tile directory\n",
    "        output_path (str): Output path for visualization\n",
    "        max_workers (int): Maximum parallel workers\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ortho_data, overall_bounds, fig, ax)\n",
    "    \"\"\"\n",
    "    print(\"Starting optimized processing pipeline...\")\n",
    "    \n",
    "    # Step 1: Collect orthophoto metadata\n",
    "    print(\"\\n=== Step 1: Collecting orthophoto metadata ===\")\n",
    "    ortho_data, overall_bounds = collect_orthophoto_metadata(ortho_path, max_workers)\n",
    "    \n",
    "    if not ortho_data:\n",
    "        print(\"No orthophoto data found\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Match tiles to orthophotos\n",
    "    print(\"\\n=== Step 2: Matching tiles to orthophotos ===\")\n",
    "    ortho_data = match_tiles_to_orthophotos(ortho_data, tile_path, max_workers)\n",
    "    \n",
    "    # Step 3: Create visualization\n",
    "    print(\"\\n=== Step 3: Creating visualization ===\")\n",
    "    fig, ax = create_canton_visualization(ortho_data, overall_bounds, output_path)\n",
    "    \n",
    "    return ortho_data, overall_bounds, fig, ax\n",
    "\n",
    "def run_optimized_processing(ortho_path, tile_path, output_path):\n",
    "    \"\"\"\n",
    "    Run the complete optimized processing pipeline.\n",
    "    \n",
    "    Automatically determines optimal number of workers based on\n",
    "    available CPU cores.\n",
    "    \n",
    "    Parameters:\n",
    "        ortho_path (str): Path to orthophoto directory\n",
    "        tile_path (str): Path to tile directory\n",
    "        output_path (str): Output path for visualization\n",
    "        \n",
    "    Returns:\n",
    "        Processing results\n",
    "    \"\"\"\n",
    "    # Determine optimal number of workers\n",
    "    cpu_count = mp.cpu_count()\n",
    "    optimal_workers = min(cpu_count, 16)  # Balance between speed and resource usage\n",
    "    \n",
    "    print(f\"Using {optimal_workers} workers for parallel processing\")\n",
    "    print(f\"Available CPU cores: {cpu_count}\")\n",
    "    \n",
    "    return process_all_orthophotos(ortho_path, tile_path, output_path, optimal_workers)\n",
    "\n",
    "# Execute processing pipeline\n",
    "result = run_optimized_processing(\n",
    "    GEOTIFF_ORTHO2019_PATH, \n",
    "    TILE_1024_FOLDER_PATH, \n",
    "    os.path.join(GRAPHICS_PATH, EXEMPLE_DECOUPE_ORTHOPHOTO_06_PNG)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kroki import diagram_image\n",
    "\n",
    "graphviz_code = '''\n",
    "    digraph DatasetDistributionProcess {\n",
    "        rankdir=TB;\n",
    "        bgcolor=white;\n",
    "        fontname=\"Arial\";\n",
    "        fontsize=11;\n",
    "        pad=\"0.03\";\n",
    "        nodesep=\"0.8\";\n",
    "        ranksep=\"0.8\";\n",
    "        ratio=compress;\n",
    "        dpi=600;\n",
    "        size=\"10,10\"\n",
    "        ordering=out;\n",
    "        \n",
    "        // Base node style\n",
    "        node [shape=box, style=\"rounded,filled\", fontname=\"Arial\", fontsize=11,\n",
    "              margin=\"0.15\", width=\"1.5\", height=\"0.4\", penwidth=1];\n",
    "        \n",
    "        // Edge style\n",
    "        edge [color=\"#2E86AB\", penwidth=2, arrowsize=0.8, fontsize=11];\n",
    "        \n",
    "        // Subgraph for dataset distribution workflow\n",
    "        subgraph cluster_0 {\n",
    "            label=\"Processus de répartition en datasets 5 k-folds et test\";\n",
    "            style=rounded;\n",
    "            color=\"#2A4D7E\";\n",
    "            fontsize=11;\n",
    "            \n",
    "            // Step 1 - Light Blue\n",
    "            step1 [label=\"Rogner tuiles\\\\nannotées avec\\\\ncouche toitures\", \n",
    "                   fillcolor=\"#e7f5ff\", color=\"#4dabf7\"];\n",
    "            \n",
    "            // Step 2 - Light Green  \n",
    "            step2 [label=\"Problème fuite\\\\nde données\\\\nentre datasets\", \n",
    "                   fillcolor=\"#e6fcf5\", color=\"#38d9a9\"];\n",
    "            \n",
    "            // Step 3 - Light Yellow\n",
    "            step3 [label=\"Traitement des\\\\nchevauchements\\\\nentre les tuiles\", \n",
    "                   fillcolor=\"#fff9db\", color=\"#fcc419\"];\n",
    "            \n",
    "            // Step 4 - Light Orange\n",
    "            step4 [label=\"Distribution\\\\nstratifiée\\\\n5-fold CV + test\", \n",
    "                   fillcolor=\"#fff4e6\", color=\"#fd7e14\"];\n",
    "            \n",
    "            // Step 5 - Light Purple\n",
    "            step5 [label=\"Validation\\\\nde la distribution\\\\ndes datasets\", \n",
    "                   fillcolor=\"#f3f0ff\", color=\"#845ef7\"];\n",
    "            \n",
    "            // Step 6 - Light Pink\n",
    "            step6 [label=\"Datasets\\\\nprêts pour\\\\nl'entraînement\", \n",
    "                   fillcolor=\"#fdf2f8\", color=\"#ec4899\",\n",
    "                   penwidth=\"2\", style=\"rounded,filled,bold\"];\n",
    "        }\n",
    "        \n",
    "        // Define ranking for clean vertical layout\n",
    "        {rank=source; step1, step2, step3}\n",
    "        {rank=same; step4, step5, step6}\n",
    "        \n",
    "        // Sequential flow\n",
    "        step1 -> step2 -> step3;\n",
    "        step4 -> step3 [dir=back];\n",
    "        step6 -> step5 -> step4 [dir=back];\n",
    "\n",
    "    }\n",
    "    '''\n",
    "\n",
    "png_data = diagram_image(graphviz_code, diagram_type='graphviz', output_format='png')\n",
    "\n",
    "# Save to file (adjust path as needed)\n",
    "save_high_quality_kroki(png_data, os.path.join(GRAPHICS_PATH, POST_TREATMENT_DATASET_01_OVERVIEW_PNG))\n",
    "\n",
    "display(png_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load tile metadata\n",
    "df = gpd.read_parquet(TILE_1024_FOLDER_PATH + \"/combined_metadata.parquet\")\n",
    "\n",
    "# Display loaded data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique EGID\n",
    "len(df[\"egid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classification data\n",
    "gdf_toiture_7_classification = gpd.read_parquet(\"data/notebook_02/parquet/02_gdf_toiture_7_classification.parquet\")\n",
    "len(gdf_toiture_7_classification[\"egid\"].unique())\n",
    "\n",
    "# Find missing EGIDs\n",
    "missing_egids = set(df[\"egid\"].unique()) - set(gdf_toiture_7_classification[\"egid\"].unique())\n",
    "print(f\"Missing EGIDs: {missing_egids}\")\n",
    "\n",
    "# Filter to keep only valid EGIDs\n",
    "df = df[df[\"egid\"].isin(gdf_toiture_7_classification[\"egid\"].unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import logging\n",
    "import warnings\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure logging and warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('timm').setLevel(logging.ERROR)\n",
    "logging.getLogger('__main__').setLevel(logging.ERROR)\n",
    "\n",
    "@dataclass\n",
    "class ModelStats:\n",
    "    \"\"\"Store model architecture statistics.\"\"\"\n",
    "    architecture: str\n",
    "    backbone: str\n",
    "    encoder_params: int\n",
    "    decoder_params: int\n",
    "    head_params: int\n",
    "    total_params: int\n",
    "    decoder_ratio: float\n",
    "    encoder_ratio: float\n",
    "    status: str = \"success\"\n",
    "    error: Optional[str] = None\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze segmentation model architectures.\n",
    "    \n",
    "    Provides comprehensive analysis of different segmentation architectures\n",
    "    and backbones, including parameter counts and component ratios.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with available architectures and backbones.\"\"\"\n",
    "        self.model_creators = {\n",
    "            \"U-Net\": smp.Unet,\n",
    "            \"U-Net++\": smp.UnetPlusPlus,\n",
    "            \"MAnet\": smp.MAnet,\n",
    "            \"LinkNet\": smp.Linknet,\n",
    "            \"FPN\": smp.FPN,\n",
    "            \"PAN\": smp.PAN,\n",
    "            \"PSPNet\": smp.PSPNet,\n",
    "            \"SegFormer\": smp.Segformer,\n",
    "            \"DeepLabV3+\": smp.DeepLabV3Plus,\n",
    "            \"UPerNet\": smp.UPerNet,\n",
    "            \"DPT\": smp.DPT,\n",
    "        }\n",
    "        \n",
    "        self.common_backbones = [\n",
    "            \"timm-efficientnet-b3\",\n",
    "            \"tu-efficientvit_b2.r224_in1k\",\n",
    "            \"tu-fastvit_t8.apple_in1k\",\n",
    "            \"tu-repvit_m1.dist_in1k\",\n",
    "            \"tu-regnety_032.ra_in1k\",\n",
    "            \"tu-mambaout_small\",\n",
    "            \"tu-efficientnetv2_rw_s.ra2_in1k\",\n",
    "            \"tu-regnety_080.ra3_in1k\",\n",
    "            \"timm-res2net101_26w_4s\",\n",
    "            \"resnext50_32x4d\",\n",
    "            \"tu-mambaout_base\",\n",
    "            \"tu-efficientnetv2_rw_m.agc_in1k\",\n",
    "            \"timm-resnest200e\",\n",
    "            \"resnext101_32x8d\",\n",
    "            \"timm-efficientnet-b5\",\n",
    "            \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\"\n",
    "        ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_parameters(model_part) -> int:\n",
    "        \"\"\"\n",
    "        Count parameters in a model component.\n",
    "        \n",
    "        Parameters:\n",
    "            model_part: PyTorch module to count parameters\n",
    "            \n",
    "        Returns:\n",
    "            int: Total number of parameters\n",
    "        \"\"\"\n",
    "        return sum(p.numel() for p in model_part.parameters())\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_params(count: int) -> str:\n",
    "        \"\"\"\n",
    "        Format parameter count in human readable format.\n",
    "        \n",
    "        Parameters:\n",
    "            count (int): Number of parameters\n",
    "            \n",
    "        Returns:\n",
    "            str: Formatted string (e.g., \"25.5M\", \"1.2B\")\n",
    "        \"\"\"\n",
    "        if count >= 1e9:\n",
    "            return f\"{count/1e9:.2f}B\"\n",
    "        elif count >= 1e6:\n",
    "            return f\"{count/1e6:.2f}M\"\n",
    "        elif count >= 1e3:\n",
    "            return f\"{count/1e3:.2f}K\"\n",
    "        else:\n",
    "            return str(count)\n",
    "    \n",
    "    def analyze_model(self, architecture: str, model_class, backbone: str = \"resnet34\") -> ModelStats:\n",
    "        \"\"\"\n",
    "        Analyze a single model architecture.\n",
    "        \n",
    "        Parameters:\n",
    "            architecture (str): Architecture name\n",
    "            model_class: Model class from segmentation_models_pytorch\n",
    "            backbone (str): Backbone encoder name\n",
    "            \n",
    "        Returns:\n",
    "            ModelStats: Statistics for the model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Configure model parameters\n",
    "            model_params = {\n",
    "                \"encoder_name\": backbone,\n",
    "                \"encoder_weights\": \"imagenet\",\n",
    "                \"in_channels\": 3,\n",
    "                \"classes\": 1,\n",
    "                \"activation\": None,\n",
    "            }\n",
    "            \n",
    "            # Create model\n",
    "            model = model_class(**model_params)\n",
    "            \n",
    "            # Calculate component sizes\n",
    "            total_params = self.count_parameters(model)\n",
    "            encoder_params = self.count_parameters(model.encoder) if hasattr(model, 'encoder') else 0\n",
    "            decoder_params = self.count_parameters(model.decoder) if hasattr(model, 'decoder') else 0\n",
    "            \n",
    "            # Handle different head naming conventions\n",
    "            head_params = 0\n",
    "            if hasattr(model, 'segmentation_head'):\n",
    "                head_params = self.count_parameters(model.segmentation_head)\n",
    "            elif hasattr(model, 'classification_head'):\n",
    "                head_params = self.count_parameters(model.classification_head)\n",
    "            \n",
    "            # Calculate ratios\n",
    "            decoder_ratio = (decoder_params / total_params * 100) if total_params > 0 else 0\n",
    "            encoder_ratio = (encoder_params / total_params * 100) if total_params > 0 else 0\n",
    "            \n",
    "            return ModelStats(\n",
    "                architecture=architecture,\n",
    "                backbone=backbone,\n",
    "                encoder_params=encoder_params,\n",
    "                decoder_params=decoder_params,\n",
    "                head_params=head_params,\n",
    "                total_params=total_params,\n",
    "                decoder_ratio=decoder_ratio,\n",
    "                encoder_ratio=encoder_ratio\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return ModelStats(\n",
    "                architecture=architecture,\n",
    "                backbone=backbone,\n",
    "                encoder_params=0,\n",
    "                decoder_params=0,\n",
    "                head_params=0,\n",
    "                total_params=0,\n",
    "                decoder_ratio=0,\n",
    "                encoder_ratio=0,\n",
    "                status=\"error\",\n",
    "                error=str(e)[:100]\n",
    "            )\n",
    "    \n",
    "    def analyze_architectures(self, backbone: str = \"resnet34\") -> List[ModelStats]:\n",
    "        \"\"\"\n",
    "        Analyze all architectures with a given backbone.\n",
    "        \n",
    "        Parameters:\n",
    "            backbone (str): Backbone encoder to use\n",
    "            \n",
    "        Returns:\n",
    "            List[ModelStats]: Statistics for all architectures\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing Model Architectures (Backbone: {backbone})\")\n",
    "        print(\"=\" * 90)\n",
    "        \n",
    "        results = []\n",
    "        for arch_name, model_class in self.model_creators.items():\n",
    "            print(f\"Testing {arch_name}...\", end=\" \")\n",
    "            stats = self.analyze_model(arch_name, model_class, backbone)\n",
    "            results.append(stats)\n",
    "            \n",
    "            if stats.status == \"success\":\n",
    "                print(\"Done\")\n",
    "            else:\n",
    "                print(f\"Error ({stats.error[:30]}...)\")\n",
    "        \n",
    "        # Display results\n",
    "        self._display_architecture_results(results, backbone)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_backbones(self, architecture: str = \"U-Net\") -> List[ModelStats]:\n",
    "        \"\"\"\n",
    "        Analyze different backbones with a single architecture.\n",
    "        \n",
    "        Parameters:\n",
    "            architecture (str): Architecture to use\n",
    "            \n",
    "        Returns:\n",
    "            List[ModelStats]: Statistics for all backbones\n",
    "        \"\"\"\n",
    "        print(f\"\\nAnalyzing Backbones (Architecture: {architecture})\")\n",
    "        print(\"=\" * 90)\n",
    "        \n",
    "        model_class = self.model_creators.get(architecture)\n",
    "        if not model_class:\n",
    "            print(f\"Architecture '{architecture}' not found!\")\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        for backbone in self.common_backbones:\n",
    "            print(f\"Testing {backbone}...\", end=\" \")\n",
    "            stats = self.analyze_model(architecture, model_class, backbone)\n",
    "            results.append(stats)\n",
    "            \n",
    "            if stats.status == \"success\":\n",
    "                print(\"Done\")\n",
    "            else:\n",
    "                print(f\"Error ({stats.error[:30]}...)\")\n",
    "        \n",
    "        # Display results\n",
    "        self._display_backbone_results(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _display_architecture_results(self, results: List[ModelStats], backbone: str):\n",
    "        \"\"\"Display architecture comparison results.\"\"\"\n",
    "        print(\"\\nArchitecture Comparison Results\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        # Filter successful results\n",
    "        successful_results = [r for r in results if r.status == \"success\"]\n",
    "        failed_results = [r for r in results if r.status == \"error\"]\n",
    "        \n",
    "        if successful_results:\n",
    "            # Sort by decoder size\n",
    "            successful_results.sort(key=lambda x: x.decoder_params, reverse=True)\n",
    "            \n",
    "            headers = [\"Architecture\", \"Decoder\", \"Encoder\", \"Head\", \"Total\", \"Dec%\", \"Enc%\"]\n",
    "            table_data = []\n",
    "            \n",
    "            for stats in successful_results:\n",
    "                table_data.append([\n",
    "                    stats.architecture,\n",
    "                    self.format_params(stats.decoder_params),\n",
    "                    self.format_params(stats.encoder_params),\n",
    "                    self.format_params(stats.head_params),\n",
    "                    self.format_params(stats.total_params),\n",
    "                    f\"{stats.decoder_ratio:.1f}%\",\n",
    "                    f\"{stats.encoder_ratio:.1f}%\"\n",
    "                ])\n",
    "            \n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "            \n",
    "            # Summary statistics\n",
    "            self._print_architecture_summary(successful_results, backbone)\n",
    "        \n",
    "        # Show failed models\n",
    "        if failed_results:\n",
    "            print(f\"\\nFailed Models ({len(failed_results)}):\")\n",
    "            for result in failed_results:\n",
    "                print(f\"  • {result.architecture}: {result.error}\")\n",
    "    \n",
    "    def _display_backbone_results(self, results: List[ModelStats]):\n",
    "        \"\"\"Display backbone comparison results.\"\"\"\n",
    "        print(\"\\nBackbone Comparison Results\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        successful_results = [r for r in results if r.status == \"success\"]\n",
    "        failed_results = [r for r in results if r.status == \"error\"]\n",
    "        \n",
    "        if successful_results:\n",
    "            # Sort by total parameters\n",
    "            successful_results.sort(key=lambda x: x.total_params)\n",
    "            \n",
    "            headers = [\"Backbone\", \"Encoder\", \"Decoder\", \"Total\", \"Enc%\"]\n",
    "            table_data = []\n",
    "            \n",
    "            for stats in successful_results:\n",
    "                table_data.append([\n",
    "                    stats.backbone,\n",
    "                    self.format_params(stats.encoder_params),\n",
    "                    self.format_params(stats.decoder_params),\n",
    "                    self.format_params(stats.total_params),\n",
    "                    f\"{stats.encoder_ratio:.1f}%\"\n",
    "                ])\n",
    "            \n",
    "            print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "            \n",
    "            # Summary statistics\n",
    "            self._print_backbone_summary(successful_results)\n",
    "        \n",
    "        # Show failed models\n",
    "        if failed_results:\n",
    "            print(f\"\\nFailed Backbones ({len(failed_results)}):\")\n",
    "            for result in failed_results:\n",
    "                print(f\"  • {result.backbone}: {result.error}\")\n",
    "    \n",
    "    def _print_architecture_summary(self, results: List[ModelStats], backbone: str):\n",
    "        \"\"\"Print summary statistics for architecture analysis.\"\"\"\n",
    "        print(f\"\\nSummary Statistics (Backbone: {backbone})\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No successful results to analyze.\")\n",
    "            return\n",
    "        \n",
    "        # Decoder analysis\n",
    "        decoder_sizes = [r.decoder_params for r in results]\n",
    "        min_decoder = min(results, key=lambda x: x.decoder_params)\n",
    "        max_decoder = max(results, key=lambda x: x.decoder_params)\n",
    "        \n",
    "        print(f\"Models analyzed: {len(results)}\")\n",
    "        print(f\"Encoder size: {self.format_params(results[0].encoder_params)} (consistent)\")\n",
    "        print(f\"Decoder range: {self.format_params(min(decoder_sizes))} - {self.format_params(max(decoder_sizes))}\")\n",
    "        print(f\"Smallest decoder: {min_decoder.architecture} ({self.format_params(min_decoder.decoder_params)})\")\n",
    "        print(f\"Largest decoder: {max_decoder.architecture} ({self.format_params(max_decoder.decoder_params)})\")\n",
    "        \n",
    "        # Efficiency analysis\n",
    "        efficient_models = [r for r in results if r.decoder_ratio < 10]\n",
    "        heavy_models = [r for r in results if r.decoder_ratio > 25]\n",
    "        \n",
    "        print(\"\\nInsights:\")\n",
    "        print(f\"  • Efficient models (<10% decoder): {[r.architecture for r in efficient_models]}\")\n",
    "        print(f\"  • Heavy decoders (>25% decoder): {[r.architecture for r in heavy_models]}\")\n",
    "        \n",
    "        # Model recommendations\n",
    "        print(\"\\nRecommendations:\")\n",
    "        print(f\"  • For speed: {min_decoder.architecture} (smallest decoder)\")\n",
    "        print(f\"  • For accuracy: {max_decoder.architecture} (largest decoder)\")\n",
    "        balanced = min(results, key=lambda x: abs(x.decoder_ratio - 15))\n",
    "        print(f\"  • For balance: {balanced.architecture} ({balanced.decoder_ratio:.1f}% decoder)\")\n",
    "    \n",
    "    def _print_backbone_summary(self, results: List[ModelStats]):\n",
    "        \"\"\"Print summary statistics for backbone analysis.\"\"\"\n",
    "        print(\"\\nSummary Statistics\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No successful results to analyze.\")\n",
    "            return\n",
    "        \n",
    "        min_total = min(results, key=lambda x: x.total_params)\n",
    "        max_total = max(results, key=lambda x: x.total_params)\n",
    "        \n",
    "        print(f\"Backbones tested: {len(results)}\")\n",
    "        print(f\"Size range: {self.format_params(min_total.total_params)} - {self.format_params(max_total.total_params)}\")\n",
    "        print(f\"Smallest: {min_total.backbone} ({self.format_params(min_total.total_params)})\")\n",
    "        print(f\"Largest: {max_total.backbone} ({self.format_params(max_total.total_params)})\")\n",
    "        \n",
    "        # Check decoder consistency\n",
    "        decoder_sizes = [r.decoder_params for r in results]\n",
    "        if len(set(decoder_sizes)) == 1:\n",
    "            print(f\"Decoder size: {self.format_params(decoder_sizes[0])} (consistent across backbones)\")\n",
    "        else:\n",
    "            print(f\"Decoder varies: {self.format_params(min(decoder_sizes))} - {self.format_params(max(decoder_sizes))}\")\n",
    "    \n",
    "    def create_comparison_plot(self, arch_results: List[ModelStats], backbone_results: List[ModelStats]):\n",
    "        \"\"\"Create visualization plots for the analysis.\"\"\"\n",
    "       \n",
    "        def compare_architectures(arch_results):\n",
    "            \"\"\"Create architecture decoder size comparison plot.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            pastel_palette = sns.color_palette(\"pastel\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            successful_arch = [r for r in arch_results if r.status == \"success\"]\n",
    "            if successful_arch:\n",
    "                # Define display order\n",
    "                archs_ordered = ['U-Net', 'FPN', 'PSPNet', 'LinkNet', 'U-Net++', 'DeepLabV3+', 'PAN', 'UPerNet', 'MAnet', 'SegFormer', 'DPT']\n",
    "                archs = [r.architecture for r in successful_arch]\n",
    "                archs = sorted(archs, key=lambda x: archs_ordered.index(x) if x in archs_ordered else len(archs_ordered))\n",
    "                \n",
    "                decoder_sizes = [r.decoder_params / 1e6 for r in successful_arch]  # Convert to millions\n",
    "                \n",
    "                ax1.bar(archs, decoder_sizes, color=pastel_palette[:len(archs)], alpha=0.85)\n",
    "                ax1.set_title('Taille du décodeur', fontsize=11, fontweight='bold')\n",
    "                ax1.set_ylabel('Paramètres (Millions)')\n",
    "                ax1.tick_params(axis='x', rotation=45)\n",
    "                # Add values on bars\n",
    "                for i, v in enumerate(decoder_sizes):\n",
    "                    ax1.text(i, v + 1.5, f\"{v:.1f}\", ha='center', va='top', fontsize=10)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, ARCHITECTURE_SIZE_DECODER_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        def compare_backbones_family(backbone_results):\n",
    "            \"\"\"Create backbone comparison plot grouped by family.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            \n",
    "            # Define backbone families\n",
    "            backbone_families = {\n",
    "                \"ResNext\": ['resnext50', 'resnext101'],\n",
    "                \"EfficientNet\" : [\"efficientnet-b3\", \"efficientnet-b5\"],\n",
    "                \"RegNetY\" : [\"regnety_032\", \"regnety_080\"],\n",
    "                \"ResNeSt\": [\"resnest200e\"],\n",
    "                \"EfficientNetV2\": [\"efficientnetv2_rw_s\", \"efficientnetv2_rw_m\", \"tf_efficientnetv2_xl\"],\n",
    "                \"Res2Net\": [\"res2net101_26w_4s\"],\n",
    "                \"FastViT\": [\"fastvit_t8\"],\n",
    "                \"RepViT\": [\"repvit_m1\"],\n",
    "                \"MambaOut\": [\"mambaout_small\", \"mambaout_base\"],\n",
    "                \"EfficientViT\": [\"efficientvit_b2\"],\n",
    "            }\n",
    "            \n",
    "            # Group backbones by family\n",
    "            grouped = {}\n",
    "            for family in backbone_families.keys():\n",
    "                grouped[family] = []\n",
    "            \n",
    "            successful_backbones = [r for r in backbone_results if r.status == \"success\"]\n",
    "            \n",
    "            for result in successful_backbones:\n",
    "                backbone_name = result.backbone.lower()\n",
    "                family_found = False\n",
    "                \n",
    "                for family, keywords in backbone_families.items():\n",
    "                    if family == 'Others':\n",
    "                        continue\n",
    "                    if any(keyword in backbone_name for keyword in keywords):\n",
    "                        grouped[family].append(result)\n",
    "                        family_found = True\n",
    "                        break\n",
    "                \n",
    "                if not family_found:\n",
    "                    grouped['Others'].append(result)\n",
    "            \n",
    "            # Remove empty families and sort\n",
    "            grouped = {family: results for family, results in grouped.items() if results}\n",
    "            for family in grouped:\n",
    "                grouped[family].sort(key=lambda x: x.encoder_params)\n",
    "            \n",
    "            # Prepare data for plotting\n",
    "            all_backbones = []\n",
    "            all_encoder_sizes = []\n",
    "            family_colors = []\n",
    "            family_boundaries = []\n",
    "            \n",
    "            # Create color map\n",
    "            family_names = list(grouped.keys())\n",
    "            family_palette = sns.color_palette(\"pastel\", len(family_names))\n",
    "            color_map = {family: color for family, color in zip(family_names, family_palette)}\n",
    "            \n",
    "            current_pos = 0\n",
    "\n",
    "            for family, results in grouped.items():\n",
    "                for result in results:\n",
    "                    all_backbones.append(result.backbone)\n",
    "                    all_encoder_sizes.append(result.encoder_params / 1e6)\n",
    "                    family_colors.append(color_map[family])\n",
    "                    current_pos += 1\n",
    "                \n",
    "                family_end = current_pos - 1\n",
    "                family_boundaries.append(family_end + 0.5)\n",
    "\n",
    "            if family_boundaries:\n",
    "                family_boundaries.pop()\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            \n",
    "            # Create bars with family colors\n",
    "            bars = ax1.bar(range(len(all_backbones)), all_encoder_sizes, \n",
    "                        color=family_colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "            \n",
    "            ax1.set_title(\"Encodeurs groupés par type d'architecture\", fontsize=11, fontweight='bold')\n",
    "            ax1.set_ylabel('Paramètres (Millions)')\n",
    "            ax1.set_xticks(range(len(all_backbones)))\n",
    "            \n",
    "            # Readable backbone names\n",
    "            bb_readable = {\n",
    "                \"timm-efficientnet-b3\": \"EfficientNet-B3\",\n",
    "                \"timm-efficientnet-b5\": \"EfficientNet-B5\",\n",
    "                \"tu-efficientvit_b2.r224_in1k\": \"EfficientViT-B2\",\n",
    "                \"tu-fastvit_t8.apple_in1k\": \"FastViT-T8\",\n",
    "                \"tu-repvit_m1.dist_in1k\": \"RepViT-M1\",\n",
    "                \"tu-regnety_032.ra_in1k\": \"RegNetY-032\",\n",
    "                \"tu-regnety_080.ra3_in1k\": \"RegNetY-080\",\n",
    "                \"tu-mambaout_small\": \"MambaOut-Small\",\n",
    "                \"tu-mambaout_base\": \"MambaOut-Base\",\n",
    "                \"tu-efficientnetv2_rw_s.ra2_in1k\": \"EfficientNetV2-S\",\n",
    "                \"tu-efficientnetv2_rw_m.agc_in1k\": \"EfficientNetV2-M\",\n",
    "                \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\": \"EfficientNetV2-XL\",\n",
    "                \"timm-res2net101_26w_4s\": \"Res2Net-101\",\n",
    "                \"resnext50_32x4d\": \"ResNeXt-50\",\n",
    "                \"resnext101_32x8d\": \"ResNeXt-101\",\n",
    "                \"timm-resnest200e\": \"ResNeSt-200E\",\n",
    "            }\n",
    "            readable_labels = [bb_readable.get(bb, bb) for bb in all_backbones]\n",
    "            ax1.set_xticklabels(readable_labels, rotation=90, ha='center', fontsize=10)\n",
    "\n",
    "            # Add values on bars\n",
    "            for i, v in enumerate(all_encoder_sizes):\n",
    "                ax1.text(i, v + max(all_encoder_sizes) * 0.005, f\"{v:.1f}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            # Add family separators\n",
    "            for boundary in family_boundaries:\n",
    "                ax1.axvline(x=boundary, color='lightgray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "          \n",
    "            plt.ylim(0, max(all_encoder_sizes) * 1.07)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, BACKBONE_SIZE_ENCODER_FAMILY_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        def compare_backbones_size(backbone_results):\n",
    "            \"\"\"Create backbone comparison plot ordered by size.\"\"\"\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            plt.rcParams['font.size'] = 10\n",
    "            plt.rcParams['axes.labelsize'] = 10\n",
    "            plt.rcParams['axes.titlesize'] = 11\n",
    "            \n",
    "            # Define backbone families (same as above)\n",
    "            backbone_families = {\n",
    "                \"ResNext\": ['resnext50', 'resnext101'],\n",
    "                \"EfficientNet\" : [\"efficientnet-b3\", \"efficientnet-b5\"],\n",
    "                \"RegNetY\" : [\"regnety_032\", \"regnety_080\"],\n",
    "                \"ResNeSt\": [\"resnest200e\"],\n",
    "                \"EfficientNetV2\": [\"efficientnetv2_rw_s\", \"efficientnetv2_rw_m\", \"tf_efficientnetv2_xl\"],\n",
    "                \"Res2Net\": [\"res2net101_26w_4s\"],\n",
    "                \"FastViT\": [\"fastvit_t8\"],\n",
    "                \"RepViT\": [\"repvit_m1\"],\n",
    "                \"MambaOut\": [\"mambaout_small\", \"mambaout_base\"],\n",
    "                \"EfficientViT\": [\"efficientvit_b2\"],\n",
    "            }\n",
    "            \n",
    "            # Create color mapping\n",
    "            family_names = list(backbone_families.keys())\n",
    "            family_palette = sns.color_palette(\"pastel\", len(family_names))\n",
    "            color_map = {family: color for family, color in zip(family_names, family_palette)}\n",
    "            \n",
    "            # Function to determine backbone family\n",
    "            def get_backbone_family(backbone_name):\n",
    "                backbone_lower = backbone_name.lower()\n",
    "                for family, keywords in backbone_families.items():\n",
    "                    if any(keyword in backbone_lower for keyword in keywords):\n",
    "                        return family\n",
    "                return \"Others\"\n",
    "            \n",
    "            # Extract and prepare data\n",
    "            successful_backbones = [r for r in backbone_results if r.status == \"success\"]\n",
    "            \n",
    "            all_backbones = []\n",
    "            all_encoder_sizes = []\n",
    "            \n",
    "            for result in successful_backbones:\n",
    "                all_backbones.append(result.backbone)\n",
    "                all_encoder_sizes.append(result.encoder_params / 1e6)\n",
    "            \n",
    "            # Sort by size\n",
    "            backbone_size_pairs = list(zip(all_backbones, all_encoder_sizes))\n",
    "            backbone_size_pairs.sort(key=lambda x: x[1])\n",
    "            \n",
    "            sorted_backbones, sorted_sizes = zip(*backbone_size_pairs)\n",
    "            sorted_backbones = list(sorted_backbones)\n",
    "            sorted_sizes = list(sorted_sizes)\n",
    "            \n",
    "            # Assign colors based on family\n",
    "            bar_colors = []\n",
    "            for backbone in sorted_backbones:\n",
    "                family = get_backbone_family(backbone)\n",
    "                if family in color_map:\n",
    "                    bar_colors.append(color_map[family])\n",
    "                else:\n",
    "                    bar_colors.append('lightgray')\n",
    "            \n",
    "            # Readable names\n",
    "            bb_readable = {\n",
    "                \"timm-efficientnet-b3\": \"EfficientNet-B3\",\n",
    "                \"timm-efficientnet-b5\": \"EfficientNet-B5\",\n",
    "                \"tu-efficientvit_b2.r224_in1k\": \"EfficientViT-B2\",\n",
    "                \"tu-fastvit_t8.apple_in1k\": \"FastViT-T8\",\n",
    "                \"tu-repvit_m1.dist_in1k\": \"RepViT-M1\",\n",
    "                \"tu-regnety_032.ra_in1k\": \"RegNetY-032\",\n",
    "                \"tu-regnety_080.ra3_in1k\": \"RegNetY-080\",\n",
    "                \"tu-mambaout_small\": \"MambaOut-Small\",\n",
    "                \"tu-mambaout_base\": \"MambaOut-Base\",\n",
    "                \"tu-efficientnetv2_rw_s.ra2_in1k\": \"EfficientNetV2-S\",\n",
    "                \"tu-efficientnetv2_rw_m.agc_in1k\": \"EfficientNetV2-M\",\n",
    "                \"tu-tf_efficientnetv2_xl.in21k_ft_in1k\": \"EfficientNetV2-XL\",\n",
    "                \"timm-res2net101_26w_4s\": \"Res2Net-101\",\n",
    "                \"resnext50_32x4d\": \"ResNeXt-50\",\n",
    "                \"resnext101_32x8d\": \"ResNeXt-101\",\n",
    "                \"timm-resnest200e\": \"ResNeSt-200E\",\n",
    "            }\n",
    "            \n",
    "            readable_labels = [bb_readable.get(bb, bb) for bb in sorted_backbones]\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax1 = plt.subplots(figsize=(6.5, 4))\n",
    "            \n",
    "            # Create bars with family colors\n",
    "            bars = ax1.bar(range(len(sorted_backbones)), sorted_sizes, \n",
    "                        color=bar_colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "            \n",
    "            ax1.set_title(\"Encodeurs par ordre croissant de paramètres\", fontsize=11, fontweight='bold')\n",
    "            ax1.set_ylabel('Paramètres (Millions)')\n",
    "            ax1.set_xticks(range(len(readable_labels)))\n",
    "            ax1.set_xticklabels(readable_labels, rotation=90, ha='center', fontsize=10)\n",
    "\n",
    "            # Add values on bars\n",
    "            for i, v in enumerate(sorted_sizes):\n",
    "                ax1.text(i, v + max(sorted_sizes) * 0.005, f\"{v:.1f}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            plt.ylim(0, max(sorted_sizes) * 1.07)\n",
    "            ax1.grid(False)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(GRAPHICS_PATH, BACKBONE_SIZE_ENCODER_ORDER_PNG), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        # Create all plots\n",
    "        compare_architectures(arch_results)\n",
    "        compare_backbones_family(backbone_results)\n",
    "        compare_backbones_size(backbone_results)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Execute model architecture analysis.\"\"\"\n",
    "    print(\"Segmentation Models Analysis Tool\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    analyzer = ModelAnalyzer()\n",
    "    \n",
    "    # Analyze architectures with ResNet34\n",
    "    arch_results = analyzer.analyze_architectures(\"tu-resnet34\")\n",
    "    \n",
    "    # Analyze backbones with U-Net\n",
    "    backbone_results = analyzer.analyze_backbones(\"U-Net\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    try:\n",
    "        analyzer.create_comparison_plot(arch_results, backbone_results)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nVisualization skipped: {e}\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "\n",
    "# Execute analysis\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
